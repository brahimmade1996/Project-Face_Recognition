{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/apache/incubator-mxnet/blob/master/tools/im2rec.py\n",
    "-     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T08:50:10.769086Z",
     "start_time": "2020-07-15T08:50:09.404087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mxnet in c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages (from mxnet) (0.8.4)\n",
      "Requirement already satisfied: requests<2.19.0,>=2.18.4 in c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages (from mxnet) (2.18.4)\n",
      "Requirement already satisfied: numpy<1.17.0,>=1.8.2 in c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages (from mxnet) (1.16.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet) (2020.6.20)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet) (1.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install mxnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T08:50:19.796291Z",
     "start_time": "2020-07-15T08:50:12.034580Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# curr_path = os.path.abspath(os.path.dirname(__file__))\n",
    "# sys.path.append(os.path.join(curr_path, \"../python\"))\n",
    "import mxnet as mx\n",
    "import random\n",
    "import argparse\n",
    "import cv2\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "try:\n",
    "    import multiprocessing\n",
    "except ImportError:\n",
    "    multiprocessing = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T09:50:34.526317Z",
     "start_time": "2020-07-15T09:50:34.466286Z"
    }
   },
   "outputs": [],
   "source": [
    "def list_image(root, recursive, exts):\n",
    "    \"\"\"Traverses the root of directory that contains images and\n",
    "    generates image list iterator.\n",
    "    Parameters\n",
    "    ----------\n",
    "    root: string\n",
    "    recursive: bool\n",
    "    exts: string\n",
    "    Returns\n",
    "    -------\n",
    "    image iterator that contains all the image under the specified path\n",
    "    \"\"\"\n",
    "\n",
    "    i = 0\n",
    "    if recursive:\n",
    "        cat = {}\n",
    "        for path, dirs, files in os.walk(root, followlinks=True):\n",
    "            dirs.sort()\n",
    "            files.sort()\n",
    "            for fname in files:\n",
    "                fpath = os.path.join(path, fname)\n",
    "                suffix = os.path.splitext(fname)[1].lower()\n",
    "                if os.path.isfile(fpath) and (suffix in exts):\n",
    "                    if path not in cat:\n",
    "                        cat[path] = len(cat)\n",
    "                    yield (i, os.path.relpath(fpath, root), cat[path])\n",
    "                    i += 1\n",
    "        for k, v in sorted(cat.items(), key=lambda x: x[1]):\n",
    "            print(os.path.relpath(k, root), v)\n",
    "    else:\n",
    "        for fname in sorted(os.listdir(root)):\n",
    "            fpath = os.path.join(root, fname)\n",
    "            suffix = os.path.splitext(fname)[1].lower()\n",
    "            if os.path.isfile(fpath) and (suffix in exts):\n",
    "                yield (i, os.path.relpath(fpath, root), 0)\n",
    "                i += 1\n",
    "\n",
    "def write_list(path_out, image_list):\n",
    "    \"\"\"Hepler function to write image list into the file.\n",
    "    The format is as below,\n",
    "    integer_image_index \\t float_label_index \\t path_to_image\n",
    "    Note that the blank between number and tab is only used for readability.\n",
    "    Parameters\n",
    "    ----------\n",
    "    path_out: string\n",
    "    image_list: list\n",
    "    \"\"\"\n",
    "    with open(path_out, 'w') as fout:\n",
    "        for i, item in enumerate(image_list):\n",
    "            line = '%d\\t' % item[0]\n",
    "            for j in item[2:]:\n",
    "                line += '%f\\t' % j\n",
    "            line += '%s\\n' % item[1]\n",
    "            fout.write(line)\n",
    "\n",
    "def make_list(args):\n",
    "    \"\"\"Generates .lst file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    args: object that contains all the arguments\n",
    "    \"\"\"\n",
    "    image_list = list_image(args.root, args.recursive, args.exts)\n",
    "    image_list = list(image_list)\n",
    "    if args.shuffle is True:\n",
    "        random.seed(100)\n",
    "        random.shuffle(image_list)\n",
    "    N = len(image_list)\n",
    "    chunk_size = (N + args.chunks - 1) // args.chunks\n",
    "    for i in range(args.chunks):\n",
    "        chunk = image_list[i * chunk_size:(i + 1) * chunk_size]\n",
    "        if args.chunks > 1:\n",
    "            str_chunk = '_%d' % i\n",
    "        else:\n",
    "            str_chunk = ''\n",
    "        sep = int(chunk_size * args.train_ratio)\n",
    "        sep_test = int(chunk_size * args.test_ratio)\n",
    "        if args.train_ratio == 1.0:\n",
    "            write_list(args.prefix + str_chunk + '.lst', chunk)\n",
    "        else:\n",
    "            if args.test_ratio:\n",
    "                write_list(args.prefix + str_chunk + '_test.lst', chunk[:sep_test])\n",
    "            if args.train_ratio + args.test_ratio < 1.0:\n",
    "                write_list(args.prefix + str_chunk + '_val.lst', chunk[sep_test + sep:])\n",
    "            write_list(args.prefix + str_chunk + '_train.lst', chunk[sep_test:sep_test + sep])\n",
    "\n",
    "def read_list(path_in):\n",
    "    \"\"\"Reads the .lst file and generates corresponding iterator.\n",
    "    Parameters\n",
    "    ----------\n",
    "    path_in: string\n",
    "    Returns\n",
    "    -------\n",
    "    item iterator that contains information in .lst file\n",
    "    \"\"\"\n",
    "    with open(path_in) as fin:\n",
    "        while True:\n",
    "            line = fin.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = [i.strip() for i in line.strip().split('\\t')]\n",
    "            line_len = len(line)\n",
    "            # check the data format of .lst file\n",
    "            if line_len < 3:\n",
    "                print('lst should have at least has three parts, but only has %s parts for %s' % (line_len, line))\n",
    "                continue\n",
    "            try:\n",
    "                item = [int(line[0])] + [line[-1]] + [float(i) for i in line[1:-1]]\n",
    "            except Exception as e:\n",
    "                print('Parsing lst met error for %s, detail: %s' % (line, e))\n",
    "                continue\n",
    "            yield item\n",
    "\n",
    "def image_encode(args, i, item, q_out):\n",
    "    \"\"\"Reads, preprocesses, packs the image and put it back in output queue.\n",
    "    Parameters\n",
    "    ----------\n",
    "    args: object\n",
    "    i: int\n",
    "    item: list\n",
    "    q_out: queue\n",
    "    \"\"\"\n",
    "    fullpath = os.path.join(args.root, item[1])\n",
    "\n",
    "    if len(item) > 3 and args.pack_label:\n",
    "        header = mx.recordio.IRHeader(0, item[2:], item[0], 0)\n",
    "    else:\n",
    "        header = mx.recordio.IRHeader(0, item[2], item[0], 0)\n",
    "\n",
    "    if args.pass_through:\n",
    "        try:\n",
    "            with open(fullpath, 'rb') as fin:\n",
    "                img = fin.read()\n",
    "            s = mx.recordio.pack(header, img)\n",
    "            q_out.put((i, s, item))\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            print('pack_img error:', item[1], e)\n",
    "            q_out.put((i, None, item))\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        img = cv2.imread(fullpath, args.color)\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        print('imread error trying to load file: %s ' % fullpath)\n",
    "        q_out.put((i, None, item))\n",
    "        return\n",
    "    if img is None:\n",
    "        print('imread read blank (None) image for file: %s' % fullpath)\n",
    "        q_out.put((i, None, item))\n",
    "        return\n",
    "    if args.center_crop:\n",
    "        if img.shape[0] > img.shape[1]:\n",
    "            margin = (img.shape[0] - img.shape[1]) // 2\n",
    "            img = img[margin:margin + img.shape[1], :]\n",
    "        else:\n",
    "            margin = (img.shape[1] - img.shape[0]) // 2\n",
    "            img = img[:, margin:margin + img.shape[0]]\n",
    "    if args.resize:\n",
    "        if img.shape[0] > img.shape[1]:\n",
    "            newsize = (args.resize, img.shape[0] * args.resize // img.shape[1])\n",
    "        else:\n",
    "            newsize = (img.shape[1] * args.resize // img.shape[0], args.resize)\n",
    "        img = cv2.resize(img, newsize)\n",
    "\n",
    "    try:\n",
    "        s = mx.recordio.pack_img(header, img, quality=args.quality, img_fmt=args.encoding)\n",
    "        q_out.put((i, s, item))\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        print('pack_img error on file: %s' % fullpath, e)\n",
    "        q_out.put((i, None, item))\n",
    "        return\n",
    "\n",
    "def read_worker(args, q_in, q_out):\n",
    "    \"\"\"Function that will be spawned to fetch the image\n",
    "    from the input queue and put it back to output queue.\n",
    "    Parameters\n",
    "    ----------\n",
    "    args: object\n",
    "    q_in: queue\n",
    "    q_out: queue\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        deq = q_in.get()\n",
    "        if deq is None:\n",
    "            break\n",
    "        i, item = deq\n",
    "        image_encode(args, i, item, q_out)\n",
    "\n",
    "def write_worker(q_out, fname, working_dir):\n",
    "    \"\"\"Function that will be spawned to fetch processed image\n",
    "    from the output queue and write to the .rec file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    q_out: queue\n",
    "    fname: string\n",
    "    working_dir: string\n",
    "    \"\"\"\n",
    "    pre_time = time.time()\n",
    "    count = 0\n",
    "    fname = os.path.basename(fname)\n",
    "    fname_rec = os.path.splitext(fname)[0] + '.rec'\n",
    "    fname_idx = os.path.splitext(fname)[0] + '.idx'\n",
    "    record = mx.recordio.MXIndexedRecordIO(os.path.join(working_dir, fname_idx),\n",
    "                                           os.path.join(working_dir, fname_rec), 'w')\n",
    "    buf = {}\n",
    "    more = True\n",
    "    while more:\n",
    "        deq = q_out.get()\n",
    "        if deq is not None:\n",
    "            i, s, item = deq\n",
    "            buf[i] = (s, item)\n",
    "        else:\n",
    "            more = False\n",
    "        while count in buf:\n",
    "            s, item = buf[count]\n",
    "            del buf[count]\n",
    "            if s is not None:\n",
    "                record.write_idx(item[0], s)\n",
    "\n",
    "            if count % 1000 == 0:\n",
    "                cur_time = time.time()\n",
    "                print('time:', cur_time - pre_time, ' count:', count)\n",
    "                pre_time = cur_time\n",
    "            count += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T09:30:49.179758Z",
     "start_time": "2020-07-15T09:30:48.036795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: easydict in c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages (1.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T09:50:59.447290Z",
     "start_time": "2020-07-15T09:50:59.443289Z"
    }
   },
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T09:37:33.935534Z",
     "start_time": "2020-07-15T09:37:33.922534Z"
    }
   },
   "outputs": [],
   "source": [
    "class JsonConfigFileManager:\n",
    "    \"\"\"Json설정파일을 관리한다\"\"\"\n",
    "    def __init__(self, file_path):\n",
    "        self.values = EasyDict()\n",
    "        if file_path:\n",
    "            self.file_path = file_path # 파일경로 저장\n",
    "            self.reload()\n",
    "\n",
    "    def reload(self):\n",
    "        \"\"\"설정을 리셋하고 설정파일을 다시 로딩한다\"\"\"\n",
    "        self.clear()\n",
    "        if self.file_path:\n",
    "            with open(self.file_path, 'r') as f:\n",
    "                self.values.update(json.load(f))\n",
    "\n",
    "    def clear(self):\n",
    "        \"\"\"설정을 리셋한다\"\"\"\n",
    "        self.values.clear()\n",
    "                \n",
    "    def update(self, in_dict):\n",
    "        \"\"\"기존 설정에 새로운 설정을 업데이트한다(최대 3레벨까지만)\"\"\"\n",
    "        for (k1, v1) in in_dict.items():\n",
    "            if isinstance(v1, dict):\n",
    "                for (k2, v2) in v1.items():\n",
    "                    if isinstance(v2, dict):\n",
    "                        for (k3, v3) in v2.items():\n",
    "                            self.values[k1][k2][k3] = v3\n",
    "                    else:\n",
    "                        self.values[k1][k2] = v2\n",
    "            else:\n",
    "                self.values[k1] = v1     \n",
    "            \n",
    "    def export(self, save_file_name):\n",
    "        \"\"\"설정값을 json파일로 저장한다\"\"\"\n",
    "        if save_file_name:\n",
    "            with open(save_file_name, 'w') as f:\n",
    "                json.dump(dict(self.values), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T09:44:25.900798Z",
     "start_time": "2020-07-15T09:44:25.884769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 10, 'model': {'batch_size': 32, 'cells': 64}}\n",
      "epochs: 10\n",
      "epochs: 10\n",
      "batch_size: 32\n",
      "batch_size: 32\n",
      "{'epochs': 20, 'model': {'batch_size': 32, 'cells': 128}, 'patients': 3}\n"
     ]
    }
   ],
   "source": [
    "conf = JsonConfigFileManager('config.json')\n",
    "\n",
    "# dict과 내용이 같다\n",
    "print(conf.values)\n",
    "\n",
    "# 대괄호[] 또는 점(.)을 이용하여 접근할 수 있다\n",
    "print('epochs:', conf.values['epochs'])\n",
    "print('epochs:', conf.values.epochs)\n",
    "\n",
    "print('batch_size:', conf.values['model']['batch_size'])\n",
    "print('batch_size:', conf.values.model.batch_size)\n",
    "\n",
    "# 새로운 dict의 값으로 각 키별 업데이트한다 \n",
    "conf.update({'epochs': 20, 'model': {'cells': 128}, 'patients': 3})\n",
    "\n",
    "# 업데이트된 결과를 확인할 수 있다\n",
    "print(conf.values)\n",
    "\n",
    "# 현재 설정을 다른 파일명으로 내보낸다\n",
    "conf.export('config_new.json')                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args= EasyDict({\n",
    "    'prefix': 'vgg', #'prefix of input/output lst and rec files.')\n",
    "    'root': '../data/small_vgg/train' #'path to folder containing images.')\n",
    "})\n",
    "\n",
    "cgroup = EasyDict({\n",
    "    '--list', action='store_true',\n",
    "                        help='If this is set im2rec will create image list(s) by traversing root folder\\\n",
    "        and output to <prefix>.lst.\\\n",
    "        Otherwise im2rec will read <prefix>.lst and create a database at <prefix>.rec')\n",
    "    cgroup.add_argument('--exts', nargs='+', default=['.jpeg', '.jpg', '.png'],\n",
    "                        help='list of acceptable image extensions.')\n",
    "    cgroup.add_argument('--chunks', type=int, default=1, help='number of chunks.')\n",
    "    cgroup.add_argument('--train-ratio', type=float, default=1.0,\n",
    "                        help='Ratio of images to use for training.')\n",
    "    cgroup.add_argument('--test-ratio', type=float, default=0,\n",
    "                        help='Ratio of images to use for testing.')\n",
    "    cgroup.add_argument('--recursive', action='store_true',\n",
    "                        help='If true recursively walk through subdirs and assign an unique label\\\n",
    "        to images in each folder. Otherwise only include images in the root folder\\\n",
    "        and give them label 0.')\n",
    "    cgroup.add_argument('--no-shuffle', dest='shuffle', action='store_false',\n",
    "                        help='If this is passed, \\\n",
    "        im2rec will not randomize the image order in <prefix>.lst')\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    \"\"\"Defines all arguments.\n",
    "    Returns\n",
    "    -------\n",
    "    args object that contains all the params\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n",
    "        description='Create an image list or \\\n",
    "        make a record database by reading from an image list')\n",
    "    parser.add_argument('prefix', help='prefix of input/output lst and rec files.')\n",
    "    parser.add_argument('root', help='path to folder containing images.')\n",
    "\n",
    "    cgroup = parser.add_argument_group('Options for creating image lists')\n",
    "    cgroup.add_argument('--list', action='store_true',\n",
    "                        help='If this is set im2rec will create image list(s) by traversing root folder\\\n",
    "        and output to <prefix>.lst.\\\n",
    "        Otherwise im2rec will read <prefix>.lst and create a database at <prefix>.rec')\n",
    "    cgroup.add_argument('--exts', nargs='+', default=['.jpeg', '.jpg', '.png'],\n",
    "                        help='list of acceptable image extensions.')\n",
    "    cgroup.add_argument('--chunks', type=int, default=1, help='number of chunks.')\n",
    "    cgroup.add_argument('--train-ratio', type=float, default=1.0,\n",
    "                        help='Ratio of images to use for training.')\n",
    "    cgroup.add_argument('--test-ratio', type=float, default=0,\n",
    "                        help='Ratio of images to use for testing.')\n",
    "    cgroup.add_argument('--recursive', action='store_true',\n",
    "                        help='If true recursively walk through subdirs and assign an unique label\\\n",
    "        to images in each folder. Otherwise only include images in the root folder\\\n",
    "        and give them label 0.')\n",
    "    cgroup.add_argument('--no-shuffle', dest='shuffle', action='store_false',\n",
    "                        help='If this is passed, \\\n",
    "        im2rec will not randomize the image order in <prefix>.lst')\n",
    "    \n",
    "    rgroup = parser.add_argument_group('Options for creating database')\n",
    "    rgroup.add_argument('--pass-through', action='store_true',\n",
    "                        help='whether to skip transformation and save image as is')\n",
    "    rgroup.add_argument('--resize', type=int, default=0,\n",
    "                        help='resize the shorter edge of image to the newsize, original images will\\\n",
    "        be packed by default.')\n",
    "    rgroup.add_argument('--center-crop', action='store_true',\n",
    "                        help='specify whether to crop the center image to make it rectangular.')\n",
    "    rgroup.add_argument('--quality', type=int, default=95,\n",
    "                        help='JPEG quality for encoding, 1-100; or PNG compression for encoding, 1-9')\n",
    "    rgroup.add_argument('--num-thread', type=int, default=1,\n",
    "                        help='number of thread to use for encoding. order of images will be different\\\n",
    "        from the input list if >1. the input list will be modified to match the\\\n",
    "        resulting order.')\n",
    "    rgroup.add_argument('--color', type=int, default=1, choices=[-1, 0, 1],\n",
    "                        help='specify the color mode of the loaded image.\\\n",
    "        1: Loads a color image. Any transparency of image will be neglected. It is the default flag.\\\n",
    "        0: Loads image in grayscale mode.\\\n",
    "        -1:Loads image as such including alpha channel.')\n",
    "    rgroup.add_argument('--encoding', type=str, default='.jpg', choices=['.jpg', '.png'],\n",
    "                        help='specify the encoding of the images.')\n",
    "    rgroup.add_argument('--pack-label', action='store_true',\n",
    "        help='Whether to also pack multi dimensional label in the record file')\n",
    "    args = parser.parse_args()\n",
    "    args.prefix = os.path.abspath(args.prefix)\n",
    "    args.root = os.path.abspath(args.root)\n",
    "    return args\n",
    "\n",
    "if __name__ == '__main__':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T09:49:50.515287Z",
     "start_time": "2020-07-15T09:49:50.481322Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--list] [--exts EXTS [EXTS ...]]\n",
      "                             [--chunks CHUNKS] [--train-ratio TRAIN_RATIO]\n",
      "                             [--test-ratio TEST_RATIO] [--recursive]\n",
      "                             [--no-shuffle] [--pass-through] [--resize RESIZE]\n",
      "                             [--center-crop] [--quality QUALITY]\n",
      "                             [--num-thread NUM_THREAD] [--color {-1,0,1}]\n",
      "                             [--encoding {.jpg,.png}] [--pack-label]\n",
      "                             prefix root\n",
      "ipykernel_launcher.py: error: the following arguments are required: root\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shiney\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "args = parse_args()\n",
    "# if the '--list' is used, it generates .lst file\n",
    "if args.list:\n",
    "    make_list(args)\n",
    "# otherwise read .lst file to generates .rec file\n",
    "else:\n",
    "    if os.path.isdir(args.prefix):\n",
    "        working_dir = args.prefix\n",
    "    else:\n",
    "        working_dir = os.path.dirname(args.prefix)\n",
    "    files = [os.path.join(working_dir, fname) for fname in os.listdir(working_dir)\n",
    "                if os.path.isfile(os.path.join(working_dir, fname))]\n",
    "    count = 0\n",
    "    for fname in files:\n",
    "        if fname.startswith(args.prefix) and fname.endswith('.lst'):\n",
    "            print('Creating .rec file from', fname, 'in', working_dir)\n",
    "            count += 1\n",
    "            image_list = read_list(fname)\n",
    "            # -- write_record -- #\n",
    "            if args.num_thread > 1 and multiprocessing is not None:\n",
    "                q_in = [multiprocessing.Queue(1024) for i in range(args.num_thread)]\n",
    "                q_out = multiprocessing.Queue(1024)\n",
    "                # define the process\n",
    "                read_process = [multiprocessing.Process(target=read_worker, args=(args, q_in[i], q_out)) \\\n",
    "                                for i in range(args.num_thread)]\n",
    "                # process images with num_thread process\n",
    "                for p in read_process:\n",
    "                    p.start()\n",
    "                # only use one process to write .rec to avoid race-condtion\n",
    "                write_process = multiprocessing.Process(target=write_worker, args=(q_out, fname, working_dir))\n",
    "                write_process.start()\n",
    "                # put the image list into input queue\n",
    "                for i, item in enumerate(image_list):\n",
    "                    q_in[i % len(q_in)].put((i, item))\n",
    "                for q in q_in:\n",
    "                    q.put(None)\n",
    "                for p in read_process:\n",
    "                    p.join()\n",
    "\n",
    "                q_out.put(None)\n",
    "                write_process.join()\n",
    "            else:\n",
    "                print('multiprocessing not available, fall back to single threaded encoding')\n",
    "                try:\n",
    "                    import Queue as queue\n",
    "                except ImportError:\n",
    "                    import queue\n",
    "                q_out = queue.Queue()\n",
    "                fname = os.path.basename(fname)\n",
    "                fname_rec = os.path.splitext(fname)[0] + '.rec'\n",
    "                fname_idx = os.path.splitext(fname)[0] + '.idx'\n",
    "                record = mx.recordio.MXIndexedRecordIO(os.path.join(working_dir, fname_idx),\n",
    "                                                       os.path.join(working_dir, fname_rec), 'w')\n",
    "                cnt = 0\n",
    "                pre_time = time.time()\n",
    "                for i, item in enumerate(image_list):\n",
    "                    image_encode(args, i, item, q_out)\n",
    "                    if q_out.empty():\n",
    "                        continue\n",
    "                    _, s, _ = q_out.get()\n",
    "                    record.write_idx(item[0], s)\n",
    "                    if cnt % 1000 == 0:\n",
    "                        cur_time = time.time()\n",
    "                        print('time:', cur_time - pre_time, ' count:', cnt)\n",
    "                        pre_time = cur_time\n",
    "                    cnt += 1\n",
    "    if not count:\n",
    "        print('Did not find and list file with prefix %s'%args.prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T08:52:28.092347Z",
     "start_time": "2020-07-15T08:52:28.076351Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    \"\"\"Defines all arguments.\n",
    "    Returns\n",
    "    -------\n",
    "    args object that contains all the params\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n",
    "        description='Create an image list or \\\n",
    "        make a record database by reading from an image list')\n",
    "    parser.add_argument('prefix', help='prefix of input/output lst and rec files.')\n",
    "    parser.add_argument('root', help='path to folder containing images.')\n",
    "\n",
    "    cgroup = parser.add_argument_group('Options for creating image lists')\n",
    "    cgroup.add_argument('--list', action='store_true',\n",
    "                        help='If this is set im2rec will create image list(s) by traversing root folder\\\n",
    "        and output to <prefix>.lst.\\\n",
    "        Otherwise im2rec will read <prefix>.lst and create a database at <prefix>.rec')\n",
    "    cgroup.add_argument('--exts', nargs='+', default=['.jpeg', '.jpg', '.png'],\n",
    "                        help='list of acceptable image extensions.')\n",
    "    cgroup.add_argument('--chunks', type=int, default=1, help='number of chunks.')\n",
    "    cgroup.add_argument('--train-ratio', type=float, default=1.0,\n",
    "                        help='Ratio of images to use for training.')\n",
    "    cgroup.add_argument('--test-ratio', type=float, default=0,\n",
    "                        help='Ratio of images to use for testing.')\n",
    "    cgroup.add_argument('--recursive', action='store_true',\n",
    "                        help='If true recursively walk through subdirs and assign an unique label\\\n",
    "        to images in each folder. Otherwise only include images in the root folder\\\n",
    "        and give them label 0.')\n",
    "    cgroup.add_argument('--no-shuffle', dest='shuffle', action='store_false',\n",
    "                        help='If this is passed, \\\n",
    "        im2rec will not randomize the image order in <prefix>.lst')\n",
    "    rgroup = parser.add_argument_group('Options for creating database')\n",
    "    rgroup.add_argument('--pass-through', action='store_true',\n",
    "                        help='whether to skip transformation and save image as is')\n",
    "    rgroup.add_argument('--resize', type=int, default=0,\n",
    "                        help='resize the shorter edge of image to the newsize, original images will\\\n",
    "        be packed by default.')\n",
    "    rgroup.add_argument('--center-crop', action='store_true',\n",
    "                        help='specify whether to crop the center image to make it rectangular.')\n",
    "    rgroup.add_argument('--quality', type=int, default=95,\n",
    "                        help='JPEG quality for encoding, 1-100; or PNG compression for encoding, 1-9')\n",
    "    rgroup.add_argument('--num-thread', type=int, default=1,\n",
    "                        help='number of thread to use for encoding. order of images will be different\\\n",
    "        from the input list if >1. the input list will be modified to match the\\\n",
    "        resulting order.')\n",
    "    rgroup.add_argument('--color', type=int, default=1, choices=[-1, 0, 1],\n",
    "                        help='specify the color mode of the loaded image.\\\n",
    "        1: Loads a color image. Any transparency of image will be neglected. It is the default flag.\\\n",
    "        0: Loads image in grayscale mode.\\\n",
    "        -1:Loads image as such including alpha channel.')\n",
    "    rgroup.add_argument('--encoding', type=str, default='.jpg', choices=['.jpg', '.png'],\n",
    "                        help='specify the encoding of the images.')\n",
    "    rgroup.add_argument('--pack-label', action='store_true',\n",
    "        help='Whether to also pack multi dimensional label in the record file')\n",
    "    args = parser.parse_args()\n",
    "    args.prefix = os.path.abspath(args.prefix)\n",
    "    args.root = os.path.abspath(args.root)\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T08:53:01.987540Z",
     "start_time": "2020-07-15T08:53:01.978539Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--list] [--exts EXTS [EXTS ...]]\n",
      "                             [--chunks CHUNKS] [--train-ratio TRAIN_RATIO]\n",
      "                             [--test-ratio TEST_RATIO] [--recursive]\n",
      "                             [--no-shuffle] [--pass-through] [--resize RESIZE]\n",
      "                             [--center-crop] [--quality QUALITY]\n",
      "                             [--num-thread NUM_THREAD] [--color {-1,0,1}]\n",
      "                             [--encoding {.jpg,.png}] [--pack-label]\n",
      "                             prefix root\n",
      "ipykernel_launcher.py: error: the following arguments are required: root\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "args = parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T08:52:46.311119Z",
     "start_time": "2020-07-15T08:52:46.251121Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--list] [--exts EXTS [EXTS ...]]\n",
      "                             [--chunks CHUNKS] [--train-ratio TRAIN_RATIO]\n",
      "                             [--test-ratio TEST_RATIO] [--recursive]\n",
      "                             [--no-shuffle] [--pass-through] [--resize RESIZE]\n",
      "                             [--center-crop] [--quality QUALITY]\n",
      "                             [--num-thread NUM_THREAD] [--color {-1,0,1}]\n",
      "                             [--encoding {.jpg,.png}] [--pack-label]\n",
      "                             prefix root\n",
      "ipykernel_launcher.py: error: the following arguments are required: root\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "# if the '--list' is used, it generates .lst file\n",
    "if args.list:\n",
    "    make_list(args)\n",
    "# otherwise read .lst file to generates .rec file\n",
    "else:\n",
    "    if os.path.isdir(args.prefix):\n",
    "        working_dir = args.prefix\n",
    "    else:\n",
    "        working_dir = os.path.dirname(args.prefix)\n",
    "    files = [os.path.join(working_dir, fname) for fname in os.listdir(working_dir)\n",
    "                if os.path.isfile(os.path.join(working_dir, fname))]\n",
    "    count = 0\n",
    "    for fname in files:\n",
    "        if fname.startswith(args.prefix) and fname.endswith('.lst'):\n",
    "            print('Creating .rec file from', fname, 'in', working_dir)\n",
    "            count += 1\n",
    "            image_list = read_list(fname)\n",
    "            # -- write_record -- #\n",
    "            if args.num_thread > 1 and multiprocessing is not None:\n",
    "                q_in = [multiprocessing.Queue(1024) for i in range(args.num_thread)]\n",
    "                q_out = multiprocessing.Queue(1024)\n",
    "                # define the process\n",
    "                read_process = [multiprocessing.Process(target=read_worker, args=(args, q_in[i], q_out)) \\\n",
    "                                for i in range(args.num_thread)]\n",
    "                # process images with num_thread process\n",
    "                for p in read_process:\n",
    "                    p.start()\n",
    "                # only use one process to write .rec to avoid race-condtion\n",
    "                write_process = multiprocessing.Process(target=write_worker, args=(q_out, fname, working_dir))\n",
    "                write_process.start()\n",
    "                # put the image list into input queue\n",
    "                for i, item in enumerate(image_list):\n",
    "                    q_in[i % len(q_in)].put((i, item))\n",
    "                for q in q_in:\n",
    "                    q.put(None)\n",
    "                for p in read_process:\n",
    "                    p.join()\n",
    "\n",
    "                q_out.put(None)\n",
    "                write_process.join()\n",
    "            else:\n",
    "                print('multiprocessing not available, fall back to single threaded encoding')\n",
    "                try:\n",
    "                    import Queue as queue\n",
    "                except ImportError:\n",
    "                    import queue\n",
    "                q_out = queue.Queue()\n",
    "                fname = os.path.basename(fname)\n",
    "                fname_rec = os.path.splitext(fname)[0] + '.rec'\n",
    "                fname_idx = os.path.splitext(fname)[0] + '.idx'\n",
    "                record = mx.recordio.MXIndexedRecordIO(os.path.join(working_dir, fname_idx),\n",
    "                                                       os.path.join(working_dir, fname_rec), 'w')\n",
    "                cnt = 0\n",
    "                pre_time = time.time()\n",
    "                for i, item in enumerate(image_list):\n",
    "                    image_encode(args, i, item, q_out)\n",
    "                    if q_out.empty():\n",
    "                        continue\n",
    "                    _, s, _ = q_out.get()\n",
    "                    record.write_idx(item[0], s)\n",
    "                    if cnt % 1000 == 0:\n",
    "                        cur_time = time.time()\n",
    "                        print('time:', cur_time - pre_time, ' count:', cnt)\n",
    "                        pre_time = cur_time\n",
    "                    cnt += 1\n",
    "    if not count:\n",
    "        print('Did not find and list file with prefix %s'%args.prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
