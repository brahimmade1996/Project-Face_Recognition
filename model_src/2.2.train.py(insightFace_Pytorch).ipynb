{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# insightFace_Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T05:24:21.356199Z",
     "start_time": "2020-07-17T05:24:21.239923Z"
    }
   },
   "outputs": [],
   "source": [
    "from easydict import EasyDict as edict\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchvision import transforms as trans\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# from data.data_pipe import de_preprocess, get_train_loader, get_val_data\n",
    "# from model import Backbone, Arcface, MobileFaceNet, Am_softmax, l2_norm\n",
    "# from verifacation import evaluate\n",
    "# from utils import get_time, gen_plot, hflip_batch, separate_bn_paras\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "from matplotlib import pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "from PIL import Image\n",
    "from torchvision import transforms as trans\n",
    "import math\n",
    "import bcolz\n",
    "\n",
    "from torch.nn import Linear, Conv2d, BatchNorm1d, BatchNorm2d, PReLU, ReLU, Sigmoid, Dropout2d, Dropout, AvgPool2d, MaxPool2d, AdaptiveAvgPool2d, Sequential, Module, Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from collections import namedtuple\n",
    "import math\n",
    "import pdb\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn\n",
    "from scipy import interpolate\n",
    "import datetime\n",
    "import mxnet as mx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 적인 변수들: config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T05:22:26.628407Z",
     "start_time": "2020-07-17T05:22:26.611414Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_config(training = True):\n",
    "    conf = edict()\n",
    "    conf.data_path = Path('../data')\n",
    "    conf.work_path = Path('work_space/')\n",
    "    conf.model_path = conf.work_path/'models'\n",
    "    conf.log_path = conf.work_path/'log'\n",
    "    conf.save_path = conf.work_path/'save'\n",
    "    conf.input_size = [112,112]\n",
    "    conf.embedding_size = 512\n",
    "    conf.use_mobilfacenet = False\n",
    "    conf.net_depth = 50\n",
    "    conf.drop_ratio = 0.6\n",
    "    conf.net_mode = 'ir_se' # or 'ir'\n",
    "    conf.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    conf.test_transform = trans.Compose([\n",
    "                    trans.ToTensor(),\n",
    "                    trans.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "                ])\n",
    "    conf.data_mode = 'emore'\n",
    "    conf.vgg_folder = conf.data_path/'faces_vgg2_112x112'\n",
    "    conf.ms1m_folder = conf.data_path/'faces_ms1m_112x112'\n",
    "    conf.emore_folder = conf.data_path/'faces_emore'\n",
    "    conf.batch_size = 100 # irse net depth 50 \n",
    "#   conf.batch_size = 200 # mobilefacenet\n",
    "#--------------------Training Config ------------------------    \n",
    "    if training:        \n",
    "        conf.log_path = conf.work_path/'log'\n",
    "        conf.save_path = conf.work_path/'save'\n",
    "    #     conf.weight_decay = 5e-4\n",
    "        conf.lr = 1e-3\n",
    "        conf.milestones = [12,15,18]\n",
    "        conf.momentum = 0.9\n",
    "        conf.pin_memory = True\n",
    "#         conf.num_workers = 4 # when batchsize is 200\n",
    "        conf.num_workers = 3\n",
    "        conf.ce_loss = CrossEntropyLoss()    \n",
    "#--------------------Inference Config ------------------------\n",
    "    else:\n",
    "        conf.facebank_path = conf.data_path/'facebank'\n",
    "        conf.threshold = 1.5\n",
    "        conf.face_limit = 10 \n",
    "        #when inference, at maximum detect 10 faces in one image, my laptop is slow\n",
    "        conf.min_face_size = 30 \n",
    "        # the larger this value, the faster deduction, comes with tradeoff in small faces\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T05:12:45.306177Z",
     "start_time": "2020-07-17T05:12:45.303180Z"
    }
   },
   "source": [
    "### utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T05:20:17.422864Z",
     "start_time": "2020-07-17T05:20:17.402824Z"
    }
   },
   "outputs": [],
   "source": [
    "def separate_bn_paras(modules):\n",
    "    if not isinstance(modules, list):\n",
    "        modules = [*modules.modules()]\n",
    "    paras_only_bn = []\n",
    "    paras_wo_bn = []\n",
    "    for layer in modules:\n",
    "        if 'model' in str(layer.__class__):\n",
    "            continue\n",
    "        if 'container' in str(layer.__class__):\n",
    "            continue\n",
    "        else:\n",
    "            if 'batchnorm' in str(layer.__class__):\n",
    "                paras_only_bn.extend([*layer.parameters()])\n",
    "            else:\n",
    "                paras_wo_bn.extend([*layer.parameters()])\n",
    "    return paras_only_bn, paras_wo_bn\n",
    "\n",
    "def hflip_batch(imgs_tensor):\n",
    "    hfliped_imgs = torch.empty_like(imgs_tensor)\n",
    "    for i, img_ten in enumerate(imgs_tensor):\n",
    "        hfliped_imgs[i] = hflip(img_ten)\n",
    "    return hfliped_imgs\n",
    "\n",
    "def get_time():\n",
    "    return (str(datetime.now())[:-10]).replace(' ','-').replace(':','-')\n",
    "\n",
    "def gen_plot(fpr, tpr):\n",
    "    \"\"\"Create a pyplot plot and save to buffer.\"\"\"\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"FPR\", fontsize=14)\n",
    "    plt.ylabel(\"TPR\", fontsize=14)\n",
    "    plt.title(\"ROC Curve\", fontsize=14)\n",
    "    plot = plt.plot(fpr, tpr, linewidth=2)\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='jpeg')\n",
    "    buf.seek(0)\n",
    "    plt.close()\n",
    "    return buf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data_pipe.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T05:57:55.914987Z",
     "start_time": "2020-07-17T05:57:55.896997Z"
    }
   },
   "outputs": [],
   "source": [
    "def de_preprocess(tensor):\n",
    "    return tensor*0.5 + 0.5\n",
    "    \n",
    "def get_train_dataset(imgs_folder):\n",
    "    train_transform = trans.Compose([\n",
    "        trans.RandomHorizontalFlip(),\n",
    "        trans.ToTensor(),\n",
    "        trans.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    ds = ImageFolder(imgs_folder, train_transform)\n",
    "    class_num = ds[-1][1] + 1\n",
    "    print('class_num', class_num)\n",
    "    return ds, class_num\n",
    "\n",
    "def get_train_loader(conf):\n",
    "    if conf.data_mode in ['ms1m', 'concat']:\n",
    "        ms1m_ds, ms1m_class_num = get_train_dataset(conf.ms1m_folder/'imgs')\n",
    "        print('ms1m loader generated')\n",
    "    if conf.data_mode in ['vgg', 'concat']:\n",
    "        vgg_ds, vgg_class_num = get_train_dataset(conf.vgg_folder/'imgs')\n",
    "        print('vgg loader generated')        \n",
    "    if conf.data_mode == 'vgg':\n",
    "        ds = vgg_ds\n",
    "        class_num = vgg_class_num\n",
    "    elif conf.data_mode == 'ms1m':\n",
    "        ds = ms1m_ds\n",
    "        class_num = ms1m_class_num\n",
    "    elif conf.data_mode == 'concat':\n",
    "        for i,(url,label) in enumerate(vgg_ds.imgs):\n",
    "            vgg_ds.imgs[i] = (url, label + ms1m_class_num)\n",
    "        ds = ConcatDataset([ms1m_ds,vgg_ds])\n",
    "        class_num = vgg_class_num + ms1m_class_num\n",
    "    elif conf.data_mode == 'emore':\n",
    "        ds, class_num = get_train_dataset(conf.emore_folder/'imgs')\n",
    "    loader = DataLoader(ds, batch_size=conf.batch_size, shuffle=True, pin_memory=conf.pin_memory, num_workers=conf.num_workers)\n",
    "    return loader, class_num \n",
    "\n",
    "def get_val_data(data_path):\n",
    "    agedb_30, agedb_30_issame = get_val_pair(data_path, 'agedb_30')\n",
    "    cfp_fp, cfp_fp_issame = get_val_pair(data_path, 'cfp_fp')\n",
    "    lfw, lfw_issame = get_val_pair(data_path, 'lfw')\n",
    "    return agedb_30, cfp_fp, lfw, agedb_30_issame, cfp_fp_issame, lfw_issame\n",
    "\n",
    "def get_val_pair(path, name):\n",
    "    carray = bcolz.carray(rootdir = path/name, mode='r')\n",
    "    issame = np.load(path/'{}_list.npy'.format(name))\n",
    "    return carray, issame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T05:15:02.527796Z",
     "start_time": "2020-07-17T05:15:02.426519Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "##################################  Original Arcface Model #############################################################\n",
    "\n",
    "class Flatten(Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "def l2_norm(input,axis=1):\n",
    "    norm = torch.norm(input,2,axis,True)\n",
    "    output = torch.div(input, norm)\n",
    "    return output\n",
    "\n",
    "class SEModule(Module):\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = Conv2d(\n",
    "            channels, channels // reduction, kernel_size=1, padding=0 ,bias=False)\n",
    "        self.relu = ReLU(inplace=True)\n",
    "        self.fc2 = Conv2d(\n",
    "            channels // reduction, channels, kernel_size=1, padding=0 ,bias=False)\n",
    "        self.sigmoid = Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x\n",
    "\n",
    "class bottleneck_IR(Module):\n",
    "    def __init__(self, in_channel, depth, stride):\n",
    "        super(bottleneck_IR, self).__init__()\n",
    "        if in_channel == depth:\n",
    "            self.shortcut_layer = MaxPool2d(1, stride)\n",
    "        else:\n",
    "            self.shortcut_layer = Sequential(\n",
    "                Conv2d(in_channel, depth, (1, 1), stride ,bias=False), BatchNorm2d(depth))\n",
    "        self.res_layer = Sequential(\n",
    "            BatchNorm2d(in_channel),\n",
    "            Conv2d(in_channel, depth, (3, 3), (1, 1), 1 ,bias=False), PReLU(depth),\n",
    "            Conv2d(depth, depth, (3, 3), stride, 1 ,bias=False), BatchNorm2d(depth))\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut_layer(x)\n",
    "        res = self.res_layer(x)\n",
    "        return res + shortcut\n",
    "\n",
    "class bottleneck_IR_SE(Module):\n",
    "    def __init__(self, in_channel, depth, stride):\n",
    "        super(bottleneck_IR_SE, self).__init__()\n",
    "        if in_channel == depth:\n",
    "            self.shortcut_layer = MaxPool2d(1, stride)\n",
    "        else:\n",
    "            self.shortcut_layer = Sequential(\n",
    "                Conv2d(in_channel, depth, (1, 1), stride ,bias=False), \n",
    "                BatchNorm2d(depth))\n",
    "        self.res_layer = Sequential(\n",
    "            BatchNorm2d(in_channel),\n",
    "            Conv2d(in_channel, depth, (3,3), (1,1),1 ,bias=False),\n",
    "            PReLU(depth),\n",
    "            Conv2d(depth, depth, (3,3), stride, 1 ,bias=False),\n",
    "            BatchNorm2d(depth),\n",
    "            SEModule(depth,16)\n",
    "            )\n",
    "    def forward(self,x):\n",
    "        shortcut = self.shortcut_layer(x)\n",
    "        res = self.res_layer(x)\n",
    "        return res + shortcut\n",
    "\n",
    "class Bottleneck(namedtuple('Block', ['in_channel', 'depth', 'stride'])):\n",
    "    '''A named tuple describing a ResNet block.'''\n",
    "    \n",
    "def get_block(in_channel, depth, num_units, stride = 2):\n",
    "  return [Bottleneck(in_channel, depth, stride)] + [Bottleneck(depth, depth, 1) for i in range(num_units-1)]\n",
    "\n",
    "def get_blocks(num_layers):\n",
    "    if num_layers == 50:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units = 3),\n",
    "            get_block(in_channel=64, depth=128, num_units=4),\n",
    "            get_block(in_channel=128, depth=256, num_units=14),\n",
    "            get_block(in_channel=256, depth=512, num_units=3)\n",
    "        ]\n",
    "    elif num_layers == 100:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units=3),\n",
    "            get_block(in_channel=64, depth=128, num_units=13),\n",
    "            get_block(in_channel=128, depth=256, num_units=30),\n",
    "            get_block(in_channel=256, depth=512, num_units=3)\n",
    "        ]\n",
    "    elif num_layers == 152:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units=3),\n",
    "            get_block(in_channel=64, depth=128, num_units=8),\n",
    "            get_block(in_channel=128, depth=256, num_units=36),\n",
    "            get_block(in_channel=256, depth=512, num_units=3)\n",
    "        ]\n",
    "    return blocks\n",
    "\n",
    "class Backbone(Module):\n",
    "    def __init__(self, num_layers, drop_ratio, mode='ir'):\n",
    "        super(Backbone, self).__init__()\n",
    "        assert num_layers in [50, 100, 152], 'num_layers should be 50,100, or 152'\n",
    "        assert mode in ['ir', 'ir_se'], 'mode should be ir or ir_se'\n",
    "        blocks = get_blocks(num_layers)\n",
    "        if mode == 'ir':\n",
    "            unit_module = bottleneck_IR\n",
    "        elif mode == 'ir_se':\n",
    "            unit_module = bottleneck_IR_SE\n",
    "        self.input_layer = Sequential(Conv2d(3, 64, (3, 3), 1, 1 ,bias=False), \n",
    "                                      BatchNorm2d(64), \n",
    "                                      PReLU(64))\n",
    "        self.output_layer = Sequential(BatchNorm2d(512), \n",
    "                                       Dropout(drop_ratio),\n",
    "                                       Flatten(),\n",
    "                                       Linear(512 * 7 * 7, 512),\n",
    "                                       BatchNorm1d(512))\n",
    "        modules = []\n",
    "        for block in blocks:\n",
    "            for bottleneck in block:\n",
    "                modules.append(\n",
    "                    unit_module(bottleneck.in_channel,\n",
    "                                bottleneck.depth,\n",
    "                                bottleneck.stride))\n",
    "        self.body = Sequential(*modules)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.body(x)\n",
    "        x = self.output_layer(x)\n",
    "        return l2_norm(x)\n",
    "\n",
    "##################################  MobileFaceNet #############################################################\n",
    "    \n",
    "class Conv_block(Module):\n",
    "    def __init__(self, in_c, out_c, kernel=(1, 1), stride=(1, 1), padding=(0, 0), groups=1):\n",
    "        super(Conv_block, self).__init__()\n",
    "        self.conv = Conv2d(in_c, out_channels=out_c, kernel_size=kernel, groups=groups, stride=stride, padding=padding, bias=False)\n",
    "        self.bn = BatchNorm2d(out_c)\n",
    "        self.prelu = PReLU(out_c)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.prelu(x)\n",
    "        return x\n",
    "\n",
    "class Linear_block(Module):\n",
    "    def __init__(self, in_c, out_c, kernel=(1, 1), stride=(1, 1), padding=(0, 0), groups=1):\n",
    "        super(Linear_block, self).__init__()\n",
    "        self.conv = Conv2d(in_c, out_channels=out_c, kernel_size=kernel, groups=groups, stride=stride, padding=padding, bias=False)\n",
    "        self.bn = BatchNorm2d(out_c)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "class Depth_Wise(Module):\n",
    "     def __init__(self, in_c, out_c, residual = False, kernel=(3, 3), stride=(2, 2), padding=(1, 1), groups=1):\n",
    "        super(Depth_Wise, self).__init__()\n",
    "        self.conv = Conv_block(in_c, out_c=groups, kernel=(1, 1), padding=(0, 0), stride=(1, 1))\n",
    "        self.conv_dw = Conv_block(groups, groups, groups=groups, kernel=kernel, padding=padding, stride=stride)\n",
    "        self.project = Linear_block(groups, out_c, kernel=(1, 1), padding=(0, 0), stride=(1, 1))\n",
    "        self.residual = residual\n",
    "     def forward(self, x):\n",
    "        if self.residual:\n",
    "            short_cut = x\n",
    "        x = self.conv(x)\n",
    "        x = self.conv_dw(x)\n",
    "        x = self.project(x)\n",
    "        if self.residual:\n",
    "            output = short_cut + x\n",
    "        else:\n",
    "            output = x\n",
    "        return output\n",
    "\n",
    "class Residual(Module):\n",
    "    def __init__(self, c, num_block, groups, kernel=(3, 3), stride=(1, 1), padding=(1, 1)):\n",
    "        super(Residual, self).__init__()\n",
    "        modules = []\n",
    "        for _ in range(num_block):\n",
    "            modules.append(Depth_Wise(c, c, residual=True, kernel=kernel, padding=padding, stride=stride, groups=groups))\n",
    "        self.model = Sequential(*modules)\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class MobileFaceNet(Module):\n",
    "    def __init__(self, embedding_size):\n",
    "        super(MobileFaceNet, self).__init__()\n",
    "        self.conv1 = Conv_block(3, 64, kernel=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.conv2_dw = Conv_block(64, 64, kernel=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
    "        self.conv_23 = Depth_Wise(64, 64, kernel=(3, 3), stride=(2, 2), padding=(1, 1), groups=128)\n",
    "        self.conv_3 = Residual(64, num_block=4, groups=128, kernel=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.conv_34 = Depth_Wise(64, 128, kernel=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
    "        self.conv_4 = Residual(128, num_block=6, groups=256, kernel=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.conv_45 = Depth_Wise(128, 128, kernel=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)\n",
    "        self.conv_5 = Residual(128, num_block=2, groups=256, kernel=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.conv_6_sep = Conv_block(128, 512, kernel=(1, 1), stride=(1, 1), padding=(0, 0))\n",
    "        self.conv_6_dw = Linear_block(512, 512, groups=512, kernel=(7,7), stride=(1, 1), padding=(0, 0))\n",
    "        self.conv_6_flatten = Flatten()\n",
    "        self.linear = Linear(512, embedding_size, bias=False)\n",
    "        self.bn = BatchNorm1d(embedding_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "\n",
    "        out = self.conv2_dw(out)\n",
    "\n",
    "        out = self.conv_23(out)\n",
    "\n",
    "        out = self.conv_3(out)\n",
    "        \n",
    "        out = self.conv_34(out)\n",
    "\n",
    "        out = self.conv_4(out)\n",
    "\n",
    "        out = self.conv_45(out)\n",
    "\n",
    "        out = self.conv_5(out)\n",
    "\n",
    "        out = self.conv_6_sep(out)\n",
    "\n",
    "        out = self.conv_6_dw(out)\n",
    "\n",
    "        out = self.conv_6_flatten(out)\n",
    "\n",
    "        out = self.linear(out)\n",
    "\n",
    "        out = self.bn(out)\n",
    "        return l2_norm(out)\n",
    "\n",
    "##################################  Arcface head #############################################################\n",
    "\n",
    "class Arcface(Module):\n",
    "    # implementation of additive margin softmax loss in https://arxiv.org/abs/1801.05599    \n",
    "    def __init__(self, embedding_size=512, classnum=51332,  s=64., m=0.5):\n",
    "        super(Arcface, self).__init__()\n",
    "        self.classnum = classnum\n",
    "        self.kernel = Parameter(torch.Tensor(embedding_size,classnum))\n",
    "        # initial kernel\n",
    "        self.kernel.data.uniform_(-1, 1).renorm_(2,1,1e-5).mul_(1e5)\n",
    "        self.m = m # the margin value, default is 0.5\n",
    "        self.s = s # scalar value default is 64, see normface https://arxiv.org/abs/1704.06369\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.mm = self.sin_m * m  # issue 1\n",
    "        self.threshold = math.cos(math.pi - m)\n",
    "    def forward(self, embbedings, label):\n",
    "        # weights norm\n",
    "        nB = len(embbedings)\n",
    "        kernel_norm = l2_norm(self.kernel,axis=0)\n",
    "        # cos(theta+m)\n",
    "        cos_theta = torch.mm(embbedings,kernel_norm)\n",
    "#         output = torch.mm(embbedings,kernel_norm)\n",
    "        cos_theta = cos_theta.clamp(-1,1) # for numerical stability\n",
    "        cos_theta_2 = torch.pow(cos_theta, 2)\n",
    "        sin_theta_2 = 1 - cos_theta_2\n",
    "        sin_theta = torch.sqrt(sin_theta_2)\n",
    "        cos_theta_m = (cos_theta * self.cos_m - sin_theta * self.sin_m)\n",
    "        # this condition controls the theta+m should in range [0, pi]\n",
    "        #      0<=theta+m<=pi\n",
    "        #     -m<=theta<=pi-m\n",
    "        cond_v = cos_theta - self.threshold\n",
    "        cond_mask = cond_v <= 0\n",
    "        keep_val = (cos_theta - self.mm) # when theta not in [0,pi], use cosface instead\n",
    "        cos_theta_m[cond_mask] = keep_val[cond_mask]\n",
    "        output = cos_theta * 1.0 # a little bit hacky way to prevent in_place operation on cos_theta\n",
    "        idx_ = torch.arange(0, nB, dtype=torch.long)\n",
    "        output[idx_, label] = cos_theta_m[idx_, label]\n",
    "        output *= self.s # scale up in order to make softmax work, first introduced in normface\n",
    "        return output\n",
    "\n",
    "##################################  Cosface head #############################################################    \n",
    "    \n",
    "class Am_softmax(Module):\n",
    "    # implementation of additive margin softmax loss in https://arxiv.org/abs/1801.05599    \n",
    "    def __init__(self,embedding_size=512,classnum=51332):\n",
    "        super(Am_softmax, self).__init__()\n",
    "        self.classnum = classnum\n",
    "        self.kernel = Parameter(torch.Tensor(embedding_size,classnum))\n",
    "        # initial kernel\n",
    "        self.kernel.data.uniform_(-1, 1).renorm_(2,1,1e-5).mul_(1e5)\n",
    "        self.m = 0.35 # additive margin recommended by the paper\n",
    "        self.s = 30. # see normface https://arxiv.org/abs/1704.06369\n",
    "    def forward(self,embbedings,label):\n",
    "        kernel_norm = l2_norm(self.kernel,axis=0)\n",
    "        cos_theta = torch.mm(embbedings,kernel_norm)\n",
    "        cos_theta = cos_theta.clamp(-1,1) # for numerical stability\n",
    "        phi = cos_theta - self.m\n",
    "        label = label.view(-1,1) #size=(B,1)\n",
    "        index = cos_theta.data * 0.0 #size=(B,Classnum)\n",
    "        index.scatter_(1,label.data.view(-1,1),1)\n",
    "        index = index.byte()\n",
    "        output = cos_theta * 1.0\n",
    "        output[index] = phi[index] #only change the correct predicted output\n",
    "        output *= self.s # scale up in order to make softmax work, first introduced in normface\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vrifacions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T05:53:26.755869Z",
     "start_time": "2020-07-17T05:53:26.727874Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(embeddings, actual_issame, nrof_folds=10, pca=0):\n",
    "    # Calculate evaluation metrics\n",
    "    thresholds = np.arange(0, 4, 0.01)\n",
    "    embeddings1 = embeddings[0::2]\n",
    "    embeddings2 = embeddings[1::2]\n",
    "    tpr, fpr, accuracy, best_thresholds = calculate_roc(thresholds, embeddings1, embeddings2,\n",
    "                                       np.asarray(actual_issame), nrof_folds=nrof_folds, pca=pca)\n",
    "#     thresholds = np.arange(0, 4, 0.001)\n",
    "#     val, val_std, far = calculate_val(thresholds, embeddings1, embeddings2,\n",
    "#                                       np.asarray(actual_issame), 1e-3, nrof_folds=nrof_folds)\n",
    "#     return tpr, fpr, accuracy, best_thresholds, val, val_std, far\n",
    "    return tpr, fpr, accuracy, best_thresholds\n",
    "\n",
    "def calculate_roc(thresholds, embeddings1, embeddings2, actual_issame, nrof_folds=10, pca=0):\n",
    "    assert (embeddings1.shape[0] == embeddings2.shape[0])\n",
    "    assert (embeddings1.shape[1] == embeddings2.shape[1])\n",
    "    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
    "    nrof_thresholds = len(thresholds)\n",
    "    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\n",
    "\n",
    "    tprs = np.zeros((nrof_folds, nrof_thresholds))\n",
    "    fprs = np.zeros((nrof_folds, nrof_thresholds))\n",
    "    accuracy = np.zeros((nrof_folds))\n",
    "    best_thresholds = np.zeros((nrof_folds))\n",
    "    indices = np.arange(nrof_pairs)\n",
    "    # print('pca', pca)\n",
    "\n",
    "    if pca == 0:\n",
    "        diff = np.subtract(embeddings1, embeddings2)\n",
    "        dist = np.sum(np.square(diff), 1)\n",
    "\n",
    "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
    "        # print('train_set', train_set)\n",
    "        # print('test_set', test_set)\n",
    "        if pca > 0:\n",
    "            print('doing pca on', fold_idx)\n",
    "            embed1_train = embeddings1[train_set]\n",
    "            embed2_train = embeddings2[train_set]\n",
    "            _embed_train = np.concatenate((embed1_train, embed2_train), axis=0)\n",
    "            # print(_embed_train.shape)\n",
    "            pca_model = PCA(n_components=pca)\n",
    "            pca_model.fit(_embed_train)\n",
    "            embed1 = pca_model.transform(embeddings1)\n",
    "            embed2 = pca_model.transform(embeddings2)\n",
    "            embed1 = sklearn.preprocessing.normalize(embed1)\n",
    "            embed2 = sklearn.preprocessing.normalize(embed2)\n",
    "            # print(embed1.shape, embed2.shape)\n",
    "            diff = np.subtract(embed1, embed2)\n",
    "            dist = np.sum(np.square(diff), 1)\n",
    "\n",
    "        # Find the best threshold for the fold\n",
    "        acc_train = np.zeros((nrof_thresholds))\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            _, _, acc_train[threshold_idx] = calculate_accuracy(threshold, dist[train_set], actual_issame[train_set])\n",
    "        best_threshold_index = np.argmax(acc_train)\n",
    "#         print('best_threshold_index', best_threshold_index, acc_train[best_threshold_index])\n",
    "        best_thresholds[fold_idx] = thresholds[best_threshold_index]\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            tprs[fold_idx, threshold_idx], fprs[fold_idx, threshold_idx], _ = calculate_accuracy(threshold,\n",
    "                                                                                                 dist[test_set],\n",
    "                                                                                                 actual_issame[\n",
    "                                                                                                     test_set])\n",
    "        _, _, accuracy[fold_idx] = calculate_accuracy(thresholds[best_threshold_index], dist[test_set],\n",
    "                                                      actual_issame[test_set])\n",
    "\n",
    "    tpr = np.mean(tprs, 0)\n",
    "    fpr = np.mean(fprs, 0)\n",
    "    return tpr, fpr, accuracy, best_thresholds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learner.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T05:56:10.753082Z",
     "start_time": "2020-07-17T05:56:10.608081Z"
    }
   },
   "outputs": [],
   "source": [
    "class face_learner(object):\n",
    "    def __init__(self, conf, inference=False):\n",
    "        print(conf)\n",
    "        if conf.use_mobilfacenet:\n",
    "            self.model = MobileFaceNet(conf.embedding_size).to(conf.device)\n",
    "            print('MobileFaceNet model generated')\n",
    "        else:\n",
    "            self.model = Backbone(conf.net_depth, conf.drop_ratio, conf.net_mode).to(conf.device)\n",
    "            print('{}_{} model generated'.format(conf.net_mode, conf.net_depth))\n",
    "        \n",
    "        if not inference:\n",
    "            self.milestones = conf.milestones\n",
    "            self.loader, self.class_num = get_train_loader(conf)        \n",
    "\n",
    "            self.writer = SummaryWriter(conf.log_path)\n",
    "            self.step = 0\n",
    "            self.head = Arcface(embedding_size=conf.embedding_size, classnum=self.class_num).to(conf.device)\n",
    "\n",
    "            print('two model heads generated')\n",
    "\n",
    "            paras_only_bn, paras_wo_bn = separate_bn_paras(self.model)\n",
    "        \n",
    "            \n",
    "            if conf.use_mobilfacenet:\n",
    "                self.optimizer = optim.SGD([\n",
    "                                    {'params': paras_wo_bn[:-1], 'weight_decay': 4e-5},\n",
    "                                    {'params': [paras_wo_bn[-1]] + [self.head.kernel], 'weight_decay': 4e-4},\n",
    "                                    {'params': paras_only_bn}\n",
    "                                ], lr = conf.lr, momentum = conf.momentum)\n",
    "            else:\n",
    "                self.optimizer = optim.SGD([\n",
    "                                    {'params': paras_wo_bn + [self.head.kernel], 'weight_decay': 5e-4},\n",
    "#                                     {'params': paras_only_bn}\n",
    "                                ], lr = conf.lr, momentum = conf.momentum)\n",
    "            print(self.optimizer)\n",
    "#             self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, patience=40, verbose=True)\n",
    "\n",
    "            print('optimizers generated')    \n",
    "            self.board_loss_every = len(self.loader)//100\n",
    "            self.evaluate_every = len(self.loader)//10\n",
    "            self.save_every = len(self.loader)//5\n",
    "            self.agedb_30, self.cfp_fp, self.lfw, self.agedb_30_issame, self.cfp_fp_issame, self.lfw_issame = get_val_data(self.loader.dataset.root.parent)\n",
    "        else:\n",
    "            self.threshold = conf.threshold\n",
    "    \n",
    "    def save_state(self, conf, accuracy, to_save_folder=False, extra=None, model_only=False):\n",
    "        if to_save_folder:\n",
    "            save_path = conf.save_path\n",
    "        else:\n",
    "            save_path = conf.model_path\n",
    "        torch.save(\n",
    "            self.model.state_dict(), save_path /\n",
    "            ('model_{}_accuracy:{}_step:{}_{}.pth'.format(get_time(), accuracy, self.step, extra)))\n",
    "        if not model_only:\n",
    "            torch.save(\n",
    "                self.head.state_dict(), save_path /\n",
    "                ('head_{}_accuracy:{}_step:{}_{}.pth'.format(get_time(), accuracy, self.step, extra)))\n",
    "            torch.save(\n",
    "                self.optimizer.state_dict(), save_path /\n",
    "                ('optimizer_{}_accuracy:{}_step:{}_{}.pth'.format(get_time(), accuracy, self.step, extra)))\n",
    "    \n",
    "    def load_state(self, conf, fixed_str, from_save_folder=False, model_only=False):\n",
    "        if from_save_folder:\n",
    "            save_path = conf.save_path\n",
    "        else:\n",
    "            save_path = conf.model_path            \n",
    "        self.model.load_state_dict(torch.load(save_path/'model_{}'.format(fixed_str)))\n",
    "        if not model_only:\n",
    "            self.head.load_state_dict(torch.load(save_path/'head_{}'.format(fixed_str)))\n",
    "            self.optimizer.load_state_dict(torch.load(save_path/'optimizer_{}'.format(fixed_str)))\n",
    "        \n",
    "    def board_val(self, db_name, accuracy, best_threshold, roc_curve_tensor):\n",
    "        self.writer.add_scalar('{}_accuracy'.format(db_name), accuracy, self.step)\n",
    "        self.writer.add_scalar('{}_best_threshold'.format(db_name), best_threshold, self.step)\n",
    "        self.writer.add_image('{}_roc_curve'.format(db_name), roc_curve_tensor, self.step)\n",
    "#         self.writer.add_scalar('{}_val:true accept ratio'.format(db_name), val, self.step)\n",
    "#         self.writer.add_scalar('{}_val_std'.format(db_name), val_std, self.step)\n",
    "#         self.writer.add_scalar('{}_far:False Acceptance Ratio'.format(db_name), far, self.step)\n",
    "        \n",
    "    def evaluate(self, conf, carray, issame, nrof_folds = 5, tta = False):\n",
    "        self.model.eval()\n",
    "        idx = 0\n",
    "        embeddings = np.zeros([len(carray), conf.embedding_size])\n",
    "        with torch.no_grad():\n",
    "            while idx + conf.batch_size <= len(carray):\n",
    "                batch = torch.tensor(carray[idx:idx + conf.batch_size])\n",
    "                if tta:\n",
    "                    fliped = hflip_batch(batch)\n",
    "                    emb_batch = self.model(batch.to(conf.device)) + self.model(fliped.to(conf.device))\n",
    "                    embeddings[idx:idx + conf.batch_size] = l2_norm(emb_batch)\n",
    "                else:\n",
    "                    embeddings[idx:idx + conf.batch_size] = self.model(batch.to(conf.device)).cpu()\n",
    "                idx += conf.batch_size\n",
    "            if idx < len(carray):\n",
    "                batch = torch.tensor(carray[idx:])            \n",
    "                if tta:\n",
    "                    fliped = hflip_batch(batch)\n",
    "                    emb_batch = self.model(batch.to(conf.device)) + self.model(fliped.to(conf.device))\n",
    "                    embeddings[idx:] = l2_norm(emb_batch)\n",
    "                else:\n",
    "                    embeddings[idx:] = self.model(batch.to(conf.device)).cpu()\n",
    "        tpr, fpr, accuracy, best_thresholds = evaluate(embeddings, issame, nrof_folds)\n",
    "        buf = gen_plot(fpr, tpr)\n",
    "        roc_curve = Image.open(buf)\n",
    "        roc_curve_tensor = trans.ToTensor()(roc_curve)\n",
    "        return accuracy.mean(), best_thresholds.mean(), roc_curve_tensor\n",
    "    \n",
    "    def find_lr(self,\n",
    "                conf,\n",
    "                init_value=1e-8,\n",
    "                final_value=10.,\n",
    "                beta=0.98,\n",
    "                bloding_scale=3.,\n",
    "                num=None):\n",
    "        if not num:\n",
    "            num = len(self.loader)\n",
    "        mult = (final_value / init_value)**(1 / num)\n",
    "        lr = init_value\n",
    "        for params in self.optimizer.param_groups:\n",
    "            params['lr'] = lr\n",
    "        self.model.train()\n",
    "        avg_loss = 0.\n",
    "        best_loss = 0.\n",
    "        batch_num = 0\n",
    "        losses = []\n",
    "        log_lrs = []\n",
    "        for i, (imgs, labels) in tqdm(enumerate(self.loader), total=num):\n",
    "\n",
    "            imgs = imgs.to(conf.device)\n",
    "            labels = labels.to(conf.device)\n",
    "            batch_num += 1          \n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            embeddings = self.model(imgs)\n",
    "            thetas = self.head(embeddings, labels)\n",
    "            loss = conf.ce_loss(thetas, labels)          \n",
    "          \n",
    "            #Compute the smoothed loss\n",
    "            avg_loss = beta * avg_loss + (1 - beta) * loss.item()\n",
    "            self.writer.add_scalar('avg_loss', avg_loss, batch_num)\n",
    "            smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
    "            self.writer.add_scalar('smoothed_loss', smoothed_loss,batch_num)\n",
    "            #Stop if the loss is exploding\n",
    "            if batch_num > 1 and smoothed_loss > bloding_scale * best_loss:\n",
    "                print('exited with best_loss at {}'.format(best_loss))\n",
    "                plt.plot(log_lrs[10:-5], losses[10:-5])\n",
    "                return log_lrs, losses\n",
    "            #Record the best loss\n",
    "            if smoothed_loss < best_loss or batch_num == 1:\n",
    "                best_loss = smoothed_loss\n",
    "            #Store the values\n",
    "            losses.append(smoothed_loss)\n",
    "            log_lrs.append(math.log10(lr))\n",
    "            self.writer.add_scalar('log_lr', math.log10(lr), batch_num)\n",
    "            #Do the SGD step\n",
    "            #Update the lr for the next step\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            lr *= mult\n",
    "            for params in self.optimizer.param_groups:\n",
    "                params['lr'] = lr\n",
    "            if batch_num > num:\n",
    "                plt.plot(log_lrs[10:-5], losses[10:-5])\n",
    "                return log_lrs, losses    \n",
    "\n",
    "    def train(self, conf, epochs):\n",
    "        self.model.train()\n",
    "        running_loss = 0.            \n",
    "        for e in range(epochs):\n",
    "            print('epoch {} started'.format(e))\n",
    "            if e == self.milestones[0]:\n",
    "                self.schedule_lr()\n",
    "            if e == self.milestones[1]:\n",
    "                self.schedule_lr()      \n",
    "            if e == self.milestones[2]:\n",
    "                self.schedule_lr()                                 \n",
    "            for imgs, labels in tqdm(iter(self.loader)):\n",
    "                imgs = imgs.to(conf.device)\n",
    "                labels = labels.to(conf.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                embeddings = self.model(imgs)\n",
    "                thetas = self.head(embeddings, labels)\n",
    "                loss = conf.ce_loss(thetas, labels)\n",
    "                loss.backward()\n",
    "                running_loss += loss.item()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                if self.step % self.board_loss_every == 0 and self.step != 0:\n",
    "                    loss_board = running_loss / self.board_loss_every\n",
    "                    self.writer.add_scalar('train_loss', loss_board, self.step)\n",
    "                    running_loss = 0.\n",
    "                \n",
    "                if self.step % self.evaluate_every == 0 and self.step != 0:\n",
    "                    accuracy, best_threshold, roc_curve_tensor = self.evaluate(conf, self.agedb_30, self.agedb_30_issame)\n",
    "                    self.board_val('agedb_30', accuracy, best_threshold, roc_curve_tensor)\n",
    "                    accuracy, best_threshold, roc_curve_tensor = self.evaluate(conf, self.lfw, self.lfw_issame)\n",
    "                    self.board_val('lfw', accuracy, best_threshold, roc_curve_tensor)\n",
    "                    accuracy, best_threshold, roc_curve_tensor = self.evaluate(conf, self.cfp_fp, self.cfp_fp_issame)\n",
    "                    self.board_val('cfp_fp', accuracy, best_threshold, roc_curve_tensor)\n",
    "                    self.model.train()\n",
    "                if self.step % self.save_every == 0 and self.step != 0:\n",
    "                    self.save_state(conf, accuracy)\n",
    "                    \n",
    "                self.step += 1\n",
    "                \n",
    "        self.save_state(conf, accuracy, to_save_folder=True, extra='final')\n",
    "\n",
    "    def schedule_lr(self):\n",
    "        for params in self.optimizer.param_groups:                 \n",
    "            params['lr'] /= 10\n",
    "        print(self.optimizer)\n",
    "    \n",
    "    def infer(self, conf, faces, target_embs, tta=False):\n",
    "        '''\n",
    "        faces : list of PIL Image\n",
    "        target_embs : [n, 512] computed embeddings of faces in facebank\n",
    "        names : recorded names of faces in facebank\n",
    "        tta : test time augmentation (hfilp, that's all)\n",
    "        '''\n",
    "        embs = []\n",
    "        for img in faces:\n",
    "            if tta:\n",
    "                mirror = trans.functional.hflip(img)\n",
    "                emb = self.model(conf.test_transform(img).to(conf.device).unsqueeze(0))\n",
    "                emb_mirror = self.model(conf.test_transform(mirror).to(conf.device).unsqueeze(0))\n",
    "                embs.append(l2_norm(emb + emb_mirror))\n",
    "            else:                        \n",
    "                embs.append(self.model(conf.test_transform(img).to(conf.device).unsqueeze(0)))\n",
    "        source_embs = torch.cat(embs)\n",
    "        \n",
    "        diff = source_embs.unsqueeze(-1) - target_embs.transpose(1,0).unsqueeze(0)\n",
    "        dist = torch.sum(torch.pow(diff, 2), dim=1)\n",
    "        minimum, min_idx = torch.min(dist, dim=1)\n",
    "        min_idx[minimum > self.threshold] = -1 # if no match, set idx to -1\n",
    "        return min_idx, minimum               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T05:58:00.296996Z",
     "start_time": "2020-07-17T05:58:00.286987Z"
    }
   },
   "outputs": [],
   "source": [
    "args = edict()\n",
    "\n",
    "args.epochs =20\n",
    "args.net_mode = 'ir_se'  #\"which network, [ir, ir_se, mobilefacenet]\"\n",
    "args.net_depth = 50 # \"how many layers [50,100,152]\"\n",
    "args.lr = 1e-3\n",
    "args.batch_size = 96\n",
    "args.num_workers = 3\n",
    "args.data_mode = 'vgg' # use which database, [vgg, ms1m, emore, concat]\"\n",
    "\n",
    "conf = get_config()\n",
    "\n",
    "if args.net_mode == 'mobilefacenet':\n",
    "        conf.use_mobilfacenet = True\n",
    "else:\n",
    "    conf.net_mode = args.net_mode\n",
    "    conf.net_depth = args.net_depth    \n",
    "\n",
    "    \n",
    "conf.lr = args.lr\n",
    "conf.batch_size = args.batch_size\n",
    "conf.num_workers = args.num_workers\n",
    "conf.data_mode = args.data_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T05:58:01.169987Z",
     "start_time": "2020-07-17T05:58:00.718990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_path': WindowsPath('../data'), 'work_path': WindowsPath('work_space'), 'model_path': WindowsPath('work_space/models'), 'log_path': WindowsPath('work_space/log'), 'save_path': WindowsPath('work_space/save'), 'input_size': [112, 112], 'embedding_size': 512, 'use_mobilfacenet': False, 'net_depth': 50, 'drop_ratio': 0.6, 'net_mode': 'ir_se', 'device': device(type='cpu'), 'test_transform': Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
      "), 'data_mode': 'vgg', 'vgg_folder': WindowsPath('../data/faces_vgg2_112x112'), 'ms1m_folder': WindowsPath('../data/faces_ms1m_112x112'), 'emore_folder': WindowsPath('../data/faces_emore'), 'batch_size': 96, 'lr': 0.001, 'milestones': [12, 15, 18], 'momentum': 0.9, 'pin_memory': True, 'num_workers': 3, 'ce_loss': CrossEntropyLoss()}\n",
      "ir_se_50 model generated\n",
      "class_num 3\n",
      "vgg loader generated\n",
      "two model heads generated\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.001\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0005\n",
      ")\n",
      "optimizers generated\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\data\\\\faces_vgg2_112x112\\\\agedb_30\\\\meta\\\\sizes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-0dc0e76f91a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlearner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_learner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlearner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-70-68df8ceed99c>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, conf, inference)\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_every\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_every\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magedb_30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcfp_fp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlfw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magedb_30_issame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcfp_fp_issame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlfw_issame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_val_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-75-2161253f7300>\u001b[0m in \u001b[0;36mget_val_data\u001b[1;34m(data_path)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_val_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0magedb_30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magedb_30_issame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_val_pair\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'agedb_30'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[0mcfp_fp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcfp_fp_issame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_val_pair\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cfp_fp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mlfw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlfw_issame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_val_pair\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lfw'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-75-2161253f7300>\u001b[0m in \u001b[0;36mget_val_pair\u001b[1;34m(path, name)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_val_pair\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mcarray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbcolz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrootdir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[0missame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;34m'{}_list.npy'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0missame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mbcolz/carray_ext.pyx\u001b[0m in \u001b[0;36mbcolz.carray_ext.carray.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mbcolz/carray_ext.pyx\u001b[0m in \u001b[0;36mbcolz.carray_ext.carray._read_meta\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\data\\\\faces_vgg2_112x112\\\\agedb_30\\\\meta\\\\sizes'"
     ]
    }
   ],
   "source": [
    "learner = face_learner(conf)\n",
    "\n",
    "learner.train(conf, args.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "373.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
