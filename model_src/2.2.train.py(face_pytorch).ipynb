{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train.py(face_pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:27:58.006862Z",
     "start_time": "2020-07-18T13:27:57.662879Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "from torch.nn import DataParallel\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import argparse\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from easydict import EasyDict\n",
    "from torch import nn\n",
    "import math\n",
    "from torch import nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "import visdom\n",
    "import time\n",
    "import logging\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import scipy.io\n",
    "import json\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mobilefacenet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:17:21.438614Z",
     "start_time": "2020-07-18T13:17:21.393619Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-537395905dd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m ]\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mBottleNeck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpansion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBottleNeck\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# from backbone.mobilefacenet import MobileFaceNet\n",
    "MobileFaceNet_BottleNeck_Setting = [\n",
    "    # t, c , n ,s\n",
    "    [2, 64, 5, 2],\n",
    "    [4, 128, 1, 2],\n",
    "    [2, 128, 6, 1],\n",
    "    [4, 128, 1, 2],\n",
    "    [2, 128, 2, 1]\n",
    "]\n",
    "\n",
    "class BottleNeck(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expansion):\n",
    "        super(BottleNeck, self).__init__()\n",
    "        self.connect = stride == 1 and inp == oup\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            # 1*1 conv\n",
    "            nn.Conv2d(inp, inp * expansion, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(inp * expansion),\n",
    "            nn.PReLU(inp * expansion),\n",
    "\n",
    "            # 3*3 depth wise conv\n",
    "            nn.Conv2d(inp * expansion, inp * expansion, 3, stride, 1, groups=inp * expansion, bias=False),\n",
    "            nn.BatchNorm2d(inp * expansion),\n",
    "            nn.PReLU(inp * expansion),\n",
    "\n",
    "            # 1*1 conv\n",
    "            nn.Conv2d(inp * expansion, oup, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(oup),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, inp, oup, k, s, p, dw=False, linear=False):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.linear = linear\n",
    "        if dw:\n",
    "            self.conv = nn.Conv2d(inp, oup, k, s, p, groups=inp, bias=False)\n",
    "        else:\n",
    "            self.conv = nn.Conv2d(inp, oup, k, s, p, bias=False)\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(oup)\n",
    "        if not linear:\n",
    "            self.prelu = nn.PReLU(oup)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        if self.linear:\n",
    "            return x\n",
    "        else:\n",
    "            return self.prelu(x)\n",
    "\n",
    "\n",
    "class MobileFaceNet(nn.Module):\n",
    "    def __init__(self, feature_dim=128, bottleneck_setting=MobileFaceNet_BottleNeck_Setting):\n",
    "        super(MobileFaceNet, self).__init__()\n",
    "        self.conv1 = ConvBlock(3, 64, 3, 2, 1)\n",
    "        self.dw_conv1 = ConvBlock(64, 64, 3, 1, 1, dw=True)\n",
    "\n",
    "        self.cur_channel = 64\n",
    "        block = BottleNeck\n",
    "        self.blocks = self._make_layer(block, bottleneck_setting)\n",
    "\n",
    "        self.conv2 = ConvBlock(128, 512, 1, 1, 0)\n",
    "        self.linear7 = ConvBlock(512, 512, 7, 1, 0, dw=True, linear=True)\n",
    "        self.linear1 = ConvBlock(512, feature_dim, 1, 1, 0, linear=True)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, setting):\n",
    "        layers = []\n",
    "        for t, c, n, s in setting:\n",
    "            for i in range(n):\n",
    "                if i == 0:\n",
    "                    layers.append(block(self.cur_channel, c, s, t))\n",
    "                else:\n",
    "                    layers.append(block(self.cur_channel, c, 1, t))\n",
    "                self.cur_channel = c\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.dw_conv1(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.linear7(x)\n",
    "        x = self.linear1(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input = torch.Tensor(2, 3, 112, 112)\n",
    "    net = MobileFaceNet()\n",
    "    print(net)\n",
    "\n",
    "    x = net(input)\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cbam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:18:13.791072Z",
     "start_time": "2020-07-18T13:18:13.683075Z"
    }
   },
   "outputs": [],
   "source": [
    "# from backbone.cbam import CBAMResNet\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "    '''Squeeze and Excitation Module'''\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1, padding=0, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1, padding=0, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return input * x\n",
    "\n",
    "class CAModule(nn.Module):\n",
    "    '''Channel Attention Module'''\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(CAModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.shared_mlp = nn.Sequential(nn.Conv2d(channels, channels // reduction, kernel_size=1, padding=0, bias=False),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.Conv2d(channels // reduction, channels, kernel_size=1, padding=0, bias=False))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        avg_pool = self.avg_pool(x)\n",
    "        max_pool = self.max_pool(x)\n",
    "        x = self.shared_mlp(avg_pool) + self.shared_mlp(max_pool)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return input * x\n",
    "\n",
    "class SAModule(nn.Module):\n",
    "    '''Spatial Attention Module'''\n",
    "    def __init__(self):\n",
    "        super(SAModule, self).__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        avg_c = torch.mean(x, 1, True)\n",
    "        max_c, _ = torch.max(x, 1, True)\n",
    "        x = torch.cat((avg_c, max_c), 1)\n",
    "        x = self.conv(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return input * x\n",
    "\n",
    "class BottleNeck_IR(nn.Module):\n",
    "    '''Improved Residual Bottlenecks'''\n",
    "    def __init__(self, in_channel, out_channel, stride, dim_match):\n",
    "        super(BottleNeck_IR, self).__init__()\n",
    "        self.res_layer = nn.Sequential(nn.BatchNorm2d(in_channel),\n",
    "                                       nn.Conv2d(in_channel, out_channel, (3, 3), 1, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       nn.PReLU(out_channel),\n",
    "                                       nn.Conv2d(out_channel, out_channel, (3, 3), stride, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel))\n",
    "        if dim_match:\n",
    "            self.shortcut_layer = None\n",
    "        else:\n",
    "            self.shortcut_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, out_channel, kernel_size=(1, 1), stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        if self.shortcut_layer is not None:\n",
    "            shortcut = self.shortcut_layer(x)\n",
    "\n",
    "        return shortcut + res\n",
    "\n",
    "class BottleNeck_IR_SE(nn.Module):\n",
    "    '''Improved Residual Bottlenecks with Squeeze and Excitation Module'''\n",
    "    def __init__(self, in_channel, out_channel, stride, dim_match):\n",
    "        super(BottleNeck_IR_SE, self).__init__()\n",
    "        self.res_layer = nn.Sequential(nn.BatchNorm2d(in_channel),\n",
    "                                       nn.Conv2d(in_channel, out_channel, (3, 3), 1, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       nn.PReLU(out_channel),\n",
    "                                       nn.Conv2d(out_channel, out_channel, (3, 3), stride, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       SEModule(out_channel, 16))\n",
    "        if dim_match:\n",
    "            self.shortcut_layer = None\n",
    "        else:\n",
    "            self.shortcut_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, out_channel, kernel_size=(1, 1), stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        if self.shortcut_layer is not None:\n",
    "            shortcut = self.shortcut_layer(x)\n",
    "\n",
    "        return shortcut + res\n",
    "\n",
    "class BottleNeck_IR_CAM(nn.Module):\n",
    "    '''Improved Residual Bottlenecks with Channel Attention Module'''\n",
    "    def __init__(self, in_channel, out_channel, stride, dim_match):\n",
    "        super(BottleNeck_IR_CAM, self).__init__()\n",
    "        self.res_layer = nn.Sequential(nn.BatchNorm2d(in_channel),\n",
    "                                       nn.Conv2d(in_channel, out_channel, (3, 3), 1, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       nn.PReLU(out_channel),\n",
    "                                       nn.Conv2d(out_channel, out_channel, (3, 3), stride, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       CAModule(out_channel, 16))\n",
    "        if dim_match:\n",
    "            self.shortcut_layer = None\n",
    "        else:\n",
    "            self.shortcut_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, out_channel, kernel_size=(1, 1), stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        if self.shortcut_layer is not None:\n",
    "            shortcut = self.shortcut_layer(x)\n",
    "\n",
    "        return shortcut + res\n",
    "\n",
    "class BottleNeck_IR_SAM(nn.Module):\n",
    "    '''Improved Residual Bottlenecks with Spatial Attention Module'''\n",
    "    def __init__(self, in_channel, out_channel, stride, dim_match):\n",
    "        super(BottleNeck_IR_SAM, self).__init__()\n",
    "        self.res_layer = nn.Sequential(nn.BatchNorm2d(in_channel),\n",
    "                                       nn.Conv2d(in_channel, out_channel, (3, 3), 1, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       nn.PReLU(out_channel),\n",
    "                                       nn.Conv2d(out_channel, out_channel, (3, 3), stride, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       SAModule())\n",
    "        if dim_match:\n",
    "            self.shortcut_layer = None\n",
    "        else:\n",
    "            self.shortcut_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, out_channel, kernel_size=(1, 1), stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        if self.shortcut_layer is not None:\n",
    "            shortcut = self.shortcut_layer(x)\n",
    "\n",
    "        return shortcut + res\n",
    "\n",
    "class BottleNeck_IR_CBAM(nn.Module):\n",
    "    '''Improved Residual Bottleneck with Channel Attention Module and Spatial Attention Module'''\n",
    "    def __init__(self, in_channel, out_channel, stride, dim_match):\n",
    "        super(BottleNeck_IR_CBAM, self).__init__()\n",
    "        self.res_layer = nn.Sequential(nn.BatchNorm2d(in_channel),\n",
    "                                       nn.Conv2d(in_channel, out_channel, (3, 3), 1, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       nn.PReLU(out_channel),\n",
    "                                       nn.Conv2d(out_channel, out_channel, (3, 3), stride, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       CAModule(out_channel, 16),\n",
    "                                       SAModule()\n",
    "                                       )\n",
    "        if dim_match:\n",
    "            self.shortcut_layer = None\n",
    "        else:\n",
    "            self.shortcut_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, out_channel, kernel_size=(1, 1), stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        if self.shortcut_layer is not None:\n",
    "            shortcut = self.shortcut_layer(x)\n",
    "\n",
    "        return shortcut + res\n",
    "\n",
    "\n",
    "filter_list = [64, 64, 128, 256, 512]\n",
    "def get_layers(num_layers):\n",
    "    if num_layers == 50:\n",
    "        return [3, 4, 14, 3]\n",
    "    elif num_layers == 100:\n",
    "        return [3, 13, 30, 3]\n",
    "    elif num_layers == 152:\n",
    "        return [3, 8, 36, 3]\n",
    "\n",
    "class CBAMResNet(nn.Module):\n",
    "    def __init__(self, num_layers, feature_dim=512, drop_ratio=0.4, mode='ir',filter_list=filter_list):\n",
    "        super(CBAMResNet, self).__init__()\n",
    "        assert num_layers in [50, 100, 152], 'num_layers should be 50, 100 or 152'\n",
    "        assert mode in ['ir', 'ir_se', 'ir_cam', 'ir_sam', 'ir_cbam'], 'mode should be ir, ir_se, ir_cam, ir_sam or ir_cbam'\n",
    "        layers = get_layers(num_layers)\n",
    "        if mode == 'ir':\n",
    "            block = BottleNeck_IR\n",
    "        elif mode == 'ir_se':\n",
    "            block = BottleNeck_IR_SE\n",
    "        elif mode == 'ir_cam':\n",
    "            block = BottleNeck_IR_CAM\n",
    "        elif mode == 'ir_sam':\n",
    "            block = BottleNeck_IR_SAM\n",
    "        elif mode == 'ir_cbam':\n",
    "            block = BottleNeck_IR_CBAM\n",
    "\n",
    "        self.input_layer = nn.Sequential(nn.Conv2d(3, 64, (3, 3), stride=1, padding=1, bias=False),\n",
    "                                         nn.BatchNorm2d(64),\n",
    "                                         nn.PReLU(64))\n",
    "        self.layer1 = self._make_layer(block, filter_list[0], filter_list[1], layers[0], stride=2)\n",
    "        self.layer2 = self._make_layer(block, filter_list[1], filter_list[2], layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, filter_list[2], filter_list[3], layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, filter_list[3], filter_list[4], layers[3], stride=2)\n",
    "\n",
    "        self.output_layer = nn.Sequential(nn.BatchNorm2d(512),\n",
    "                                          nn.Dropout(drop_ratio),\n",
    "                                          Flatten(),\n",
    "                                          nn.Linear(512 * 7 * 7, feature_dim),\n",
    "                                          nn.BatchNorm1d(feature_dim))\n",
    "\n",
    "        # weight initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, in_channel, out_channel, blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(block(in_channel, out_channel, stride, False))\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channel, out_channel, 1, True))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attention.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:18:41.446406Z",
     "start_time": "2020-07-18T13:18:41.331405Z"
    }
   },
   "outputs": [],
   "source": [
    "# from backbone.attention import ResidualAttentionNet_56, ResidualAttentionNet_92\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channel, out_channel, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "        self.stride = stride\n",
    "\n",
    "        self.res_bottleneck = nn.Sequential(nn.BatchNorm2d(in_channel),\n",
    "                                            nn.ReLU(inplace=True),\n",
    "                                            nn.Conv2d(in_channel, out_channel//4, 1, 1, bias=False),\n",
    "                                            nn.BatchNorm2d(out_channel//4),\n",
    "                                            nn.ReLU(inplace=True),\n",
    "                                            nn.Conv2d(out_channel//4, out_channel//4, 3, stride, padding=1, bias=False),\n",
    "                                            nn.BatchNorm2d(out_channel//4),\n",
    "                                            nn.ReLU(inplace=True),\n",
    "                                            nn.Conv2d(out_channel//4, out_channel, 1, 1, bias=False))\n",
    "        self.shortcut = nn.Conv2d(in_channel, out_channel, 1, stride, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        out = self.res_bottleneck(x)\n",
    "        if self.in_channel != self.out_channel or self.stride != 1:\n",
    "            res = self.shortcut(x)\n",
    "\n",
    "        out += res\n",
    "        return out\n",
    "\n",
    "class AttentionModule_stage1(nn.Module):\n",
    "\n",
    "    # input size is 56*56\n",
    "    def __init__(self, in_channel, out_channel, size1=(56, 56), size2=(28, 28), size3=(14, 14)):\n",
    "        super(AttentionModule_stage1, self).__init__()\n",
    "        self.share_residual_block = ResidualBlock(in_channel, out_channel)\n",
    "        self.trunk_branches = nn.Sequential(ResidualBlock(in_channel, out_channel),\n",
    "                                            ResidualBlock(in_channel, out_channel))\n",
    "\n",
    "        self.mpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.mask_block1 = ResidualBlock(in_channel, out_channel)\n",
    "        self.skip_connect1 = ResidualBlock(in_channel, out_channel)\n",
    "\n",
    "        self.mpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.mask_block2 = ResidualBlock(in_channel, out_channel)\n",
    "        self.skip_connect2 = ResidualBlock(in_channel, out_channel)\n",
    "\n",
    "        self.mpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.mask_block3 = nn.Sequential(ResidualBlock(in_channel, out_channel),\n",
    "                                         ResidualBlock(in_channel, out_channel))\n",
    "\n",
    "        self.interpolation3 = nn.UpsamplingBilinear2d(size=size3)\n",
    "        self.mask_block4 = ResidualBlock(in_channel, out_channel)\n",
    "\n",
    "        self.interpolation2 = nn.UpsamplingBilinear2d(size=size2)\n",
    "        self.mask_block5 = ResidualBlock(in_channel, out_channel)\n",
    "\n",
    "        self.interpolation1 = nn.UpsamplingBilinear2d(size=size1)\n",
    "        self.mask_block6 = nn.Sequential(nn.BatchNorm2d(out_channel),\n",
    "                                         nn.ReLU(inplace=True),\n",
    "                                         nn.Conv2d(out_channel, out_channel, 1, 1, bias=False),\n",
    "                                         nn.BatchNorm2d(out_channel),\n",
    "                                         nn.ReLU(inplace=True),\n",
    "                                         nn.Conv2d(out_channel, out_channel, 1, 1, bias=False),\n",
    "                                         nn.Sigmoid())\n",
    "\n",
    "        self.last_block = ResidualBlock(in_channel, out_channel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.share_residual_block(x)\n",
    "        out_trunk = self.trunk_branches(x)\n",
    "\n",
    "        out_pool1 = self.mpool1(x)\n",
    "        out_block1 = self.mask_block1(out_pool1)\n",
    "        out_skip_connect1 = self.skip_connect1(out_block1)\n",
    "\n",
    "        out_pool2 = self.mpool2(out_block1)\n",
    "        out_block2 = self.mask_block2(out_pool2)\n",
    "        out_skip_connect2 = self.skip_connect2(out_block2)\n",
    "\n",
    "        out_pool3 = self.mpool3(out_block2)\n",
    "        out_block3 = self.mask_block3(out_pool3)\n",
    "        #\n",
    "        out_inter3 = self.interpolation3(out_block3) + out_block2\n",
    "        out = out_inter3 + out_skip_connect2\n",
    "        out_block4 = self.mask_block4(out)\n",
    "\n",
    "        out_inter2 = self.interpolation2(out_block4) + out_block1\n",
    "        out = out_inter2 + out_skip_connect1\n",
    "        out_block5 = self.mask_block5(out)\n",
    "\n",
    "        out_inter1 = self.interpolation1(out_block5) + out_trunk\n",
    "        out_block6 = self.mask_block6(out_inter1)\n",
    "\n",
    "        out = (1 + out_block6) + out_trunk\n",
    "        out_last = self.last_block(out)\n",
    "\n",
    "        return out_last\n",
    "\n",
    "class AttentionModule_stage2(nn.Module):\n",
    "\n",
    "    # input image size is 28*28\n",
    "    def __init__(self, in_channels, out_channels, size1=(28, 28), size2=(14, 14)):\n",
    "        super(AttentionModule_stage2, self).__init__()\n",
    "        self.first_residual_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.trunk_branches = nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels),\n",
    "            ResidualBlock(in_channels, out_channels)\n",
    "         )\n",
    "\n",
    "        self.mpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.softmax1_blocks = ResidualBlock(in_channels, out_channels)\n",
    "        self.skip1_connection_residual_block = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.mpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.softmax2_blocks = nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels),\n",
    "            ResidualBlock(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "        self.interpolation2 = nn.UpsamplingBilinear2d(size=size2)\n",
    "        self.softmax3_blocks = ResidualBlock(in_channels, out_channels)\n",
    "        self.interpolation1 = nn.UpsamplingBilinear2d(size=size1)\n",
    "        self.softmax4_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.last_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_residual_blocks(x)\n",
    "        out_trunk = self.trunk_branches(x)\n",
    "        out_mpool1 = self.mpool1(x)\n",
    "        out_softmax1 = self.softmax1_blocks(out_mpool1)\n",
    "        out_skip1_connection = self.skip1_connection_residual_block(out_softmax1)\n",
    "\n",
    "        out_mpool2 = self.mpool2(out_softmax1)\n",
    "        out_softmax2 = self.softmax2_blocks(out_mpool2)\n",
    "\n",
    "        out_interp2 = self.interpolation2(out_softmax2) + out_softmax1\n",
    "        out = out_interp2 + out_skip1_connection\n",
    "\n",
    "        out_softmax3 = self.softmax3_blocks(out)\n",
    "        out_interp1 = self.interpolation1(out_softmax3) + out_trunk\n",
    "        out_softmax4 = self.softmax4_blocks(out_interp1)\n",
    "        out = (1 + out_softmax4) * out_trunk\n",
    "        out_last = self.last_blocks(out)\n",
    "\n",
    "        return out_last\n",
    "\n",
    "class AttentionModule_stage3(nn.Module):\n",
    "\n",
    "    # input image size is 14*14\n",
    "    def __init__(self, in_channels, out_channels, size1=(14, 14)):\n",
    "        super(AttentionModule_stage3, self).__init__()\n",
    "        self.first_residual_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.trunk_branches = nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels),\n",
    "            ResidualBlock(in_channels, out_channels)\n",
    "         )\n",
    "\n",
    "        self.mpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.softmax1_blocks = nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels),\n",
    "            ResidualBlock(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "        self.interpolation1 = nn.UpsamplingBilinear2d(size=size1)\n",
    "\n",
    "        self.softmax2_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.last_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_residual_blocks(x)\n",
    "        out_trunk = self.trunk_branches(x)\n",
    "        out_mpool1 = self.mpool1(x)\n",
    "        out_softmax1 = self.softmax1_blocks(out_mpool1)\n",
    "\n",
    "        out_interp1 = self.interpolation1(out_softmax1) + out_trunk\n",
    "        out_softmax2 = self.softmax2_blocks(out_interp1)\n",
    "        out = (1 + out_softmax2) * out_trunk\n",
    "        out_last = self.last_blocks(out)\n",
    "\n",
    "        return out_last\n",
    "\n",
    "class ResidualAttentionNet_56(nn.Module):\n",
    "\n",
    "    # for input size 112\n",
    "    def __init__(self, feature_dim=512, drop_ratio=0.4):\n",
    "        super(ResidualAttentionNet_56, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias = False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.mpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.residual_block1 = ResidualBlock(64, 256)\n",
    "        self.attention_module1 = AttentionModule_stage1(256, 256)\n",
    "        self.residual_block2 = ResidualBlock(256, 512, 2)\n",
    "        self.attention_module2 = AttentionModule_stage2(512, 512)\n",
    "        self.residual_block3 = ResidualBlock(512, 512, 2)\n",
    "        self.attention_module3 = AttentionModule_stage3(512, 512)\n",
    "        self.residual_block4 = ResidualBlock(512, 512, 2)\n",
    "        self.residual_block5 = ResidualBlock(512, 512)\n",
    "        self.residual_block6 = ResidualBlock(512, 512)\n",
    "        self.output_layer = nn.Sequential(nn.BatchNorm2d(512),\n",
    "                                          nn.Dropout(drop_ratio),\n",
    "                                          Flatten(),\n",
    "                                          nn.Linear(512 * 7 * 7, feature_dim),\n",
    "                                          nn.BatchNorm1d(feature_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.mpool1(out)\n",
    "        # print(out.data)\n",
    "        out = self.residual_block1(out)\n",
    "        out = self.attention_module1(out)\n",
    "        out = self.residual_block2(out)\n",
    "        out = self.attention_module2(out)\n",
    "        out = self.residual_block3(out)\n",
    "        # print(out.data)\n",
    "        out = self.attention_module3(out)\n",
    "        out = self.residual_block4(out)\n",
    "        out = self.residual_block5(out)\n",
    "        out = self.residual_block6(out)\n",
    "        out = self.output_layer(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResidualAttentionNet_92(nn.Module):\n",
    "\n",
    "    # for input size 112\n",
    "    def __init__(self, feature_dim=512, drop_ratio=0.4):\n",
    "        super(ResidualAttentionNet_92, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias = False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.mpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.residual_block1 = ResidualBlock(64, 256)\n",
    "        self.attention_module1 = AttentionModule_stage1(256, 256)\n",
    "        self.residual_block2 = ResidualBlock(256, 512, 2)\n",
    "        self.attention_module2 = AttentionModule_stage2(512, 512)\n",
    "        self.attention_module2_2 = AttentionModule_stage2(512, 512)  # tbq add\n",
    "        self.residual_block3 = ResidualBlock(512, 1024, 2)\n",
    "        self.attention_module3 = AttentionModule_stage3(1024, 1024)\n",
    "        self.attention_module3_2 = AttentionModule_stage3(1024, 1024)  # tbq add\n",
    "        self.attention_module3_3 = AttentionModule_stage3(1024, 1024)  # tbq add\n",
    "        self.residual_block4 = ResidualBlock(1024, 2048, 2)\n",
    "        self.residual_block5 = ResidualBlock(2048, 2048)\n",
    "        self.residual_block6 = ResidualBlock(2048, 2048)\n",
    "        self.output_layer = nn.Sequential(nn.BatchNorm2d(2048),\n",
    "                                          nn.Dropout(drop_ratio),\n",
    "                                          Flatten(),\n",
    "                                          nn.Linear(2048 * 7 * 7, feature_dim),\n",
    "                                          nn.BatchNorm1d(feature_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.mpool1(out)\n",
    "        # print(out.data)\n",
    "        out = self.residual_block1(out)\n",
    "        out = self.attention_module1(out)\n",
    "        out = self.residual_block2(out)\n",
    "        out = self.attention_module2(out)\n",
    "        out = self.attention_module2_2(out)\n",
    "        out = self.residual_block3(out)\n",
    "        # print(out.data)\n",
    "        out = self.attention_module3(out)\n",
    "        out = self.attention_module3_2(out)\n",
    "        out = self.attention_module3_3(out)\n",
    "        out = self.residual_block4(out)\n",
    "        out = self.residual_block5(out)\n",
    "        out = self.residual_block6(out)\n",
    "        out = self.output_layer(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ArcMarginProduct.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:19:35.171577Z",
     "start_time": "2020-07-18T13:19:35.155612Z"
    }
   },
   "outputs": [],
   "source": [
    "# from margin.ArcMarginProduct import ArcMarginProduct\n",
    "class ArcMarginProduct(nn.Module):\n",
    "    def __init__(self, in_feature=128, out_feature=10575, s=32.0, m=0.50, easy_margin=False):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = Parameter(torch.Tensor(out_feature, in_feature))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "\n",
    "        # make the function cos(theta+m) monotonic decreasing while theta in [0°,180°]\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        # cos(theta)\n",
    "        cosine = F.linear(F.normalize(x), F.normalize(self.weight))\n",
    "        # cos(theta + m)\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where((cosine - self.th) > 0, phi, cosine - self.mm)\n",
    "\n",
    "        #one_hot = torch.zeros(cosine.size(), device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        one_hot = torch.zeros_like(cosine)\n",
    "        one_hot.scatter_(1, label.view(-1, 1), 1)\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output = output * self.s\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiMarginProduct.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:19:48.672574Z",
     "start_time": "2020-07-18T13:19:48.658576Z"
    }
   },
   "outputs": [],
   "source": [
    "# from margin.MultiMarginProduct import MultiMarginProduct\n",
    "class MultiMarginProduct(nn.Module):\n",
    "    def __init__(self, in_feature=128, out_feature=10575, s=32.0, m1=0.20, m2=0.35, easy_margin=False):\n",
    "        super(MultiMarginProduct, self).__init__()\n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "        self.s = s\n",
    "        self.m1 = m1\n",
    "        self.m2 = m2\n",
    "        self.weight = Parameter(torch.Tensor(out_feature, in_feature))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m1 = math.cos(m1)\n",
    "        self.sin_m1 = math.sin(m1)\n",
    "\n",
    "        # make the function cos(theta+m) monotonic decreasing while theta in [0°,180°]\n",
    "        self.th = math.cos(math.pi - m1)\n",
    "        self.mm = math.sin(math.pi - m1) * m1\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        # cos(theta)\n",
    "        cosine = F.linear(F.normalize(x), F.normalize(self.weight))\n",
    "        # cos(theta + m1)\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m1 - sine * self.sin_m1\n",
    "\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where((cosine - self.th) > 0, phi, cosine - self.mm)\n",
    "\n",
    "\n",
    "        one_hot = torch.zeros_like(cosine)\n",
    "        one_hot.scatter_(1, label.view(-1, 1), 1)\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine) # additive angular margin\n",
    "        output = output - one_hot * self.m2 # additive cosine margin\n",
    "        output = output * self.s\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CosineMarginProduct.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:20:00.229211Z",
     "start_time": "2020-07-18T13:20:00.215250Z"
    }
   },
   "outputs": [],
   "source": [
    "# from margin.CosineMarginProduct import CosineMarginProduct\n",
    "class CosineMarginProduct(nn.Module):\n",
    "    def __init__(self, in_feature=128, out_feature=10575, s=30.0, m=0.35):\n",
    "        super(CosineMarginProduct, self).__init__()\n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = Parameter(torch.Tensor(out_feature, in_feature))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        # one_hot = torch.zeros(cosine.size(), device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        one_hot = torch.zeros_like(cosine)\n",
    "        one_hot.scatter_(1, label.view(-1, 1), 1.0)\n",
    "\n",
    "        output = self.s * (cosine - one_hot * self.m)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InnerProduct.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:20:10.626731Z",
     "start_time": "2020-07-18T13:20:10.616731Z"
    }
   },
   "outputs": [],
   "source": [
    "# from margin.InnerProduct import InnerProduct\n",
    "class InnerProduct(nn.Module):\n",
    "    def __init__(self, in_feature=128, out_feature=10575):\n",
    "        super(InnerProduct, self).__init__()\n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "\n",
    "        self.weight = Parameter(torch.Tensor(out_feature, in_feature))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        # label not used\n",
    "        output = F.linear(input, self.weight)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:23:46.635583Z",
     "start_time": "2020-07-18T13:23:32.175585Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001F5A94918C8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/test (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001F5A94918C8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/test (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001F5A94918C8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n",
      "[WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom with `use_incoming_socket=False`, which will prevent waiting for this request to timeout.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-277cd113c6d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_curves\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_curves\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'val'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-277cd113c6d9>\u001b[0m in \u001b[0;36mplot_curves\u001b[1;34m(self, d, iters, title, xlabel, ylabel)\u001b[0m\n\u001b[0;32m     16\u001b[0m                       \u001b[0mwin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                       \u001b[0mopts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                       update=None if self.index == 0 else 'append')\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_to_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_to_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\u001b[0m in \u001b[0;36mline\u001b[1;34m(self, Y, X, win, env, opts, update, name)\u001b[0m\n\u001b[0;32m   1713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1714\u001b[0m         return self.scatter(X=linedata, Y=labels, opts=opts, win=win, env=env,\n\u001b[1;32m-> 1715\u001b[1;33m                             update=update, name=name)\n\u001b[0m\u001b[0;32m   1716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1717\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mpytorch_wrap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_to_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_to_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(self, X, Y, win, env, opts, update, name)\u001b[0m\n\u001b[0;32m   1490\u001b[0m                     \u001b[0mupdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffline\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1492\u001b[1;33m                     \u001b[0mexists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwin_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1493\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mexists\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1494\u001b[0m                         \u001b[0mupdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\u001b[0m in \u001b[0;36mwin_exists\u001b[1;34m(self, win, env)\u001b[0m\n\u001b[0;32m    829\u001b[0m         \"\"\"\n\u001b[0;32m    830\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 831\u001b[1;33m             \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_win_exists_wrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    832\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Error connecting to Visdom server!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\u001b[0m in \u001b[0;36m_win_exists_wrap\u001b[1;34m(self, win, env)\u001b[0m\n\u001b[0;32m    813\u001b[0m             \u001b[1;34m'win'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mwin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[1;34m'eid'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 815\u001b[1;33m         }, endpoint='win_exists', quiet=True)\n\u001b[0m\u001b[0;32m    816\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_env_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\u001b[0m in \u001b[0;36m_send\u001b[1;34m(self, msg, endpoint, quiet, from_log, create)\u001b[0m\n\u001b[0;32m    709\u001b[0m                 \"{0}:{1}{2}/{3}\".format(self.server, self.port,\n\u001b[0;32m    710\u001b[0m                                         self.base_url, endpoint),\n\u001b[1;32m--> 711\u001b[1;33m                 \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m             )\n\u001b[0;32m    713\u001b[0m         except (\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\u001b[0m in \u001b[0;36m_handle_post\u001b[1;34m(self, url, data)\u001b[0m\n\u001b[0;32m    675\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    678\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mpost\u001b[1;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m         \"\"\"\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'POST'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    506\u001b[0m         }\n\u001b[0;32m    507\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    438\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m                 )\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m             \u001b[1;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[1;31m# Reset the timeout for the recv() on the socket\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1250\u001b[0m                 encode_chunked=False):\n\u001b[0;32m   1251\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1252\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1296\u001b[0m             \u001b[1;31m# default charset of iso-8859-1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1298\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1245\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1247\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m     def request(self, method, url, body=None, headers={}, *,\n",
      "\u001b[1;32mc:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1024\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb\"\\r\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1025\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmessage_body\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    964\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mNotConnected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             conn = connection.create_connection(\n\u001b[1;32m--> 141\u001b[1;33m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSocketTimeout\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from utils.visualize import Visualizer\n",
    "class Visualizer():\n",
    "    def __init__(self, env='default', **kwargs):\n",
    "        self.vis = visdom.Visdom(env=env, **kwargs)\n",
    "        self.index = 1\n",
    "\n",
    "    def plot_curves(self, d, iters, title='loss', xlabel='iters', ylabel='accuracy'):\n",
    "        name = list(d.keys())\n",
    "        val = list(d.values())\n",
    "        if len(val) == 1:\n",
    "            y = np.array(val)\n",
    "        else:\n",
    "            y = np.array(val).reshape(-1, len(val))\n",
    "        self.vis.line(Y=y,\n",
    "                      X=np.array([self.index]),\n",
    "                      win=title,\n",
    "                      opts=dict(legend=name, title = title, xlabel=xlabel, ylabel=ylabel),\n",
    "                      update=None if self.index == 0 else 'append')\n",
    "        self.index = iters\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    vis = Visualizer(env='test')\n",
    "    for i in range(10):\n",
    "        x = i\n",
    "        y = 2 * i\n",
    "        z = 4 * i\n",
    "        vis.plot_curves({'train': x, 'test': y}, iters=i, title='train')\n",
    "        vis.plot_curves({'train': z, 'test': y, 'val': i}, iters=i, title='test')\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ligging.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:24:20.984400Z",
     "start_time": "2020-07-18T13:24:20.975433Z"
    }
   },
   "outputs": [],
   "source": [
    "# from utils.logging import init_log\n",
    "def init_log(output_dir):\n",
    "    logging.basicConfig(level=logging.DEBUG,\n",
    "                        format='%(asctime)s %(message)s',\n",
    "                        datefmt='%Y%m%d-%H:%M:%S',\n",
    "                        filename=os.path.join(output_dir, 'log.log'),\n",
    "                        filemode='w')\n",
    "    console = logging.StreamHandler()\n",
    "    console.setLevel(logging.INFO)\n",
    "    logging.getLogger('').addHandler(console)\n",
    "    return logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset\n",
    "## casia_sebface.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:25:08.302463Z",
     "start_time": "2020-07-18T13:25:08.287463Z"
    }
   },
   "outputs": [],
   "source": [
    "# from dataset.casia_webface import CASIAWebFace\n",
    "def img_loader(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            img = cv2.imread(path)\n",
    "            if len(img.shape) == 2:\n",
    "                img = np.stack([img] * 3, 2)\n",
    "            return img\n",
    "    except IOError:\n",
    "        print('Cannot load image ' + path)\n",
    "\n",
    "\n",
    "class CASIAWebFace(data.Dataset):\n",
    "    def __init__(self, root, file_list, transform=None, loader=img_loader):\n",
    "\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "\n",
    "        image_list = []\n",
    "        label_list = []\n",
    "        with open(file_list) as f:\n",
    "            img_label_list = f.read().splitlines()\n",
    "        for info in img_label_list:\n",
    "            image_path, label_name = info.split(' ')\n",
    "            image_list.append(image_path)\n",
    "            label_list.append(int(label_name))\n",
    "\n",
    "        self.image_list = image_list\n",
    "        self.label_list = label_list\n",
    "        self.class_nums = len(np.unique(self.label_list))\n",
    "        print(\"dataset size: \", len(self.image_list), '/', self.class_nums)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.image_list[index]\n",
    "        label = self.label_list[index]\n",
    "\n",
    "        img = self.loader(os.path.join(self.root, img_path))\n",
    "\n",
    "        # random flip with ratio of 0.5\n",
    "        flip = np.random.choice(2) * 2 - 1\n",
    "        if flip == 1:\n",
    "            img = cv2.flip(img, 1)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = torch.from_numpy(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lfw.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:26:13.648429Z",
     "start_time": "2020-07-18T13:26:13.627385Z"
    }
   },
   "outputs": [],
   "source": [
    "# from dataset.lfw import LFW\n",
    "def img_loader(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            img = cv2.imread(path)\n",
    "            if len(img.shape) == 2:\n",
    "                img = np.stack([img] * 3, 2)\n",
    "            return img\n",
    "    except IOError:\n",
    "        print('Cannot load image ' + path)\n",
    "\n",
    "class LFW(data.Dataset):\n",
    "    def __init__(self, root, file_list, transform=None, loader=img_loader):\n",
    "\n",
    "        self.root = root\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "        self.nameLs = []\n",
    "        self.nameRs = []\n",
    "        self.folds = []\n",
    "        self.flags = []\n",
    "\n",
    "        with open(file_list) as f:\n",
    "            pairs = f.read().splitlines()[1:]\n",
    "        for i, p in enumerate(pairs):\n",
    "            p = p.split('\\t')\n",
    "            if len(p) == 3:\n",
    "                nameL = p[0] + '/' + p[0] + '_' + '{:04}.jpg'.format(int(p[1]))\n",
    "                nameR = p[0] + '/' + p[0] + '_' + '{:04}.jpg'.format(int(p[2]))\n",
    "                fold = i // 600\n",
    "                flag = 1\n",
    "            elif len(p) == 4:\n",
    "                nameL = p[0] + '/' + p[0] + '_' + '{:04}.jpg'.format(int(p[1]))\n",
    "                nameR = p[2] + '/' + p[2] + '_' + '{:04}.jpg'.format(int(p[3]))\n",
    "                fold = i // 600\n",
    "                flag = -1\n",
    "            self.nameLs.append(nameL)\n",
    "            self.nameRs.append(nameR)\n",
    "            self.folds.append(fold)\n",
    "            self.flags.append(flag)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        img_l = self.loader(os.path.join(self.root, self.nameLs[index]))\n",
    "        img_r = self.loader(os.path.join(self.root, self.nameRs[index]))\n",
    "        imglist = [img_l, cv2.flip(img_l, 1), img_r, cv2.flip(img_r, 1)]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            for i in range(len(imglist)):\n",
    "                imglist[i] = self.transform(imglist[i])\n",
    "\n",
    "            imgs = imglist\n",
    "            return imgs\n",
    "        else:\n",
    "            imgs = [torch.from_numpy(i) for i in imglist]\n",
    "            return imgs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.nameLs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## agedb.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:26:52.096986Z",
     "start_time": "2020-07-18T13:26:52.079972Z"
    }
   },
   "outputs": [],
   "source": [
    "# from dataset.agedb import AgeDB30\n",
    "def img_loader(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            img = cv2.imread(path)\n",
    "            if len(img.shape) == 2:\n",
    "                img = np.stack([img] * 3, 2)\n",
    "            return img\n",
    "    except IOError:\n",
    "        print('Cannot load image ' + path)\n",
    "\n",
    "class AgeDB30(data.Dataset):\n",
    "    def __init__(self, root, file_list, transform=None, loader=img_loader):\n",
    "\n",
    "        self.root = root\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "        self.nameLs = []\n",
    "        self.nameRs = []\n",
    "        self.folds = []\n",
    "        self.flags = []\n",
    "\n",
    "        with open(file_list) as f:\n",
    "            pairs = f.read().splitlines()\n",
    "        for i, p in enumerate(pairs):\n",
    "            p = p.split(' ')\n",
    "            nameL = p[0]\n",
    "            nameR = p[1]\n",
    "            fold = i // 600\n",
    "            flag = int(p[2])\n",
    "\n",
    "            self.nameLs.append(nameL)\n",
    "            self.nameRs.append(nameR)\n",
    "            self.folds.append(fold)\n",
    "            self.flags.append(flag)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        img_l = self.loader(os.path.join(self.root, self.nameLs[index]))\n",
    "        img_r = self.loader(os.path.join(self.root, self.nameRs[index]))\n",
    "        imglist = [img_l, cv2.flip(img_l, 1), img_r, cv2.flip(img_r, 1)]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            for i in range(len(imglist)):\n",
    "                imglist[i] = self.transform(imglist[i])\n",
    "\n",
    "            imgs = imglist\n",
    "            return imgs\n",
    "        else:\n",
    "            imgs = [torch.from_numpy(i) for i in imglist]\n",
    "            return imgs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.nameLs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cfp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:27:05.313123Z",
     "start_time": "2020-07-18T13:27:05.295125Z"
    }
   },
   "outputs": [],
   "source": [
    "# from dataset.cfp import CFP_FP\n",
    "def img_loader(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            img = cv2.imread(path)\n",
    "            if len(img.shape) == 2:\n",
    "                img = np.stack([img] * 3, 2)\n",
    "            return img\n",
    "    except IOError:\n",
    "        print('Cannot load image ' + path)\n",
    "\n",
    "class CFP_FP(data.Dataset):\n",
    "    def __init__(self, root, file_list, transform=None, loader=img_loader):\n",
    "\n",
    "        self.root = root\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "        self.nameLs = []\n",
    "        self.nameRs = []\n",
    "        self.folds = []\n",
    "        self.flags = []\n",
    "\n",
    "        with open(file_list) as f:\n",
    "            pairs = f.read().splitlines()\n",
    "        for i, p in enumerate(pairs):\n",
    "            p = p.split(' ')\n",
    "            nameL = p[0]\n",
    "            nameR = p[1]\n",
    "            fold = i // 700\n",
    "            flag = int(p[2])\n",
    "\n",
    "            self.nameLs.append(nameL)\n",
    "            self.nameRs.append(nameR)\n",
    "            self.folds.append(fold)\n",
    "            self.flags.append(flag)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        img_l = self.loader(os.path.join(self.root, self.nameLs[index]))\n",
    "        img_r = self.loader(os.path.join(self.root, self.nameRs[index]))\n",
    "        imglist = [img_l, cv2.flip(img_l, 1), img_r, cv2.flip(img_r, 1)]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            for i in range(len(imglist)):\n",
    "                imglist[i] = self.transform(imglist[i])\n",
    "\n",
    "            imgs = imglist\n",
    "            return imgs\n",
    "        else:\n",
    "            imgs = [torch.from_numpy(i) for i in imglist]\n",
    "            return imgs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.nameLs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval_lfw.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:28:26.875014Z",
     "start_time": "2020-07-18T13:28:26.836986Z"
    }
   },
   "outputs": [],
   "source": [
    "# from eval_lfw import evaluation_10_fold, getFeatureFromTorch\n",
    "def getAccuracy(scores, flags, threshold):\n",
    "    p = np.sum(scores[flags == 1] > threshold)\n",
    "    n = np.sum(scores[flags == -1] < threshold)\n",
    "    return 1.0 * (p + n) / len(scores)\n",
    "\n",
    "def getThreshold(scores, flags, thrNum):\n",
    "    accuracys = np.zeros((2 * thrNum + 1, 1))\n",
    "    thresholds = np.arange(-thrNum, thrNum + 1) * 1.0 / thrNum\n",
    "    for i in range(2 * thrNum + 1):\n",
    "        accuracys[i] = getAccuracy(scores, flags, thresholds[i])\n",
    "    max_index = np.squeeze(accuracys == np.max(accuracys))\n",
    "    bestThreshold = np.mean(thresholds[max_index])\n",
    "    return bestThreshold\n",
    "\n",
    "def evaluation_10_fold(feature_path='./result/cur_epoch_result.mat'):\n",
    "    ACCs = np.zeros(10)\n",
    "    result = scipy.io.loadmat(feature_path)\n",
    "    for i in range(10):\n",
    "        fold = result['fold']\n",
    "        flags = result['flag']\n",
    "        featureLs = result['fl']\n",
    "        featureRs = result['fr']\n",
    "\n",
    "        valFold = fold != i\n",
    "        testFold = fold == i\n",
    "        flags = np.squeeze(flags)\n",
    "\n",
    "        mu = np.mean(np.concatenate((featureLs[valFold[0], :], featureRs[valFold[0], :]), 0), 0)\n",
    "        mu = np.expand_dims(mu, 0)\n",
    "        featureLs = featureLs - mu\n",
    "        featureRs = featureRs - mu\n",
    "        featureLs = featureLs / np.expand_dims(np.sqrt(np.sum(np.power(featureLs, 2), 1)), 1)\n",
    "        featureRs = featureRs / np.expand_dims(np.sqrt(np.sum(np.power(featureRs, 2), 1)), 1)\n",
    "\n",
    "        scores = np.sum(np.multiply(featureLs, featureRs), 1)\n",
    "        threshold = getThreshold(scores[valFold[0]], flags[valFold[0]], 10000)\n",
    "        ACCs[i] = getAccuracy(scores[testFold[0]], flags[testFold[0]], threshold)\n",
    "\n",
    "    return ACCs\n",
    "\n",
    "def loadModel(data_root, file_list, backbone_net, gpus='0', resume=None):\n",
    "\n",
    "    if backbone_net == 'MobileFace':\n",
    "        net = mobilefacenet.MobileFaceNet()\n",
    "    elif backbone_net == 'CBAM_50':\n",
    "        net = cbam.CBAMResNet(50, feature_dim=args.feature_dim, mode='ir')\n",
    "    elif backbone_net == 'CBAM_50_SE':\n",
    "        net = cbam.CBAMResNet(50, feature_dim=args.feature_dim, mode='ir_se')\n",
    "    elif backbone_net == 'CBAM_100':\n",
    "        net = cbam.CBAMResNet(100, feature_dim=args.feature_dim, mode='ir')\n",
    "    elif backbone_net == 'CBAM_100_SE':\n",
    "        net = cbam.CBAMResNet(100, feature_dim=args.feature_dim, mode='ir_se')\n",
    "    else:\n",
    "        print(backbone_net, ' is not available!')\n",
    "\n",
    "    # gpu init\n",
    "    multi_gpus = False\n",
    "    if len(gpus.split(',')) > 1:\n",
    "        multi_gpus = True\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = gpus\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    net.load_state_dict(torch.load(resume)['net_state_dict'])\n",
    "\n",
    "    if multi_gpus:\n",
    "        net = DataParallel(net).to(device)\n",
    "    else:\n",
    "        net = net.to(device)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # range [0, 255] -> [0.0,1.0]\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))  # range [0.0, 1.0] -> [-1.0,1.0]\n",
    "    ])\n",
    "    lfw_dataset = LFW(data_root, file_list, transform=transform)\n",
    "    lfw_loader = torch.utils.data.DataLoader(lfw_dataset, batch_size=128,\n",
    "                                             shuffle=False, num_workers=2, drop_last=False)\n",
    "\n",
    "    return net.eval(), device, lfw_dataset, lfw_loader\n",
    "\n",
    "def getFeatureFromTorch(feature_save_dir, net, device, data_set, data_loader):\n",
    "    featureLs = None\n",
    "    featureRs = None\n",
    "    count = 0\n",
    "    for data in data_loader:\n",
    "        for i in range(len(data)):\n",
    "            data[i] = data[i].to(device)\n",
    "        count += data[0].size(0)\n",
    "        #print('extracing deep features from the face pair {}...'.format(count))\n",
    "        with torch.no_grad():\n",
    "            res = [net(d).data.cpu().numpy() for d in data]\n",
    "        featureL = np.concatenate((res[0], res[1]), 1)\n",
    "        featureR = np.concatenate((res[2], res[3]), 1)\n",
    "        # print(featureL.shape, featureR.shape)\n",
    "        if featureLs is None:\n",
    "            featureLs = featureL\n",
    "        else:\n",
    "            featureLs = np.concatenate((featureLs, featureL), 0)\n",
    "        if featureRs is None:\n",
    "            featureRs = featureR\n",
    "        else:\n",
    "            featureRs = np.concatenate((featureRs, featureR), 0)\n",
    "        # print(featureLs.shape, featureRs.shape)\n",
    "\n",
    "    result = {'fl': featureLs, 'fr': featureRs, 'fold': data_set.folds, 'flag': data_set.flags}\n",
    "    scipy.io.savemat(feature_save_dir, result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:28:28.818980Z",
     "start_time": "2020-07-18T13:28:28.811983Z"
    }
   },
   "outputs": [],
   "source": [
    "def img_loader(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            img = cv2.imread(path)\n",
    "            if len(img.shape) == 2:\n",
    "                img = np.stack([img] * 3, 2)\n",
    "            return img\n",
    "    except IOError:\n",
    "        print('Cannot load image ' + path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:28:29.878978Z",
     "start_time": "2020-07-18T13:28:29.874989Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # range [0, 255] -> [0.0,1.0]\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))  # range [0.0, 1.0] -> [-1.0,1.0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:28:30.887977Z",
     "start_time": "2020-07-18T13:28:30.868979Z"
    }
   },
   "outputs": [],
   "source": [
    "class CASIAWebFace(data.Dataset):\n",
    "    def __init__(self, root, file_list, transform=None, loader=img_loader):\n",
    "\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "\n",
    "        image_list = []\n",
    "        label_list = []\n",
    "        with open(file_list) as f:\n",
    "            img_label_list = f.read().splitlines()\n",
    "        for info in img_label_list:\n",
    "            image_path, label_name = info.split('\\t')[1:]\n",
    "            image_list.append(image_path)\n",
    "            label_list.append(int(label_name))\n",
    "\n",
    "        self.image_list = image_list\n",
    "        self.label_list = label_list\n",
    "        self.class_nums = len(np.unique(self.label_list))\n",
    "        print(\"dataset size: \", len(self.image_list), '/', self.class_nums)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.image_list[index]\n",
    "        label = self.label_list[index]\n",
    "\n",
    "        img = self.loader(os.path.join(self.root, img_path))\n",
    "\n",
    "        # random flip with ratio of 0.5\n",
    "        flip = np.random.choice(2) * 2 - 1\n",
    "        if flip == 1:\n",
    "            img = cv2.flip(img, 1)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = torch.from_numpy(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:55:55.846984Z",
     "start_time": "2020-07-18T13:55:55.838981Z"
    }
   },
   "outputs": [],
   "source": [
    "# gpu init\n",
    "multi_gpus = False\n",
    "if len(args.gpus.split(',')) > 1:\n",
    "    multi_gpus = True\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpus\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:56:04.666983Z",
     "start_time": "2020-07-18T13:56:04.654983Z"
    }
   },
   "outputs": [],
   "source": [
    "# log init\n",
    "save_dir = os.path.join(args.save_dir, args.model_pre + args.backbone.upper() + '_' + datetime.now().strftime('%Y%m%d_%H%M%S'))\n",
    "if os.path.exists(save_dir):\n",
    "    raise NameError('model dir exists!')\n",
    "os.makedirs(save_dir)\n",
    "logging = init_log(save_dir)\n",
    "_print = logging.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:57:42.963144Z",
     "start_time": "2020-07-18T13:57:42.941105Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/faces_webface_112x112/train.lst'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-d379f3ae1b87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m ])\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# validation dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtrainset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCASIAWebFace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_root\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_file_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m trainloader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size,\n\u001b[0;32m      9\u001b[0m                                           shuffle=True, num_workers=8, drop_last=False)\n",
      "\u001b[1;32m<ipython-input-35-0ea422347055>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, file_list, transform, loader)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mimage_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mlabel_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0mimg_label_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimg_label_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/faces_webface_112x112/train.lst'"
     ]
    }
   ],
   "source": [
    "# dataset loader\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # range [0, 255] -> [0.0,1.0]\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))  # range [0.0, 1.0] -> [-1.0,1.0]\n",
    "])\n",
    "# validation dataset\n",
    "trainset = CASIAWebFace(args.train_root, args.train_file_list, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size,\n",
    "                                          shuffle=True, num_workers=8, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:48:40.884982Z",
     "start_time": "2020-07-18T13:48:40.868977Z"
    }
   },
   "outputs": [],
   "source": [
    "# test dataset\n",
    "lfwdataset = LFW(args.lfw_test_root, args.lfw_file_list, transform=transform)\n",
    "lfwloader = torch.utils.data.DataLoader(lfwdataset, batch_size=128,\n",
    "                                         shuffle=False, num_workers=4, drop_last=False)\n",
    "agedbdataset = AgeDB30(args.agedb_test_root, args.agedb_file_list, transform=transform)\n",
    "agedbloader = torch.utils.data.DataLoader(agedbdataset, batch_size=128,\n",
    "                                        shuffle=False, num_workers=4, drop_last=False)\n",
    "cfpfpdataset = CFP_FP(args.cfpfp_test_root, args.cfpfp_file_list, transform=transform)\n",
    "cfpfploader = torch.utils.data.DataLoader(cfpfpdataset, batch_size=128,\n",
    "                                          shuffle=False, num_workers=4, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:48:44.611977Z",
     "start_time": "2020-07-18T13:48:43.069976Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-abf781aafcd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmargin_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'ArcFace'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mmargin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArcMarginProduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_nums\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmargin_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'MultiMargin'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mmargin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultiMarginProduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_nums\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainset' is not defined"
     ]
    }
   ],
   "source": [
    "    # define backbone and margin layer\n",
    "    if args.backbone == 'MobileFace':\n",
    "        net = MobileFaceNet()\n",
    "    elif args.backbone == 'Res50_IR':\n",
    "        net = CBAMResNet(50, feature_dim=args.feature_dim, mode='ir')\n",
    "    elif args.backbone == 'SERes50_IR':\n",
    "        net = CBAMResNet(50, feature_dim=args.feature_dim, mode='ir_se')\n",
    "    elif args.backbone == 'Res100_IR':\n",
    "        net = CBAMResNet(100, feature_dim=args.feature_dim, mode='ir')\n",
    "    elif args.backbone == 'SERes100_IR':\n",
    "        net = CBAMResNet(100, feature_dim=args.feature_dim, mode='ir_se')\n",
    "    elif args.backbone == 'Attention_56':\n",
    "        net = ResidualAttentionNet_56(feature_dim=args.feature_dim)\n",
    "    elif args.backbone == 'Attention_92':\n",
    "        net = ResidualAttentionNet_92(feature_dim=args.feature_dim)\n",
    "    else:\n",
    "        print(args.backbone, ' is not available!')\n",
    "\n",
    "    if args.margin_type == 'ArcFace':\n",
    "        margin = ArcMarginProduct(args.feature_dim, trainset.class_nums, s=args.scale_size)\n",
    "    elif args.margin_type == 'MultiMargin':\n",
    "        margin = MultiMarginProduct(args.feature_dim, trainset.class_nums, s=args.scale_size)\n",
    "    elif args.margin_type == 'CosFace':\n",
    "        margin = CosineMarginProduct(args.feature_dim, trainset.class_nums, s=args.scale_size)\n",
    "    elif args.margin_type == 'Softmax':\n",
    "        margin = InnerProduct(args.feature_dim, trainset.class_nums)\n",
    "    elif args.margin_type == 'SphereFace':\n",
    "        pass\n",
    "    else:\n",
    "        print(args.margin_type, 'is not available!')\n",
    "\n",
    "    if args.resume:\n",
    "        print('resume the model parameters from: ', args.net_path, args.margin_path)\n",
    "        net.load_state_dict(torch.load(args.net_path)['net_state_dict'])\n",
    "        margin.load_state_dict(torch.load(args.margin_path)['net_state_dict'])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:48:44.615982Z",
     "start_time": "2020-07-18T13:48:43.955Z"
    }
   },
   "outputs": [],
   "source": [
    "    # define optimizers for different layer\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "    optimizer_ft = optim.SGD([\n",
    "        {'params': net.parameters(), 'weight_decay': 5e-4},\n",
    "        {'params': margin.parameters(), 'weight_decay': 5e-4}\n",
    "    ], lr=0.1, momentum=0.9, nesterov=True)\n",
    "    exp_lr_scheduler = lr_scheduler.MultiStepLR(optimizer_ft, milestones=[6, 11, 16], gamma=0.1)\n",
    "\n",
    "    if multi_gpus:\n",
    "        net = DataParallel(net).to(device)\n",
    "        margin = DataParallel(margin).to(device)\n",
    "    else:\n",
    "        net = net.to(device)\n",
    "        margin = margin.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:48:55.298013Z",
     "start_time": "2020-07-18T13:48:44.911977Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001F5BA95CFC8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/SERES100_SERes100_IR (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001F5BA95CFC8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/SERES100_SERes100_IR (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001F5BA95CFC8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n",
      "[WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom with `use_incoming_socket=False`, which will prevent waiting for this request to timeout.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exp_lr_scheduler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-76877a183e58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mvis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVisualizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_pre\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_epoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mexp_lr_scheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m# train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0m_print\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train Epoch: {}/{} ...'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'exp_lr_scheduler' is not defined"
     ]
    }
   ],
   "source": [
    "    best_lfw_acc = 0.0\n",
    "    best_lfw_iters = 0\n",
    "    best_agedb30_acc = 0.0\n",
    "    best_agedb30_iters = 0\n",
    "    best_cfp_fp_acc = 0.0\n",
    "    best_cfp_fp_iters = 0\n",
    "    total_iters = 0\n",
    "    vis = Visualizer(env=args.model_pre + args.backbone)\n",
    "    for epoch in range(1, args.total_epoch + 1):\n",
    "        exp_lr_scheduler.step()\n",
    "        # train model\n",
    "        _print('Train Epoch: {}/{} ...'.format(epoch, args.total_epoch))\n",
    "        net.train()\n",
    "\n",
    "        since = time.time()\n",
    "        for data in trainloader:\n",
    "            img, label = data[0].to(device), data[1].to(device)\n",
    "            optimizer_ft.zero_grad()\n",
    "\n",
    "            raw_logits = net(img)\n",
    "            output = margin(raw_logits, label)\n",
    "            total_loss = criterion(output, label)\n",
    "            total_loss.backward()\n",
    "            optimizer_ft.step()\n",
    "\n",
    "            total_iters += 1\n",
    "            # print train information\n",
    "            if total_iters % 100 == 0:\n",
    "                # current training accuracy\n",
    "                _, predict = torch.max(output.data, 1)\n",
    "                total = label.size(0)\n",
    "                correct = (np.array(predict.cpu()) == np.array(label.data.cpu())).sum()\n",
    "                time_cur = (time.time() - since) / 100\n",
    "                since = time.time()\n",
    "                vis.plot_curves({'softmax loss': total_loss.item()}, iters=total_iters, title='train loss',\n",
    "                                xlabel='iters', ylabel='train loss')\n",
    "                vis.plot_curves({'train accuracy': correct / total}, iters=total_iters, title='train accuracy', xlabel='iters',\n",
    "                                ylabel='train accuracy')\n",
    "\n",
    "                _print(\"Iters: {:0>6d}/[{:0>2d}], loss: {:.4f}, train_accuracy: {:.4f}, time: {:.2f} s/iter, learning rate: {}\".format(total_iters, epoch, total_loss.item(), correct/total, time_cur, exp_lr_scheduler.get_lr()[0]))\n",
    "\n",
    "            # save model\n",
    "            if total_iters % args.save_freq == 0:\n",
    "                msg = 'Saving checkpoint: {}'.format(total_iters)\n",
    "                _print(msg)\n",
    "                if multi_gpus:\n",
    "                    net_state_dict = net.module.state_dict()\n",
    "                    margin_state_dict = margin.module.state_dict()\n",
    "                else:\n",
    "                    net_state_dict = net.state_dict()\n",
    "                    margin_state_dict = margin.state_dict()\n",
    "                if not os.path.exists(save_dir):\n",
    "                    os.mkdir(save_dir)\n",
    "                torch.save({\n",
    "                    'iters': total_iters,\n",
    "                    'net_state_dict': net_state_dict},\n",
    "                    os.path.join(save_dir, 'Iter_%06d_net.ckpt' % total_iters))\n",
    "                torch.save({\n",
    "                    'iters': total_iters,\n",
    "                    'net_state_dict': margin_state_dict},\n",
    "                    os.path.join(save_dir, 'Iter_%06d_margin.ckpt' % total_iters))\n",
    "\n",
    "            # test accuracy\n",
    "            if total_iters % args.test_freq == 0:\n",
    "\n",
    "                # test model on lfw\n",
    "                net.eval()\n",
    "                getFeatureFromTorch('./result/cur_lfw_result.mat', net, device, lfwdataset, lfwloader)\n",
    "                lfw_accs = evaluation_10_fold('./result/cur_lfw_result.mat')\n",
    "                _print('LFW Ave Accuracy: {:.4f}'.format(np.mean(lfw_accs) * 100))\n",
    "                if best_lfw_acc <= np.mean(lfw_accs) * 100:\n",
    "                    best_lfw_acc = np.mean(lfw_accs) * 100\n",
    "                    best_lfw_iters = total_iters\n",
    "\n",
    "                # test model on AgeDB30\n",
    "                getFeatureFromTorch('./result/cur_agedb30_result.mat', net, device, agedbdataset, agedbloader)\n",
    "                age_accs = evaluation_10_fold('./result/cur_agedb30_result.mat')\n",
    "                _print('AgeDB-30 Ave Accuracy: {:.4f}'.format(np.mean(age_accs) * 100))\n",
    "                if best_agedb30_acc <= np.mean(age_accs) * 100:\n",
    "                    best_agedb30_acc = np.mean(age_accs) * 100\n",
    "                    best_agedb30_iters = total_iters\n",
    "\n",
    "                # test model on CFP-FP\n",
    "                getFeatureFromTorch('./result/cur_cfpfp_result.mat', net, device, cfpfpdataset, cfpfploader)\n",
    "                cfp_accs = evaluation_10_fold('./result/cur_cfpfp_result.mat')\n",
    "                _print('CFP-FP Ave Accuracy: {:.4f}'.format(np.mean(cfp_accs) * 100))\n",
    "                if best_cfp_fp_acc <= np.mean(cfp_accs) * 100:\n",
    "                    best_cfp_fp_acc = np.mean(cfp_accs) * 100\n",
    "                    best_cfp_fp_iters = total_iters\n",
    "                _print('Current Best Accuracy: LFW: {:.4f} in iters: {}, AgeDB-30: {:.4f} in iters: {} and CFP-FP: {:.4f} in iters: {}'.format(\n",
    "                    best_lfw_acc, best_lfw_iters, best_agedb30_acc, best_agedb30_iters, best_cfp_fp_acc, best_cfp_fp_iters))\n",
    "\n",
    "                vis.plot_curves({'lfw': np.mean(lfw_accs), 'agedb-30': np.mean(age_accs), 'cfp-fp': np.mean(cfp_accs)}, iters=total_iters,\n",
    "                                title='test accuracy', xlabel='iters', ylabel='test accuracy')\n",
    "                net.train()\n",
    "\n",
    "    _print('Finally Best Accuracy: LFW: {:.4f} in iters: {}, AgeDB-30: {:.4f} in iters: {} and CFP-FP: {:.4f} in iters: {}'.format(\n",
    "        best_lfw_acc, best_lfw_iters, best_agedb30_acc, best_agedb30_iters, best_cfp_fp_acc, best_cfp_fp_iters))\n",
    "    print('finishing training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:57:38.358108Z",
     "start_time": "2020-07-18T13:57:38.345108Z"
    }
   },
   "outputs": [],
   "source": [
    "args = EasyDict()\n",
    "\n",
    "args.train_root ='../data/faces_webface_112x112/imgs'    #'train image root')\n",
    "args.train_file_list= '../data/faces_webface_112x112/train.lst'    #'train list')\n",
    "args.lfw_test_root='/media/sda/lfw/lfw_align_112'     #'lfw image root')\n",
    "args.lfw_file_list='/media/sda/lfw/pairs.txt'     #'lfw pair file list')\n",
    "args.agedb_test_root='/media/sda/AgeDB-30/agedb30_align_112'     #'agedb image root')\n",
    "args.agedb_file_list='/media/sda/AgeDB-30/agedb_30_pair.txt'     #'agedb pair file list')\n",
    "args.cfpfp_test_root='/media/sda/CFP-FP/cfp_fp_aligned_112'     #'agedb image root')\n",
    "args.cfpfp_file_list='/media/sda/CFP-FP/cfp_fp_pair.txt'     #'agedb pair file list')\n",
    "\n",
    "args.backbone='SERes100_IR'     #'MobileFace, Res50_IR, SERes50_IR, Res100_IR, SERes100_IR, Attention_56, Attention_92')\n",
    "args.margin_type='ArcFace'     #'ArcFace, CosFace, SphereFace, MultiMargin, Softmax')\n",
    "args.feature_dim=512     #'feature dimension, 128 or 512')\n",
    "args.scale_size=32.0     #'scale size')\n",
    "args.batch_size=200     #'batch size')\n",
    "args.total_epoch=18     #'total epochs')\n",
    "\n",
    "args.save_freq=3000     #'save frequency')\n",
    "args.test_freq=3000     #'test frequency')\n",
    "args.resume=False     #'resume model')\n",
    "args.net_path=''     #'resume model')\n",
    "args.margin_path=''     #'resume model')\n",
    "args.save_dir='./model'     #'model save dir')\n",
    "args.model_pre='SERES100_'     #'model prefix')\n",
    "args.gpus='0,1,2,3'     #'model prefix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:07:00.415862Z",
     "start_time": "2020-07-18T13:07:00.403856Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n"
     ]
    }
   ],
   "source": [
    "# root = 'D:/data/webface_align_112'\n",
    "# file_list = 'D:/data/webface_align_train.list'\n",
    "root = '../data/faces_webface_112x112/imgs'  \n",
    "file_list = '../data/small_vgg/small_vgg_112x112.lst'\n",
    "print(os.path.isdir(root), os.path.isfile(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
