{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train.py(face_pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:13:17.736781Z",
     "start_time": "2020-07-18T15:13:15.561787Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "from torch.nn import DataParallel\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import argparse\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from easydict import EasyDict\n",
    "from torch import nn\n",
    "import math\n",
    "from torch import nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "import visdom\n",
    "import time\n",
    "import logging\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import scipy.io\n",
    "import json\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mobilefacenet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:13:22.260789Z",
     "start_time": "2020-07-18T15:13:20.965787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileFaceNet(\n",
      "  (conv1): ConvBlock(\n",
      "    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (prelu): PReLU(num_parameters=64)\n",
      "  )\n",
      "  (dw_conv1): ConvBlock(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (prelu): PReLU(num_parameters=64)\n",
      "  )\n",
      "  (blocks): Sequential(\n",
      "    (0): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=128)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=128)\n",
      "        (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=128)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=128)\n",
      "        (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=128)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=128)\n",
      "        (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=128)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=128)\n",
      "        (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=128)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=128)\n",
      "        (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=256)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=256)\n",
      "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=256)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=256)\n",
      "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=256)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=256)\n",
      "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=256)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=256)\n",
      "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=256)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=256)\n",
      "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=256)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=256)\n",
      "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=256)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=256)\n",
      "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=512)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=512)\n",
      "        (6): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=256)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=256)\n",
      "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=256)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=256)\n",
      "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv2): ConvBlock(\n",
      "    (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (prelu): PReLU(num_parameters=512)\n",
      "  )\n",
      "  (linear7): ConvBlock(\n",
      "    (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), groups=512, bias=False)\n",
      "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (linear1): ConvBlock(\n",
      "    (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 128])\n"
     ]
    }
   ],
   "source": [
    "# from backbone.mobilefacenet import MobileFaceNet\n",
    "MobileFaceNet_BottleNeck_Setting = [\n",
    "    # t, c , n ,s\n",
    "    [2, 64, 5, 2],\n",
    "    [4, 128, 1, 2],\n",
    "    [2, 128, 6, 1],\n",
    "    [4, 128, 1, 2],\n",
    "    [2, 128, 2, 1]\n",
    "]\n",
    "\n",
    "class BottleNeck(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expansion):\n",
    "        super(BottleNeck, self).__init__()\n",
    "        self.connect = stride == 1 and inp == oup\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            # 1*1 conv\n",
    "            nn.Conv2d(inp, inp * expansion, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(inp * expansion),\n",
    "            nn.PReLU(inp * expansion),\n",
    "\n",
    "            # 3*3 depth wise conv\n",
    "            nn.Conv2d(inp * expansion, inp * expansion, 3, stride, 1, groups=inp * expansion, bias=False),\n",
    "            nn.BatchNorm2d(inp * expansion),\n",
    "            nn.PReLU(inp * expansion),\n",
    "\n",
    "            # 1*1 conv\n",
    "            nn.Conv2d(inp * expansion, oup, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(oup),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, inp, oup, k, s, p, dw=False, linear=False):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.linear = linear\n",
    "        if dw:\n",
    "            self.conv = nn.Conv2d(inp, oup, k, s, p, groups=inp, bias=False)\n",
    "        else:\n",
    "            self.conv = nn.Conv2d(inp, oup, k, s, p, bias=False)\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(oup)\n",
    "        if not linear:\n",
    "            self.prelu = nn.PReLU(oup)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        if self.linear:\n",
    "            return x\n",
    "        else:\n",
    "            return self.prelu(x)\n",
    "\n",
    "\n",
    "class MobileFaceNet(nn.Module):\n",
    "    def __init__(self, feature_dim=128, bottleneck_setting=MobileFaceNet_BottleNeck_Setting):\n",
    "        super(MobileFaceNet, self).__init__()\n",
    "        self.conv1 = ConvBlock(3, 64, 3, 2, 1)\n",
    "        self.dw_conv1 = ConvBlock(64, 64, 3, 1, 1, dw=True)\n",
    "\n",
    "        self.cur_channel = 64\n",
    "        block = BottleNeck\n",
    "        self.blocks = self._make_layer(block, bottleneck_setting)\n",
    "\n",
    "        self.conv2 = ConvBlock(128, 512, 1, 1, 0)\n",
    "        self.linear7 = ConvBlock(512, 512, 7, 1, 0, dw=True, linear=True)\n",
    "        self.linear1 = ConvBlock(512, feature_dim, 1, 1, 0, linear=True)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, setting):\n",
    "        layers = []\n",
    "        for t, c, n, s in setting:\n",
    "            for i in range(n):\n",
    "                if i == 0:\n",
    "                    layers.append(block(self.cur_channel, c, s, t))\n",
    "                else:\n",
    "                    layers.append(block(self.cur_channel, c, 1, t))\n",
    "                self.cur_channel = c\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.dw_conv1(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.linear7(x)\n",
    "        x = self.linear1(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input = torch.Tensor(2, 3, 112, 112)\n",
    "    net = MobileFaceNet()\n",
    "    print(net)\n",
    "\n",
    "    x = net(input)\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cbam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:13:22.377790Z",
     "start_time": "2020-07-18T15:13:22.264785Z"
    }
   },
   "outputs": [],
   "source": [
    "# from backbone.cbam import CBAMResNet\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "    '''Squeeze and Excitation Module'''\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1, padding=0, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1, padding=0, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return input * x\n",
    "\n",
    "class CAModule(nn.Module):\n",
    "    '''Channel Attention Module'''\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(CAModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.shared_mlp = nn.Sequential(nn.Conv2d(channels, channels // reduction, kernel_size=1, padding=0, bias=False),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.Conv2d(channels // reduction, channels, kernel_size=1, padding=0, bias=False))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        avg_pool = self.avg_pool(x)\n",
    "        max_pool = self.max_pool(x)\n",
    "        x = self.shared_mlp(avg_pool) + self.shared_mlp(max_pool)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return input * x\n",
    "\n",
    "class SAModule(nn.Module):\n",
    "    '''Spatial Attention Module'''\n",
    "    def __init__(self):\n",
    "        super(SAModule, self).__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        avg_c = torch.mean(x, 1, True)\n",
    "        max_c, _ = torch.max(x, 1, True)\n",
    "        x = torch.cat((avg_c, max_c), 1)\n",
    "        x = self.conv(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return input * x\n",
    "\n",
    "class BottleNeck_IR(nn.Module):\n",
    "    '''Improved Residual Bottlenecks'''\n",
    "    def __init__(self, in_channel, out_channel, stride, dim_match):\n",
    "        super(BottleNeck_IR, self).__init__()\n",
    "        self.res_layer = nn.Sequential(nn.BatchNorm2d(in_channel),\n",
    "                                       nn.Conv2d(in_channel, out_channel, (3, 3), 1, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       nn.PReLU(out_channel),\n",
    "                                       nn.Conv2d(out_channel, out_channel, (3, 3), stride, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel))\n",
    "        if dim_match:\n",
    "            self.shortcut_layer = None\n",
    "        else:\n",
    "            self.shortcut_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, out_channel, kernel_size=(1, 1), stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        if self.shortcut_layer is not None:\n",
    "            shortcut = self.shortcut_layer(x)\n",
    "\n",
    "        return shortcut + res\n",
    "\n",
    "class BottleNeck_IR_SE(nn.Module):\n",
    "    '''Improved Residual Bottlenecks with Squeeze and Excitation Module'''\n",
    "    def __init__(self, in_channel, out_channel, stride, dim_match):\n",
    "        super(BottleNeck_IR_SE, self).__init__()\n",
    "        self.res_layer = nn.Sequential(nn.BatchNorm2d(in_channel),\n",
    "                                       nn.Conv2d(in_channel, out_channel, (3, 3), 1, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       nn.PReLU(out_channel),\n",
    "                                       nn.Conv2d(out_channel, out_channel, (3, 3), stride, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       SEModule(out_channel, 16))\n",
    "        if dim_match:\n",
    "            self.shortcut_layer = None\n",
    "        else:\n",
    "            self.shortcut_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, out_channel, kernel_size=(1, 1), stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        if self.shortcut_layer is not None:\n",
    "            shortcut = self.shortcut_layer(x)\n",
    "\n",
    "        return shortcut + res\n",
    "\n",
    "class BottleNeck_IR_CAM(nn.Module):\n",
    "    '''Improved Residual Bottlenecks with Channel Attention Module'''\n",
    "    def __init__(self, in_channel, out_channel, stride, dim_match):\n",
    "        super(BottleNeck_IR_CAM, self).__init__()\n",
    "        self.res_layer = nn.Sequential(nn.BatchNorm2d(in_channel),\n",
    "                                       nn.Conv2d(in_channel, out_channel, (3, 3), 1, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       nn.PReLU(out_channel),\n",
    "                                       nn.Conv2d(out_channel, out_channel, (3, 3), stride, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       CAModule(out_channel, 16))\n",
    "        if dim_match:\n",
    "            self.shortcut_layer = None\n",
    "        else:\n",
    "            self.shortcut_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, out_channel, kernel_size=(1, 1), stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        if self.shortcut_layer is not None:\n",
    "            shortcut = self.shortcut_layer(x)\n",
    "\n",
    "        return shortcut + res\n",
    "\n",
    "class BottleNeck_IR_SAM(nn.Module):\n",
    "    '''Improved Residual Bottlenecks with Spatial Attention Module'''\n",
    "    def __init__(self, in_channel, out_channel, stride, dim_match):\n",
    "        super(BottleNeck_IR_SAM, self).__init__()\n",
    "        self.res_layer = nn.Sequential(nn.BatchNorm2d(in_channel),\n",
    "                                       nn.Conv2d(in_channel, out_channel, (3, 3), 1, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       nn.PReLU(out_channel),\n",
    "                                       nn.Conv2d(out_channel, out_channel, (3, 3), stride, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       SAModule())\n",
    "        if dim_match:\n",
    "            self.shortcut_layer = None\n",
    "        else:\n",
    "            self.shortcut_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, out_channel, kernel_size=(1, 1), stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        if self.shortcut_layer is not None:\n",
    "            shortcut = self.shortcut_layer(x)\n",
    "\n",
    "        return shortcut + res\n",
    "\n",
    "class BottleNeck_IR_CBAM(nn.Module):\n",
    "    '''Improved Residual Bottleneck with Channel Attention Module and Spatial Attention Module'''\n",
    "    def __init__(self, in_channel, out_channel, stride, dim_match):\n",
    "        super(BottleNeck_IR_CBAM, self).__init__()\n",
    "        self.res_layer = nn.Sequential(nn.BatchNorm2d(in_channel),\n",
    "                                       nn.Conv2d(in_channel, out_channel, (3, 3), 1, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       nn.PReLU(out_channel),\n",
    "                                       nn.Conv2d(out_channel, out_channel, (3, 3), stride, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       CAModule(out_channel, 16),\n",
    "                                       SAModule()\n",
    "                                       )\n",
    "        if dim_match:\n",
    "            self.shortcut_layer = None\n",
    "        else:\n",
    "            self.shortcut_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, out_channel, kernel_size=(1, 1), stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        if self.shortcut_layer is not None:\n",
    "            shortcut = self.shortcut_layer(x)\n",
    "\n",
    "        return shortcut + res\n",
    "\n",
    "\n",
    "filter_list = [64, 64, 128, 256, 512]\n",
    "def get_layers(num_layers):\n",
    "    if num_layers == 50:\n",
    "        return [3, 4, 14, 3]\n",
    "    elif num_layers == 100:\n",
    "        return [3, 13, 30, 3]\n",
    "    elif num_layers == 152:\n",
    "        return [3, 8, 36, 3]\n",
    "\n",
    "class CBAMResNet(nn.Module):\n",
    "    def __init__(self, num_layers, feature_dim=512, drop_ratio=0.4, mode='ir',filter_list=filter_list):\n",
    "        super(CBAMResNet, self).__init__()\n",
    "        assert num_layers in [50, 100, 152], 'num_layers should be 50, 100 or 152'\n",
    "        assert mode in ['ir', 'ir_se', 'ir_cam', 'ir_sam', 'ir_cbam'], 'mode should be ir, ir_se, ir_cam, ir_sam or ir_cbam'\n",
    "        layers = get_layers(num_layers)\n",
    "        if mode == 'ir':\n",
    "            block = BottleNeck_IR\n",
    "        elif mode == 'ir_se':\n",
    "            block = BottleNeck_IR_SE\n",
    "        elif mode == 'ir_cam':\n",
    "            block = BottleNeck_IR_CAM\n",
    "        elif mode == 'ir_sam':\n",
    "            block = BottleNeck_IR_SAM\n",
    "        elif mode == 'ir_cbam':\n",
    "            block = BottleNeck_IR_CBAM\n",
    "\n",
    "        self.input_layer = nn.Sequential(nn.Conv2d(3, 64, (3, 3), stride=1, padding=1, bias=False),\n",
    "                                         nn.BatchNorm2d(64),\n",
    "                                         nn.PReLU(64))\n",
    "        self.layer1 = self._make_layer(block, filter_list[0], filter_list[1], layers[0], stride=2)\n",
    "        self.layer2 = self._make_layer(block, filter_list[1], filter_list[2], layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, filter_list[2], filter_list[3], layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, filter_list[3], filter_list[4], layers[3], stride=2)\n",
    "\n",
    "        self.output_layer = nn.Sequential(nn.BatchNorm2d(512),\n",
    "                                          nn.Dropout(drop_ratio),\n",
    "                                          Flatten(),\n",
    "                                          nn.Linear(512 * 7 * 7, feature_dim),\n",
    "                                          nn.BatchNorm1d(feature_dim))\n",
    "\n",
    "        # weight initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, in_channel, out_channel, blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(block(in_channel, out_channel, stride, False))\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channel, out_channel, 1, True))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attention.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:13:22.592793Z",
     "start_time": "2020-07-18T15:13:22.452784Z"
    }
   },
   "outputs": [],
   "source": [
    "# from backbone.attention import ResidualAttentionNet_56, ResidualAttentionNet_92\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channel, out_channel, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "        self.stride = stride\n",
    "\n",
    "        self.res_bottleneck = nn.Sequential(nn.BatchNorm2d(in_channel),\n",
    "                                            nn.ReLU(inplace=True),\n",
    "                                            nn.Conv2d(in_channel, out_channel//4, 1, 1, bias=False),\n",
    "                                            nn.BatchNorm2d(out_channel//4),\n",
    "                                            nn.ReLU(inplace=True),\n",
    "                                            nn.Conv2d(out_channel//4, out_channel//4, 3, stride, padding=1, bias=False),\n",
    "                                            nn.BatchNorm2d(out_channel//4),\n",
    "                                            nn.ReLU(inplace=True),\n",
    "                                            nn.Conv2d(out_channel//4, out_channel, 1, 1, bias=False))\n",
    "        self.shortcut = nn.Conv2d(in_channel, out_channel, 1, stride, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        out = self.res_bottleneck(x)\n",
    "        if self.in_channel != self.out_channel or self.stride != 1:\n",
    "            res = self.shortcut(x)\n",
    "\n",
    "        out += res\n",
    "        return out\n",
    "\n",
    "class AttentionModule_stage1(nn.Module):\n",
    "\n",
    "    # input size is 56*56\n",
    "    def __init__(self, in_channel, out_channel, size1=(56, 56), size2=(28, 28), size3=(14, 14)):\n",
    "        super(AttentionModule_stage1, self).__init__()\n",
    "        self.share_residual_block = ResidualBlock(in_channel, out_channel)\n",
    "        self.trunk_branches = nn.Sequential(ResidualBlock(in_channel, out_channel),\n",
    "                                            ResidualBlock(in_channel, out_channel))\n",
    "\n",
    "        self.mpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.mask_block1 = ResidualBlock(in_channel, out_channel)\n",
    "        self.skip_connect1 = ResidualBlock(in_channel, out_channel)\n",
    "\n",
    "        self.mpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.mask_block2 = ResidualBlock(in_channel, out_channel)\n",
    "        self.skip_connect2 = ResidualBlock(in_channel, out_channel)\n",
    "\n",
    "        self.mpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.mask_block3 = nn.Sequential(ResidualBlock(in_channel, out_channel),\n",
    "                                         ResidualBlock(in_channel, out_channel))\n",
    "\n",
    "        self.interpolation3 = nn.UpsamplingBilinear2d(size=size3)\n",
    "        self.mask_block4 = ResidualBlock(in_channel, out_channel)\n",
    "\n",
    "        self.interpolation2 = nn.UpsamplingBilinear2d(size=size2)\n",
    "        self.mask_block5 = ResidualBlock(in_channel, out_channel)\n",
    "\n",
    "        self.interpolation1 = nn.UpsamplingBilinear2d(size=size1)\n",
    "        self.mask_block6 = nn.Sequential(nn.BatchNorm2d(out_channel),\n",
    "                                         nn.ReLU(inplace=True),\n",
    "                                         nn.Conv2d(out_channel, out_channel, 1, 1, bias=False),\n",
    "                                         nn.BatchNorm2d(out_channel),\n",
    "                                         nn.ReLU(inplace=True),\n",
    "                                         nn.Conv2d(out_channel, out_channel, 1, 1, bias=False),\n",
    "                                         nn.Sigmoid())\n",
    "\n",
    "        self.last_block = ResidualBlock(in_channel, out_channel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.share_residual_block(x)\n",
    "        out_trunk = self.trunk_branches(x)\n",
    "\n",
    "        out_pool1 = self.mpool1(x)\n",
    "        out_block1 = self.mask_block1(out_pool1)\n",
    "        out_skip_connect1 = self.skip_connect1(out_block1)\n",
    "\n",
    "        out_pool2 = self.mpool2(out_block1)\n",
    "        out_block2 = self.mask_block2(out_pool2)\n",
    "        out_skip_connect2 = self.skip_connect2(out_block2)\n",
    "\n",
    "        out_pool3 = self.mpool3(out_block2)\n",
    "        out_block3 = self.mask_block3(out_pool3)\n",
    "        #\n",
    "        out_inter3 = self.interpolation3(out_block3) + out_block2\n",
    "        out = out_inter3 + out_skip_connect2\n",
    "        out_block4 = self.mask_block4(out)\n",
    "\n",
    "        out_inter2 = self.interpolation2(out_block4) + out_block1\n",
    "        out = out_inter2 + out_skip_connect1\n",
    "        out_block5 = self.mask_block5(out)\n",
    "\n",
    "        out_inter1 = self.interpolation1(out_block5) + out_trunk\n",
    "        out_block6 = self.mask_block6(out_inter1)\n",
    "\n",
    "        out = (1 + out_block6) + out_trunk\n",
    "        out_last = self.last_block(out)\n",
    "\n",
    "        return out_last\n",
    "\n",
    "class AttentionModule_stage2(nn.Module):\n",
    "\n",
    "    # input image size is 28*28\n",
    "    def __init__(self, in_channels, out_channels, size1=(28, 28), size2=(14, 14)):\n",
    "        super(AttentionModule_stage2, self).__init__()\n",
    "        self.first_residual_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.trunk_branches = nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels),\n",
    "            ResidualBlock(in_channels, out_channels)\n",
    "         )\n",
    "\n",
    "        self.mpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.softmax1_blocks = ResidualBlock(in_channels, out_channels)\n",
    "        self.skip1_connection_residual_block = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.mpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.softmax2_blocks = nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels),\n",
    "            ResidualBlock(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "        self.interpolation2 = nn.UpsamplingBilinear2d(size=size2)\n",
    "        self.softmax3_blocks = ResidualBlock(in_channels, out_channels)\n",
    "        self.interpolation1 = nn.UpsamplingBilinear2d(size=size1)\n",
    "        self.softmax4_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.last_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_residual_blocks(x)\n",
    "        out_trunk = self.trunk_branches(x)\n",
    "        out_mpool1 = self.mpool1(x)\n",
    "        out_softmax1 = self.softmax1_blocks(out_mpool1)\n",
    "        out_skip1_connection = self.skip1_connection_residual_block(out_softmax1)\n",
    "\n",
    "        out_mpool2 = self.mpool2(out_softmax1)\n",
    "        out_softmax2 = self.softmax2_blocks(out_mpool2)\n",
    "\n",
    "        out_interp2 = self.interpolation2(out_softmax2) + out_softmax1\n",
    "        out = out_interp2 + out_skip1_connection\n",
    "\n",
    "        out_softmax3 = self.softmax3_blocks(out)\n",
    "        out_interp1 = self.interpolation1(out_softmax3) + out_trunk\n",
    "        out_softmax4 = self.softmax4_blocks(out_interp1)\n",
    "        out = (1 + out_softmax4) * out_trunk\n",
    "        out_last = self.last_blocks(out)\n",
    "\n",
    "        return out_last\n",
    "\n",
    "class AttentionModule_stage3(nn.Module):\n",
    "\n",
    "    # input image size is 14*14\n",
    "    def __init__(self, in_channels, out_channels, size1=(14, 14)):\n",
    "        super(AttentionModule_stage3, self).__init__()\n",
    "        self.first_residual_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.trunk_branches = nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels),\n",
    "            ResidualBlock(in_channels, out_channels)\n",
    "         )\n",
    "\n",
    "        self.mpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.softmax1_blocks = nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels),\n",
    "            ResidualBlock(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "        self.interpolation1 = nn.UpsamplingBilinear2d(size=size1)\n",
    "\n",
    "        self.softmax2_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.last_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_residual_blocks(x)\n",
    "        out_trunk = self.trunk_branches(x)\n",
    "        out_mpool1 = self.mpool1(x)\n",
    "        out_softmax1 = self.softmax1_blocks(out_mpool1)\n",
    "\n",
    "        out_interp1 = self.interpolation1(out_softmax1) + out_trunk\n",
    "        out_softmax2 = self.softmax2_blocks(out_interp1)\n",
    "        out = (1 + out_softmax2) * out_trunk\n",
    "        out_last = self.last_blocks(out)\n",
    "\n",
    "        return out_last\n",
    "\n",
    "class ResidualAttentionNet_56(nn.Module):\n",
    "\n",
    "    # for input size 112\n",
    "    def __init__(self, feature_dim=512, drop_ratio=0.4):\n",
    "        super(ResidualAttentionNet_56, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias = False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.mpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.residual_block1 = ResidualBlock(64, 256)\n",
    "        self.attention_module1 = AttentionModule_stage1(256, 256)\n",
    "        self.residual_block2 = ResidualBlock(256, 512, 2)\n",
    "        self.attention_module2 = AttentionModule_stage2(512, 512)\n",
    "        self.residual_block3 = ResidualBlock(512, 512, 2)\n",
    "        self.attention_module3 = AttentionModule_stage3(512, 512)\n",
    "        self.residual_block4 = ResidualBlock(512, 512, 2)\n",
    "        self.residual_block5 = ResidualBlock(512, 512)\n",
    "        self.residual_block6 = ResidualBlock(512, 512)\n",
    "        self.output_layer = nn.Sequential(nn.BatchNorm2d(512),\n",
    "                                          nn.Dropout(drop_ratio),\n",
    "                                          Flatten(),\n",
    "                                          nn.Linear(512 * 7 * 7, feature_dim),\n",
    "                                          nn.BatchNorm1d(feature_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.mpool1(out)\n",
    "        # print(out.data)\n",
    "        out = self.residual_block1(out)\n",
    "        out = self.attention_module1(out)\n",
    "        out = self.residual_block2(out)\n",
    "        out = self.attention_module2(out)\n",
    "        out = self.residual_block3(out)\n",
    "        # print(out.data)\n",
    "        out = self.attention_module3(out)\n",
    "        out = self.residual_block4(out)\n",
    "        out = self.residual_block5(out)\n",
    "        out = self.residual_block6(out)\n",
    "        out = self.output_layer(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResidualAttentionNet_92(nn.Module):\n",
    "\n",
    "    # for input size 112\n",
    "    def __init__(self, feature_dim=512, drop_ratio=0.4):\n",
    "        super(ResidualAttentionNet_92, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias = False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.mpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.residual_block1 = ResidualBlock(64, 256)\n",
    "        self.attention_module1 = AttentionModule_stage1(256, 256)\n",
    "        self.residual_block2 = ResidualBlock(256, 512, 2)\n",
    "        self.attention_module2 = AttentionModule_stage2(512, 512)\n",
    "        self.attention_module2_2 = AttentionModule_stage2(512, 512)  # tbq add\n",
    "        self.residual_block3 = ResidualBlock(512, 1024, 2)\n",
    "        self.attention_module3 = AttentionModule_stage3(1024, 1024)\n",
    "        self.attention_module3_2 = AttentionModule_stage3(1024, 1024)  # tbq add\n",
    "        self.attention_module3_3 = AttentionModule_stage3(1024, 1024)  # tbq add\n",
    "        self.residual_block4 = ResidualBlock(1024, 2048, 2)\n",
    "        self.residual_block5 = ResidualBlock(2048, 2048)\n",
    "        self.residual_block6 = ResidualBlock(2048, 2048)\n",
    "        self.output_layer = nn.Sequential(nn.BatchNorm2d(2048),\n",
    "                                          nn.Dropout(drop_ratio),\n",
    "                                          Flatten(),\n",
    "                                          nn.Linear(2048 * 7 * 7, feature_dim),\n",
    "                                          nn.BatchNorm1d(feature_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.mpool1(out)\n",
    "        # print(out.data)\n",
    "        out = self.residual_block1(out)\n",
    "        out = self.attention_module1(out)\n",
    "        out = self.residual_block2(out)\n",
    "        out = self.attention_module2(out)\n",
    "        out = self.attention_module2_2(out)\n",
    "        out = self.residual_block3(out)\n",
    "        # print(out.data)\n",
    "        out = self.attention_module3(out)\n",
    "        out = self.attention_module3_2(out)\n",
    "        out = self.attention_module3_3(out)\n",
    "        out = self.residual_block4(out)\n",
    "        out = self.residual_block5(out)\n",
    "        out = self.residual_block6(out)\n",
    "        out = self.output_layer(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ArcMarginProduct.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:13:23.970789Z",
     "start_time": "2020-07-18T15:13:23.957786Z"
    }
   },
   "outputs": [],
   "source": [
    "# from margin.ArcMarginProduct import ArcMarginProduct\n",
    "class ArcMarginProduct(nn.Module):\n",
    "    def __init__(self, in_feature=128, out_feature=10575, s=32.0, m=0.50, easy_margin=False):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = Parameter(torch.Tensor(out_feature, in_feature))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "\n",
    "        # make the function cos(theta+m) monotonic decreasing while theta in [0°,180°]\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        # cos(theta)\n",
    "        cosine = F.linear(F.normalize(x), F.normalize(self.weight))\n",
    "        # cos(theta + m)\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where((cosine - self.th) > 0, phi, cosine - self.mm)\n",
    "\n",
    "        #one_hot = torch.zeros(cosine.size(), device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        one_hot = torch.zeros_like(cosine)\n",
    "        one_hot.scatter_(1, label.view(-1, 1), 1)\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output = output * self.s\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiMarginProduct.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:13:24.359788Z",
     "start_time": "2020-07-18T15:13:24.341787Z"
    }
   },
   "outputs": [],
   "source": [
    "# from margin.MultiMarginProduct import MultiMarginProduct\n",
    "class MultiMarginProduct(nn.Module):\n",
    "    def __init__(self, in_feature=128, out_feature=10575, s=32.0, m1=0.20, m2=0.35, easy_margin=False):\n",
    "        super(MultiMarginProduct, self).__init__()\n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "        self.s = s\n",
    "        self.m1 = m1\n",
    "        self.m2 = m2\n",
    "        self.weight = Parameter(torch.Tensor(out_feature, in_feature))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m1 = math.cos(m1)\n",
    "        self.sin_m1 = math.sin(m1)\n",
    "\n",
    "        # make the function cos(theta+m) monotonic decreasing while theta in [0°,180°]\n",
    "        self.th = math.cos(math.pi - m1)\n",
    "        self.mm = math.sin(math.pi - m1) * m1\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        # cos(theta)\n",
    "        cosine = F.linear(F.normalize(x), F.normalize(self.weight))\n",
    "        # cos(theta + m1)\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m1 - sine * self.sin_m1\n",
    "\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where((cosine - self.th) > 0, phi, cosine - self.mm)\n",
    "\n",
    "\n",
    "        one_hot = torch.zeros_like(cosine)\n",
    "        one_hot.scatter_(1, label.view(-1, 1), 1)\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine) # additive angular margin\n",
    "        output = output - one_hot * self.m2 # additive cosine margin\n",
    "        output = output * self.s\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CosineMarginProduct.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:13:24.754325Z",
     "start_time": "2020-07-18T15:13:24.740322Z"
    }
   },
   "outputs": [],
   "source": [
    "# from margin.CosineMarginProduct import CosineMarginProduct\n",
    "class CosineMarginProduct(nn.Module):\n",
    "    def __init__(self, in_feature=128, out_feature=10575, s=30.0, m=0.35):\n",
    "        super(CosineMarginProduct, self).__init__()\n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = Parameter(torch.Tensor(out_feature, in_feature))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        # one_hot = torch.zeros(cosine.size(), device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        one_hot = torch.zeros_like(cosine)\n",
    "        one_hot.scatter_(1, label.view(-1, 1), 1.0)\n",
    "\n",
    "        output = self.s * (cosine - one_hot * self.m)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InnerProduct.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:13:25.030323Z",
     "start_time": "2020-07-18T15:13:25.023329Z"
    }
   },
   "outputs": [],
   "source": [
    "# from margin.InnerProduct import InnerProduct\n",
    "class InnerProduct(nn.Module):\n",
    "    def __init__(self, in_feature=128, out_feature=10575):\n",
    "        super(InnerProduct, self).__init__()\n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "\n",
    "        self.weight = Parameter(torch.Tensor(out_feature, in_feature))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        # label not used\n",
    "        output = F.linear(input, self.weight)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:15:58.848538Z",
     "start_time": "2020-07-18T15:13:25.542322Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F0709CC8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/test (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F0709CC8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/test (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F0709CC8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n",
      "[WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom with `use_incoming_socket=False`, which will prevent waiting for this request to timeout.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F8891488>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F8891488>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F8891488>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F17A3C48>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /events (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F17A3C48>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /events (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F17A3C48>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F07099C8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /events (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F07099C8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /events (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F07099C8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F88A8688>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F88A8688>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F88A8688>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F070DEC8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F070DEC8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F070DEC8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F88B24C8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F88B24C8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F88B24C8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F88A56C8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F88A56C8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F88A56C8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F88B8DC8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F88B8DC8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F88B8DC8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F17A3C08>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F17A3C08>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F17A3C08>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F88A7608>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F88A7608>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F88A7608>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F071CE08>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F071CE08>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F071CE08>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F0709688>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F0709688>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F0709688>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F8894CC8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F8894CC8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F8894CC8>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F88A5288>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F88A5288>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F88A5288>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F070D148>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F070D148>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F070D148>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F17D1308>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F17D1308>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F17D1308>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F070DB48>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F070DB48>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F070DB48>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-277cd113c6d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_curves\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_curves\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'val'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-277cd113c6d9>\u001b[0m in \u001b[0;36mplot_curves\u001b[1;34m(self, d, iters, title, xlabel, ylabel)\u001b[0m\n\u001b[0;32m     16\u001b[0m                       \u001b[0mwin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                       \u001b[0mopts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                       update=None if self.index == 0 else 'append')\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_to_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_to_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\u001b[0m in \u001b[0;36mline\u001b[1;34m(self, Y, X, win, env, opts, update, name)\u001b[0m\n\u001b[0;32m   1713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1714\u001b[0m         return self.scatter(X=linedata, Y=labels, opts=opts, win=win, env=env,\n\u001b[1;32m-> 1715\u001b[1;33m                             update=update, name=name)\n\u001b[0m\u001b[0;32m   1716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1717\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mpytorch_wrap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_to_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_to_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(self, X, Y, win, env, opts, update, name)\u001b[0m\n\u001b[0;32m   1638\u001b[0m             \u001b[0mendpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'update'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1640\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_to_send\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1642\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mpytorch_wrap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\u001b[0m in \u001b[0;36m_send\u001b[1;34m(self, msg, endpoint, quiet, from_log, create)\u001b[0m\n\u001b[0;32m    709\u001b[0m                 \"{0}:{1}{2}/{3}\".format(self.server, self.port,\n\u001b[0;32m    710\u001b[0m                                         self.base_url, endpoint),\n\u001b[1;32m--> 711\u001b[1;33m                 \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m             )\n\u001b[0;32m    713\u001b[0m         except (\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\u001b[0m in \u001b[0;36m_handle_post\u001b[1;34m(self, url, data)\u001b[0m\n\u001b[0;32m    675\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    678\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mpost\u001b[1;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m         \"\"\"\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'POST'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    506\u001b[0m         }\n\u001b[0;32m    507\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    438\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m                 )\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m             \u001b[1;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[1;31m# Reset the timeout for the recv() on the socket\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1250\u001b[0m                 encode_chunked=False):\n\u001b[0;32m   1251\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1252\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1296\u001b[0m             \u001b[1;31m# default charset of iso-8859-1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1298\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1245\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1247\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m     def request(self, method, url, body=None, headers={}, *,\n",
      "\u001b[1;32mc:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1024\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb\"\\r\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1025\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmessage_body\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    964\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mNotConnected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             conn = connection.create_connection(\n\u001b[1;32m--> 141\u001b[1;33m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSocketTimeout\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from utils.visualize import Visualizer\n",
    "class Visualizer():\n",
    "    def __init__(self, env='default', **kwargs):\n",
    "        self.vis = visdom.Visdom(env=env, **kwargs)\n",
    "        self.index = 1\n",
    "\n",
    "    def plot_curves(self, d, iters, title='loss', xlabel='iters', ylabel='accuracy'):\n",
    "        name = list(d.keys())\n",
    "        val = list(d.values())\n",
    "        if len(val) == 1:\n",
    "            y = np.array(val)\n",
    "        else:\n",
    "            y = np.array(val).reshape(-1, len(val))\n",
    "        self.vis.line(Y=y,\n",
    "                      X=np.array([self.index]),\n",
    "                      win=title,\n",
    "                      opts=dict(legend=name, title = title, xlabel=xlabel, ylabel=ylabel),\n",
    "                      update=None if self.index == 0 else 'append')\n",
    "        self.index = iters\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    vis = Visualizer(env='test')\n",
    "    for i in range(10):\n",
    "        x = i\n",
    "        y = 2 * i\n",
    "        z = 4 * i\n",
    "        vis.plot_curves({'train': x, 'test': y}, iters=i, title='train')\n",
    "        vis.plot_curves({'train': z, 'test': y, 'val': i}, iters=i, title='test')\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ligging.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:16:26.391541Z",
     "start_time": "2020-07-18T15:16:26.384543Z"
    }
   },
   "outputs": [],
   "source": [
    "# from utils.logging import init_log\n",
    "def init_log(output_dir):\n",
    "    logging.basicConfig(level=logging.DEBUG,\n",
    "                        format='%(asctime)s %(message)s',\n",
    "                        datefmt='%Y%m%d-%H:%M:%S',\n",
    "                        filename=os.path.join(output_dir, 'log.log'),\n",
    "                        filemode='w')\n",
    "    console = logging.StreamHandler()\n",
    "    console.setLevel(logging.INFO)\n",
    "    logging.getLogger('').addHandler(console)\n",
    "    return logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset\n",
    "## casia_sebface.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:16:32.320541Z",
     "start_time": "2020-07-18T15:16:32.304541Z"
    }
   },
   "outputs": [],
   "source": [
    "# from dataset.casia_webface import CASIAWebFace\n",
    "def img_loader(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            img = cv2.imread(path)\n",
    "            if len(img.shape) == 2:\n",
    "                img = np.stack([img] * 3, 2)\n",
    "            return img\n",
    "    except IOError:\n",
    "        print('Cannot load image ' + path)\n",
    "\n",
    "\n",
    "class CASIAWebFace(data.Dataset):\n",
    "    def __init__(self, root, file_list, transform=None, loader=img_loader):\n",
    "\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "\n",
    "        image_list = []\n",
    "        label_list = []\n",
    "        with open(file_list) as f:\n",
    "            img_label_list = f.read().splitlines()\n",
    "        for info in img_label_list:\n",
    "            image_path, label_name = info.split(' ')\n",
    "            image_list.append(image_path)\n",
    "            label_list.append(int(label_name))\n",
    "\n",
    "        self.image_list = image_list\n",
    "        self.label_list = label_list\n",
    "        self.class_nums = len(np.unique(self.label_list))\n",
    "        print(\"dataset size: \", len(self.image_list), '/', self.class_nums)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.image_list[index]\n",
    "        label = self.label_list[index]\n",
    "\n",
    "        img = self.loader(os.path.join(self.root, img_path))\n",
    "\n",
    "        # random flip with ratio of 0.5\n",
    "        flip = np.random.choice(2) * 2 - 1\n",
    "        if flip == 1:\n",
    "            img = cv2.flip(img, 1)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = torch.from_numpy(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lfw.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:16:33.070542Z",
     "start_time": "2020-07-18T15:16:33.040548Z"
    }
   },
   "outputs": [],
   "source": [
    "# from dataset.lfw import LFW\n",
    "def img_loader(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            img = cv2.imread(path)\n",
    "            if len(img.shape) == 2:\n",
    "                img = np.stack([img] * 3, 2)\n",
    "            return img\n",
    "    except IOError:\n",
    "        print('Cannot load image ' + path)\n",
    "\n",
    "class LFW(data.Dataset):\n",
    "    def __init__(self, root, file_list, transform=None, loader=img_loader):\n",
    "\n",
    "        self.root = root\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "        self.nameLs = []\n",
    "        self.nameRs = []\n",
    "        self.folds = []\n",
    "        self.flags = []\n",
    "\n",
    "        with open(file_list) as f:\n",
    "            pairs = f.read().splitlines()[1:]\n",
    "        for i, p in enumerate(pairs):\n",
    "            p = p.split('\\t')\n",
    "            if len(p) == 3:\n",
    "                nameL = p[0] + '/' + p[0] + '_' + '{:04}.jpg'.format(int(p[1]))\n",
    "                nameR = p[0] + '/' + p[0] + '_' + '{:04}.jpg'.format(int(p[2]))\n",
    "                fold = i // 600\n",
    "                flag = 1\n",
    "            elif len(p) == 4:\n",
    "                nameL = p[0] + '/' + p[0] + '_' + '{:04}.jpg'.format(int(p[1]))\n",
    "                nameR = p[2] + '/' + p[2] + '_' + '{:04}.jpg'.format(int(p[3]))\n",
    "                fold = i // 600\n",
    "                flag = -1\n",
    "            self.nameLs.append(nameL)\n",
    "            self.nameRs.append(nameR)\n",
    "            self.folds.append(fold)\n",
    "            self.flags.append(flag)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        img_l = self.loader(os.path.join(self.root, self.nameLs[index]))\n",
    "        img_r = self.loader(os.path.join(self.root, self.nameRs[index]))\n",
    "        imglist = [img_l, cv2.flip(img_l, 1), img_r, cv2.flip(img_r, 1)]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            for i in range(len(imglist)):\n",
    "                imglist[i] = self.transform(imglist[i])\n",
    "\n",
    "            imgs = imglist\n",
    "            return imgs\n",
    "        else:\n",
    "            imgs = [torch.from_numpy(i) for i in imglist]\n",
    "            return imgs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.nameLs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## agedb.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:16:34.213546Z",
     "start_time": "2020-07-18T15:16:34.196541Z"
    }
   },
   "outputs": [],
   "source": [
    "# from dataset.agedb import AgeDB30\n",
    "def img_loader(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            img = cv2.imread(path)\n",
    "            if len(img.shape) == 2:\n",
    "                img = np.stack([img] * 3, 2)\n",
    "            return img\n",
    "    except IOError:\n",
    "        print('Cannot load image ' + path)\n",
    "\n",
    "class AgeDB30(data.Dataset):\n",
    "    def __init__(self, root, file_list, transform=None, loader=img_loader):\n",
    "\n",
    "        self.root = root\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "        self.nameLs = []\n",
    "        self.nameRs = []\n",
    "        self.folds = []\n",
    "        self.flags = []\n",
    "\n",
    "        with open(file_list) as f:\n",
    "            pairs = f.read().splitlines()\n",
    "        for i, p in enumerate(pairs):\n",
    "            p = p.split(' ')\n",
    "            nameL = p[0]\n",
    "            nameR = p[1]\n",
    "            fold = i // 600\n",
    "            flag = int(p[2])\n",
    "\n",
    "            self.nameLs.append(nameL)\n",
    "            self.nameRs.append(nameR)\n",
    "            self.folds.append(fold)\n",
    "            self.flags.append(flag)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        img_l = self.loader(os.path.join(self.root, self.nameLs[index]))\n",
    "        img_r = self.loader(os.path.join(self.root, self.nameRs[index]))\n",
    "        imglist = [img_l, cv2.flip(img_l, 1), img_r, cv2.flip(img_r, 1)]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            for i in range(len(imglist)):\n",
    "                imglist[i] = self.transform(imglist[i])\n",
    "\n",
    "            imgs = imglist\n",
    "            return imgs\n",
    "        else:\n",
    "            imgs = [torch.from_numpy(i) for i in imglist]\n",
    "            return imgs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.nameLs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cfp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:16:35.533545Z",
     "start_time": "2020-07-18T15:16:35.508539Z"
    }
   },
   "outputs": [],
   "source": [
    "# from dataset.cfp import CFP_FP\n",
    "def img_loader(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            img = cv2.imread(path)\n",
    "            if len(img.shape) == 2:\n",
    "                img = np.stack([img] * 3, 2)\n",
    "            return img\n",
    "    except IOError:\n",
    "        print('Cannot load image ' + path)\n",
    "\n",
    "class CFP_FP(data.Dataset):\n",
    "    def __init__(self, root, file_list, transform=None, loader=img_loader):\n",
    "\n",
    "        self.root = root\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "        self.nameLs = []\n",
    "        self.nameRs = []\n",
    "        self.folds = []\n",
    "        self.flags = []\n",
    "\n",
    "        with open(file_list) as f:\n",
    "            pairs = f.read().splitlines()\n",
    "        for i, p in enumerate(pairs):\n",
    "            p = p.split(' ')\n",
    "            nameL = p[0]\n",
    "            nameR = p[1]\n",
    "            fold = i // 700\n",
    "            flag = int(p[2])\n",
    "\n",
    "            self.nameLs.append(nameL)\n",
    "            self.nameRs.append(nameR)\n",
    "            self.folds.append(fold)\n",
    "            self.flags.append(flag)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        img_l = self.loader(os.path.join(self.root, self.nameLs[index]))\n",
    "        img_r = self.loader(os.path.join(self.root, self.nameRs[index]))\n",
    "        imglist = [img_l, cv2.flip(img_l, 1), img_r, cv2.flip(img_r, 1)]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            for i in range(len(imglist)):\n",
    "                imglist[i] = self.transform(imglist[i])\n",
    "\n",
    "            imgs = imglist\n",
    "            return imgs\n",
    "        else:\n",
    "            imgs = [torch.from_numpy(i) for i in imglist]\n",
    "            return imgs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.nameLs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval_lfw.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:16:36.786539Z",
     "start_time": "2020-07-18T15:16:36.727539Z"
    }
   },
   "outputs": [],
   "source": [
    "# from eval_lfw import evaluation_10_fold, getFeatureFromTorch\n",
    "def getAccuracy(scores, flags, threshold):\n",
    "    p = np.sum(scores[flags == 1] > threshold)\n",
    "    n = np.sum(scores[flags == -1] < threshold)\n",
    "    return 1.0 * (p + n) / len(scores)\n",
    "\n",
    "def getThreshold(scores, flags, thrNum):\n",
    "    accuracys = np.zeros((2 * thrNum + 1, 1))\n",
    "    thresholds = np.arange(-thrNum, thrNum + 1) * 1.0 / thrNum\n",
    "    for i in range(2 * thrNum + 1):\n",
    "        accuracys[i] = getAccuracy(scores, flags, thresholds[i])\n",
    "    max_index = np.squeeze(accuracys == np.max(accuracys))\n",
    "    bestThreshold = np.mean(thresholds[max_index])\n",
    "    return bestThreshold\n",
    "\n",
    "def evaluation_10_fold(feature_path='./result/cur_epoch_result.mat'):\n",
    "    ACCs = np.zeros(10)\n",
    "    result = scipy.io.loadmat(feature_path)\n",
    "    for i in range(10):\n",
    "        fold = result['fold']\n",
    "        flags = result['flag']\n",
    "        featureLs = result['fl']\n",
    "        featureRs = result['fr']\n",
    "\n",
    "        valFold = fold != i\n",
    "        testFold = fold == i\n",
    "        flags = np.squeeze(flags)\n",
    "\n",
    "        mu = np.mean(np.concatenate((featureLs[valFold[0], :], featureRs[valFold[0], :]), 0), 0)\n",
    "        mu = np.expand_dims(mu, 0)\n",
    "        featureLs = featureLs - mu\n",
    "        featureRs = featureRs - mu\n",
    "        featureLs = featureLs / np.expand_dims(np.sqrt(np.sum(np.power(featureLs, 2), 1)), 1)\n",
    "        featureRs = featureRs / np.expand_dims(np.sqrt(np.sum(np.power(featureRs, 2), 1)), 1)\n",
    "\n",
    "        scores = np.sum(np.multiply(featureLs, featureRs), 1)\n",
    "        threshold = getThreshold(scores[valFold[0]], flags[valFold[0]], 10000)\n",
    "        ACCs[i] = getAccuracy(scores[testFold[0]], flags[testFold[0]], threshold)\n",
    "\n",
    "    return ACCs\n",
    "\n",
    "def loadModel(data_root, file_list, backbone_net, gpus='0', resume=None):\n",
    "\n",
    "    if backbone_net == 'MobileFace':\n",
    "        net = mobilefacenet.MobileFaceNet()\n",
    "    elif backbone_net == 'CBAM_50':\n",
    "        net = cbam.CBAMResNet(50, feature_dim=args.feature_dim, mode='ir')\n",
    "    elif backbone_net == 'CBAM_50_SE':\n",
    "        net = cbam.CBAMResNet(50, feature_dim=args.feature_dim, mode='ir_se')\n",
    "    elif backbone_net == 'CBAM_100':\n",
    "        net = cbam.CBAMResNet(100, feature_dim=args.feature_dim, mode='ir')\n",
    "    elif backbone_net == 'CBAM_100_SE':\n",
    "        net = cbam.CBAMResNet(100, feature_dim=args.feature_dim, mode='ir_se')\n",
    "    else:\n",
    "        print(backbone_net, ' is not available!')\n",
    "\n",
    "    # gpu init\n",
    "    multi_gpus = False\n",
    "    if len(gpus.split(',')) > 1:\n",
    "        multi_gpus = True\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = gpus\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    net.load_state_dict(torch.load(resume)['net_state_dict'])\n",
    "\n",
    "    if multi_gpus:\n",
    "        net = DataParallel(net).to(device)\n",
    "    else:\n",
    "        net = net.to(device)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # range [0, 255] -> [0.0,1.0]\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))  # range [0.0, 1.0] -> [-1.0,1.0]\n",
    "    ])\n",
    "    lfw_dataset = LFW(data_root, file_list, transform=transform)\n",
    "    lfw_loader = torch.utils.data.DataLoader(lfw_dataset, batch_size=128,\n",
    "                                             shuffle=False, num_workers=2, drop_last=False)\n",
    "\n",
    "    return net.eval(), device, lfw_dataset, lfw_loader\n",
    "\n",
    "def getFeatureFromTorch(feature_save_dir, net, device, data_set, data_loader):\n",
    "    featureLs = None\n",
    "    featureRs = None\n",
    "    count = 0\n",
    "    for data in data_loader:\n",
    "        for i in range(len(data)):\n",
    "            data[i] = data[i].to(device)\n",
    "        count += data[0].size(0)\n",
    "        #print('extracing deep features from the face pair {}...'.format(count))\n",
    "        with torch.no_grad():\n",
    "            res = [net(d).data.cpu().numpy() for d in data]\n",
    "        featureL = np.concatenate((res[0], res[1]), 1)\n",
    "        featureR = np.concatenate((res[2], res[3]), 1)\n",
    "        # print(featureL.shape, featureR.shape)\n",
    "        if featureLs is None:\n",
    "            featureLs = featureL\n",
    "        else:\n",
    "            featureLs = np.concatenate((featureLs, featureL), 0)\n",
    "        if featureRs is None:\n",
    "            featureRs = featureR\n",
    "        else:\n",
    "            featureRs = np.concatenate((featureRs, featureR), 0)\n",
    "        # print(featureLs.shape, featureRs.shape)\n",
    "\n",
    "    result = {'fl': featureLs, 'fr': featureRs, 'fold': data_set.folds, 'flag': data_set.flags}\n",
    "    scipy.io.savemat(feature_save_dir, result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:16:38.248541Z",
     "start_time": "2020-07-18T15:16:38.241538Z"
    }
   },
   "outputs": [],
   "source": [
    "def img_loader(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            img = cv2.imread(path)\n",
    "            if len(img.shape) == 2:\n",
    "                img = np.stack([img] * 3, 2)\n",
    "            return img\n",
    "    except IOError:\n",
    "        print('Cannot load image ' + path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:16:39.145538Z",
     "start_time": "2020-07-18T15:16:39.140542Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # range [0, 255] -> [0.0,1.0]\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))  # range [0.0, 1.0] -> [-1.0,1.0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:16:40.002543Z",
     "start_time": "2020-07-18T15:16:39.984552Z"
    }
   },
   "outputs": [],
   "source": [
    "class CASIAWebFace(data.Dataset):\n",
    "    def __init__(self, root, file_list, transform=None, loader=img_loader):\n",
    "\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "\n",
    "        image_list = []\n",
    "        label_list = []\n",
    "        with open(file_list) as f:\n",
    "            img_label_list = f.read().splitlines()\n",
    "        for info in img_label_list:\n",
    "            image_path, label_name = info.split('\\t')[1:]\n",
    "            image_list.append(image_path)\n",
    "            label_list.append(int(label_name))\n",
    "\n",
    "        self.image_list = image_list\n",
    "        self.label_list = label_list\n",
    "        self.class_nums = len(np.unique(self.label_list))\n",
    "        print(\"dataset size: \", len(self.image_list), '/', self.class_nums)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.image_list[index]\n",
    "        label = self.label_list[index]\n",
    "\n",
    "        img = self.loader(os.path.join(self.root, img_path))\n",
    "\n",
    "        # random flip with ratio of 0.5\n",
    "        flip = np.random.choice(2) * 2 - 1\n",
    "        if flip == 1:\n",
    "            img = cv2.flip(img, 1)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = torch.from_numpy(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:17:12.560596Z",
     "start_time": "2020-07-18T15:17:12.554595Z"
    }
   },
   "outputs": [],
   "source": [
    "# gpu init\n",
    "multi_gpus = False\n",
    "if len(args.gpus.split(',')) > 1:\n",
    "    multi_gpus = True\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpus\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:17:13.061593Z",
     "start_time": "2020-07-18T15:17:13.053593Z"
    }
   },
   "outputs": [],
   "source": [
    "# log init\n",
    "save_dir = os.path.join(args.save_dir, args.model_pre + args.backbone.upper() + '_' + datetime.now().strftime('%Y%m%d_%H%M%S'))\n",
    "if os.path.exists(save_dir):\n",
    "    raise NameError('model dir exists!')\n",
    "os.makedirs(save_dir)\n",
    "logging = init_log(save_dir)\n",
    "_print = logging.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:17:13.947602Z",
     "start_time": "2020-07-18T15:17:13.935593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dataset size:  590 / 3\n"
     ]
    }
   ],
   "source": [
    "# dataset loader\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # range [0, 255] -> [0.0,1.0]\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))  # range [0.0, 1.0] -> [-1.0,1.0]\n",
    "])\n",
    "# validation dataset\n",
    "print(args.train_root)\n",
    "trainset = CASIAWebFace(args.train_root, args.train_file_list, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:17:16.479597Z",
     "start_time": "2020-07-18T15:17:16.463593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.class_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:17:17.859593Z",
     "start_time": "2020-07-18T15:17:17.841592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/small_vgg/small_vgg_112x112/train/n000001/0001_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0002_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0003_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0005_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0006_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0007_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0008_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0010_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0011_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0013_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0014_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0015_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0016_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0017_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0018_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0019_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0020_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0021_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0022_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0023_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0024_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0026_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0027_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0028_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0029_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0031_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0032_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0033_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0034_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0035_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0036_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0037_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0038_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0039_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0040_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0041_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0042_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0043_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0045_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0047_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0048_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0049_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0051_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0052_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0054_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0055_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0056_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0058_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0059_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0060_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0061_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0062_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0063_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0064_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0065_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0066_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0067_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0068_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0069_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0070_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0071_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0072_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0073_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0074_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0075_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0076_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0077_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0078_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0079_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0080_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0081_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0082_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0083_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0084_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0085_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0086_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0087_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0089_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0090_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0092_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0094_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0095_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0096_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_04.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_05.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_06.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_07.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_08.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0098_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0099_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0101_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0102_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0103_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0104_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0105_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0106_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0107_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0108_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0109_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0110_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0111_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0114_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0115_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0116_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0117_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0118_04.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0119_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0120_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0121_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0122_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0123_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0124_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0125_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0126_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0127_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0129_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0130_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0131_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0132_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0133_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0134_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0135_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0136_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0137_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0138_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0139_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0140_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0141_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0142_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0143_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0144_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0146_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0147_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0149_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0151_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0153_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0154_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0155_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0156_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0157_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0158_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0159_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0162_06.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0163_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0164_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0167_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0168_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0171_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0172_07.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0173_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0174_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0175_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0176_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0177_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0178_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0179_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0180_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0181_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0182_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0183_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0184_06.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0185_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0186_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0187_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0188_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0190_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0193_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0194_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0195_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0196_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0197_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0199_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0200_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0201_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0202_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0203_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0204_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0205_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0206_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0208_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0211_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0212_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0214_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0215_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0217_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0218_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0219_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0220_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0221_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0222_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0224_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0227_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0228_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0231_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0235_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0237_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0238_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0239_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0240_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0241_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0242_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0243_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0245_04.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0246_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0248_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0250_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0253_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0255_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0256_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0257_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0259_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0260_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0261_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0262_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0264_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0266_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0267_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0268_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0272_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0276_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0277_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0278_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0280_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0282_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0283_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0284_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0285_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0287_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0288_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0291_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0295_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0296_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0297_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0298_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0300_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0302_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0303_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0305_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0001_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0006_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0009_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0010_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0011_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0012_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0013_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0014_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0016_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0017_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0019_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0020_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0022_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0025_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0027_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0028_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0030_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0032_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0035_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0038_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0039_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0040_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0043_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0044_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0045_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0046_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0049_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0001_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0002_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0003_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0004_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0005_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0006_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0007_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0008_05.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0009_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0010_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0011_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0012_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0013_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0014_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0015_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0016_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0017_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0018_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0019_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0020_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0021_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0022_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0023_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0024_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0026_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0027_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0028_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0001_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0002_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0003_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0005_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0006_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0007_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0008_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0010_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0011_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0013_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0014_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0015_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0016_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0017_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0018_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0019_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0020_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0021_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0022_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0023_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0024_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0026_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0027_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0028_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0029_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0031_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0032_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0033_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0034_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0035_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0036_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0037_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0038_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0039_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0040_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0041_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0042_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0043_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0045_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0047_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0048_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0049_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0051_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0052_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0054_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0055_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0056_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0058_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0059_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0060_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0061_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0062_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0063_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0064_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0065_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0066_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0067_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0068_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0069_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0070_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0071_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0072_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0073_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0074_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0075_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0076_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0077_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0078_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0079_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0080_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0081_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0082_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0083_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0084_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0085_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0086_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0087_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0089_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0090_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0092_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0094_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0095_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0096_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_04.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_05.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_06.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_07.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_08.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0098_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0099_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0101_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0102_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0103_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0104_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0105_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0106_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0107_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0108_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0109_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0110_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0111_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0114_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0115_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0116_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0117_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0118_04.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0119_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0120_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0121_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0122_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0123_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0124_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0125_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0126_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0127_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0129_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0130_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0131_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0132_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0133_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0134_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0135_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0136_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0137_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0138_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0139_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0140_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0141_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0142_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0143_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0144_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0146_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0147_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0149_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0151_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0153_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0154_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0155_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0156_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0157_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0158_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0159_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0162_06.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0163_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0164_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0167_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0168_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0171_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0172_07.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0173_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0174_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0175_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0176_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0177_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0178_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0179_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0180_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0181_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0182_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0183_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0184_06.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0185_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0186_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0187_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0188_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0190_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0193_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0194_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0195_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0196_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0197_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0199_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0200_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0201_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0202_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0203_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0204_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0205_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0206_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0208_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0211_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0212_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0214_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0215_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0217_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0218_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0219_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0220_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0221_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0222_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0224_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0227_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0228_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0231_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0235_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0237_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0238_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0239_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0240_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0241_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0242_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0243_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0245_04.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0246_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0248_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0250_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0253_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0255_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0256_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0257_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0259_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0260_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0261_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0262_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0264_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0266_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0267_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0268_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0272_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0276_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0277_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0278_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0280_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0282_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0283_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0284_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0285_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0287_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0288_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0291_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0295_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0296_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0297_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0298_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0300_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0302_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0303_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0305_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0001_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0006_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0009_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0010_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0011_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0012_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0013_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0014_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0016_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0017_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0019_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0020_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0022_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0025_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0027_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0028_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0030_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0032_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0035_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0038_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0039_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0040_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0043_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0044_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0045_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0046_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0049_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0001_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0002_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0003_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0004_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0005_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0006_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0007_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0008_05.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0009_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0010_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0011_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0012_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0013_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0014_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0015_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0016_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0017_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0018_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0019_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0020_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0021_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0022_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0023_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0024_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0026_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0027_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0028_01.jpg']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:17:26.936594Z",
     "start_time": "2020-07-18T15:17:26.930595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000001B7F8874248>\n"
     ]
    }
   ],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size,\n",
    "                                          shuffle=True,  drop_last=False)   # num_workers=8,\n",
    "print(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:17:28.621601Z",
     "start_time": "2020-07-18T15:17:28.615600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:17:30.103595Z",
     "start_time": "2020-07-18T15:17:30.077594Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/sda/lfw/pairs.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-2e4601ab5f1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# test dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlfwdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLFW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlfw_test_root\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlfw_file_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m lfwloader = torch.utils.data.DataLoader(lfwdataset, batch_size=128,\n\u001b[0;32m      4\u001b[0m                                          shuffle=False, num_workers=4, drop_last=False)\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# agedbdataset = AgeDB30(args.agedb_test_root, args.agedb_file_list, transform=transform)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-a0c985e125e4>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, file_list, transform, loader)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0mpairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/sda/lfw/pairs.txt'"
     ]
    }
   ],
   "source": [
    "# test dataset\n",
    "lfwdataset = LFW(args.lfw_test_root, args.lfw_file_list, transform=transform)\n",
    "lfwloader = torch.utils.data.DataLoader(lfwdataset, batch_size=128,\n",
    "                                         shuffle=False, num_workers=4, drop_last=False)\n",
    "# agedbdataset = AgeDB30(args.agedb_test_root, args.agedb_file_list, transform=transform)\n",
    "# agedbloader = torch.utils.data.DataLoader(agedbdataset, batch_size=128,\n",
    "#                                         shuffle=False, num_workers=4, drop_last=False)\n",
    "# cfpfpdataset = CFP_FP(args.cfpfp_test_root, args.cfpfp_file_list, transform=transform)\n",
    "# cfpfploader = torch.utils.data.DataLoader(cfpfpdataset, batch_size=128,\n",
    "#                                           shuffle=False, num_workers=4, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:17:39.034594Z",
     "start_time": "2020-07-18T15:17:37.005593Z"
    }
   },
   "outputs": [],
   "source": [
    "# define backbone and margin layer\n",
    "if args.backbone == 'MobileFace':\n",
    "    net = MobileFaceNet()\n",
    "elif args.backbone == 'Res50_IR':\n",
    "    net = CBAMResNet(50, feature_dim=args.feature_dim, mode='ir')\n",
    "elif args.backbone == 'SERes50_IR':\n",
    "    net = CBAMResNet(50, feature_dim=args.feature_dim, mode='ir_se')\n",
    "elif args.backbone == 'Res100_IR':\n",
    "    net = CBAMResNet(100, feature_dim=args.feature_dim, mode='ir')\n",
    "elif args.backbone == 'SERes100_IR':\n",
    "    net = CBAMResNet(100, feature_dim=args.feature_dim, mode='ir_se')\n",
    "elif args.backbone == 'Attention_56':\n",
    "    net = ResidualAttentionNet_56(feature_dim=args.feature_dim)\n",
    "elif args.backbone == 'Attention_92':\n",
    "    net = ResidualAttentionNet_92(feature_dim=args.feature_dim)\n",
    "else:\n",
    "    print(args.backbone, ' is not available!')\n",
    "\n",
    "if args.margin_type == 'ArcFace':\n",
    "    margin = ArcMarginProduct(args.feature_dim, trainset.class_nums, s=args.scale_size)\n",
    "elif args.margin_type == 'MultiMargin':\n",
    "    margin = MultiMarginProduct(args.feature_dim, trainset.class_nums, s=args.scale_size)\n",
    "elif args.margin_type == 'CosFace':\n",
    "    margin = CosineMarginProduct(args.feature_dim, trainset.class_nums, s=args.scale_size)\n",
    "elif args.margin_type == 'Softmax':\n",
    "    margin = InnerProduct(args.feature_dim, trainset.class_nums)\n",
    "elif args.margin_type == 'SphereFace':\n",
    "    pass\n",
    "else:\n",
    "    print(args.margin_type, 'is not available!')\n",
    "\n",
    "if args.resume:\n",
    "    print('resume the model parameters from: ', args.net_path, args.margin_path)\n",
    "    net.load_state_dict(torch.load(args.net_path)['net_state_dict'])\n",
    "    margin.load_state_dict(torch.load(args.margin_path)['net_state_dict'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:17:39.068596Z",
     "start_time": "2020-07-18T15:17:39.037594Z"
    }
   },
   "outputs": [],
   "source": [
    "# define optimizers for different layer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer_ft = optim.SGD([\n",
    "    {'params': net.parameters(), 'weight_decay': 5e-4},\n",
    "    {'params': margin.parameters(), 'weight_decay': 5e-4}\n",
    "], lr=0.1, momentum=0.9, nesterov=True)\n",
    "exp_lr_scheduler = lr_scheduler.MultiStepLR(optimizer_ft, milestones=[6, 11, 16], gamma=0.1)\n",
    "\n",
    "if multi_gpus:\n",
    "    net = DataParallel(net).to(device)\n",
    "    margin = DataParallel(margin).to(device)\n",
    "else:\n",
    "    net = net.to(device)\n",
    "    margin = margin.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:17:41.402596Z",
     "start_time": "2020-07-18T15:17:41.398600Z"
    }
   },
   "outputs": [],
   "source": [
    "best_lfw_acc = 0.0\n",
    "best_lfw_iters = 0\n",
    "best_agedb30_acc = 0.0\n",
    "best_agedb30_iters = 0\n",
    "best_cfp_fp_acc = 0.0\n",
    "best_cfp_fp_iters = 0\n",
    "total_iters = 0\n",
    "# vis = Visualizer(env=args.model_pre + args.backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:46:25.496113Z",
     "start_time": "2020-07-18T15:19:37.522554Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1/18 ...\n",
      "Train Epoch: 1/18 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([14, 3, 112, 112]) torch.Size([14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2/18 ...\n",
      "Train Epoch: 2/18 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-67aadb0a69ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmargin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_logits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mtotal_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0moptimizer_ft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.total_epoch + 1):\n",
    "# while(1):\n",
    "    exp_lr_scheduler.step()\n",
    "    # train model\n",
    "    _print('Train Epoch: {}/{} ...'.format(epoch, args.total_epoch))\n",
    "    net.train()\n",
    "\n",
    "    since = time.time()\n",
    "    for data in trainloader:\n",
    "        print('len(data)', len(data), data[0].shape, data[1].shape)\n",
    "        img, label = data[0].to(device), data[1].to(device)\n",
    "        optimizer_ft.zero_grad()\n",
    "\n",
    "        raw_logits = net(img)\n",
    "        output = margin(raw_logits, label)\n",
    "        total_loss = criterion(output, label)\n",
    "        total_loss.backward()\n",
    "        optimizer_ft.step()\n",
    "\n",
    "        total_iters += 1\n",
    "        # print train information\n",
    "        if total_iters % 100 == 0:\n",
    "            # current training accuracy\n",
    "            _, predict = torch.max(output.data, 1)\n",
    "            total = label.size(0)\n",
    "            correct = (np.array(predict.cpu()) == np.array(label.data.cpu())).sum()\n",
    "            time_cur = (time.time() - since) / 100\n",
    "            since = time.time()\n",
    "#             vis.plot_curves({'softmax loss': total_loss.item()}, iters=total_iters, title='train loss',\n",
    "#                             xlabel='iters', ylabel='train loss')\n",
    "#             vis.plot_curves({'train accuracy': correct / total}, iters=total_iters, title='train accuracy', xlabel='iters',\n",
    "#                             ylabel='train accuracy')\n",
    "\n",
    "            _print(\"Iters: {:0>6d}/[{:0>2d}], loss: {:.4f}, train_accuracy: {:.4f}, time: {:.2f} s/iter, learning rate: {}\".format(total_iters, epoch, total_loss.item(), correct/total, time_cur, exp_lr_scheduler.get_lr()[0]))\n",
    "\n",
    "        # save model\n",
    "        if total_iters % args.save_freq == 0:\n",
    "            msg = 'Saving checkpoint: {}'.format(total_iters)\n",
    "            _print(msg)\n",
    "            if multi_gpus:\n",
    "                net_state_dict = net.module.state_dict()\n",
    "                margin_state_dict = margin.module.state_dict()\n",
    "            else:\n",
    "                net_state_dict = net.state_dict()\n",
    "                margin_state_dict = margin.state_dict()\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.mkdir(save_dir)\n",
    "            torch.save({\n",
    "                'iters': total_iters,\n",
    "                'net_state_dict': net_state_dict},\n",
    "                os.path.join(save_dir, 'Iter_%06d_net.ckpt' % total_iters))\n",
    "            torch.save({\n",
    "                'iters': total_iters,\n",
    "                'net_state_dict': margin_state_dict},\n",
    "                os.path.join(save_dir, 'Iter_%06d_margin.ckpt' % total_iters))\n",
    "\n",
    "print('finishing training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:17:08.497592Z",
     "start_time": "2020-07-18T15:17:08.485603Z"
    }
   },
   "outputs": [],
   "source": [
    "args = EasyDict()\n",
    "\n",
    "# args.train_root ='../data/faces_webface_112x112/imgs'    #'train image root')\n",
    "# args.train_file_list= '../data/faces_webface_112x112/train2.lst'    #'train list')\n",
    "args.train_root =''    #'train image root')\n",
    "args.train_file_list= '../data/small_vgg/train.lst'    #'train list')\n",
    "args.lfw_test_root='../data/lfw/'     #'lfw image root')\n",
    "args.lfw_file_list='/media/sda/lfw/pairs.txt'     #'lfw pair file list')\n",
    "args.agedb_test_root='/media/sda/AgeDB-30/agedb30_align_112'     #'agedb image root')\n",
    "args.agedb_file_list='/media/sda/AgeDB-30/agedb_30_pair.txt'     #'agedb pair file list')\n",
    "args.cfpfp_test_root='/media/sda/CFP-FP/cfp_fp_aligned_112'     #'agedb image root')\n",
    "args.cfpfp_file_list='/media/sda/CFP-FP/cfp_fp_pair.txt'     #'agedb pair file list')\n",
    "\n",
    "args.backbone='SERes100_IR'     #'MobileFace, Res50_IR, SERes50_IR, Res100_IR, SERes100_IR, Attention_56, Attention_92')\n",
    "args.margin_type='ArcFace'     #'ArcFace, CosFace, SphereFace, MultiMargin, Softmax')\n",
    "args.feature_dim=512     #'feature dimension, 128 or 512')\n",
    "args.scale_size=32.0     #'scale size')\n",
    "args.batch_size=32     #'batch size', defalut : 200\n",
    "args.total_epoch=18     #'total epochs')\n",
    "\n",
    "args.save_freq=3000     #'save frequency')\n",
    "args.test_freq=3000     #'test frequency')\n",
    "args.resume=False     #'resume model')\n",
    "args.net_path=''     #'resume model')\n",
    "args.margin_path=''     #'resume model')\n",
    "args.save_dir='./model'     #'model save dir')\n",
    "args.model_pre='SERES100_'     #'model prefix')\n",
    "args.gpus='0,1,2,3'     #'model prefix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:07:00.415862Z",
     "start_time": "2020-07-18T13:07:00.403856Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n"
     ]
    }
   ],
   "source": [
    "# root = 'D:/data/webface_align_112'\n",
    "# file_list = 'D:/data/webface_align_train.list'\n",
    "root = '../data/faces_webface_112x112/imgs'  \n",
    "file_list = '../data/small_vgg/small_vgg_112x112.lst'\n",
    "print(os.path.isdir(root), os.path.isfile(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "166.094px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
